{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:14.385256900Z",
     "start_time": "2025-12-28T09:26:11.796210100Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_regions: (366, 26)\n",
      "df_images : (128, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  split                                        image_id    H    W  \\\n0  real  real\\images\\10pm_feeding_around_the_clock.webp  749  750   \n1  real  real\\images\\10pm_feeding_around_the_clock.webp  749  750   \n2  real  real\\images\\10pm_feeding_around_the_clock.webp  749  750   \n3  real  real\\images\\10pm_feeding_around_the_clock.webp  749  750   \n4  real  real\\images\\10pm_feeding_around_the_clock.webp  749  750   \n\n   region_index  area_px  area_ratio  skel_mass_px  n_endpoints  n_junctions  \\\n0             0     2120    0.003774           159            0           71   \n1             1     1976    0.003518           165            0           79   \n2             2     2486    0.004425            63            0           14   \n3             3     2664    0.004742           188            1           78   \n4             4     1817    0.003235           178            1           57   \n\n   ...  is_primary  is_secondary  is_whole  centeredness  smoothness  \\\n0  ...           0             1         0      0.948810    0.744960   \n1  ...           0             1         0      0.957800    0.766552   \n2  ...           0             1         0      0.857058    0.732789   \n3  ...           0             1         0      0.863538    0.766856   \n4  ...           0             1         0      0.928498    0.728474   \n\n   stability_mask_mean  stability_mask_min  stability_mask_max  \\\n0             0.855354            0.845755            0.864953   \n1             0.840703            0.828947            0.852459   \n2             0.907409            0.903862            0.910956   \n3             0.864032            0.855480            0.872584   \n4             0.825438            0.811227            0.839649   \n\n   stability_mask_n  stability_mask_range  \n0               2.0              0.019198  \n1               2.0              0.023512  \n2               2.0              0.007095  \n3               2.0              0.017104  \n4               2.0              0.028422  \n\n[5 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>split</th>\n      <th>image_id</th>\n      <th>H</th>\n      <th>W</th>\n      <th>region_index</th>\n      <th>area_px</th>\n      <th>area_ratio</th>\n      <th>skel_mass_px</th>\n      <th>n_endpoints</th>\n      <th>n_junctions</th>\n      <th>...</th>\n      <th>is_primary</th>\n      <th>is_secondary</th>\n      <th>is_whole</th>\n      <th>centeredness</th>\n      <th>smoothness</th>\n      <th>stability_mask_mean</th>\n      <th>stability_mask_min</th>\n      <th>stability_mask_max</th>\n      <th>stability_mask_n</th>\n      <th>stability_mask_range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>real</td>\n      <td>real\\images\\10pm_feeding_around_the_clock.webp</td>\n      <td>749</td>\n      <td>750</td>\n      <td>0</td>\n      <td>2120</td>\n      <td>0.003774</td>\n      <td>159</td>\n      <td>0</td>\n      <td>71</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.948810</td>\n      <td>0.744960</td>\n      <td>0.855354</td>\n      <td>0.845755</td>\n      <td>0.864953</td>\n      <td>2.0</td>\n      <td>0.019198</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>real</td>\n      <td>real\\images\\10pm_feeding_around_the_clock.webp</td>\n      <td>749</td>\n      <td>750</td>\n      <td>1</td>\n      <td>1976</td>\n      <td>0.003518</td>\n      <td>165</td>\n      <td>0</td>\n      <td>79</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.957800</td>\n      <td>0.766552</td>\n      <td>0.840703</td>\n      <td>0.828947</td>\n      <td>0.852459</td>\n      <td>2.0</td>\n      <td>0.023512</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>real</td>\n      <td>real\\images\\10pm_feeding_around_the_clock.webp</td>\n      <td>749</td>\n      <td>750</td>\n      <td>2</td>\n      <td>2486</td>\n      <td>0.004425</td>\n      <td>63</td>\n      <td>0</td>\n      <td>14</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.857058</td>\n      <td>0.732789</td>\n      <td>0.907409</td>\n      <td>0.903862</td>\n      <td>0.910956</td>\n      <td>2.0</td>\n      <td>0.007095</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>real</td>\n      <td>real\\images\\10pm_feeding_around_the_clock.webp</td>\n      <td>749</td>\n      <td>750</td>\n      <td>3</td>\n      <td>2664</td>\n      <td>0.004742</td>\n      <td>188</td>\n      <td>1</td>\n      <td>78</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.863538</td>\n      <td>0.766856</td>\n      <td>0.864032</td>\n      <td>0.855480</td>\n      <td>0.872584</td>\n      <td>2.0</td>\n      <td>0.017104</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>real</td>\n      <td>real\\images\\10pm_feeding_around_the_clock.webp</td>\n      <td>749</td>\n      <td>750</td>\n      <td>4</td>\n      <td>1817</td>\n      <td>0.003235</td>\n      <td>178</td>\n      <td>1</td>\n      <td>57</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.928498</td>\n      <td>0.728474</td>\n      <td>0.825438</td>\n      <td>0.811227</td>\n      <td>0.839649</td>\n      <td>2.0</td>\n      <td>0.028422</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 26 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "REGION_CSV = r\"F:\\New Dissertation - Image Generation\\POC\\outputs\\shape_region_features.csv\"\n",
    "IMAGE_CSV  = r\"F:\\New Dissertation - Image Generation\\POC\\outputs\\shape_image_indices.csv\"\n",
    "\n",
    "OUT_FORM_DIR = r\"outputs\\form\\form_outputs_csv_only\"\n",
    "\n",
    "os.makedirs(OUT_FORM_DIR, exist_ok=True)\n",
    "\n",
    "df_regions = pd.read_csv(REGION_CSV)\n",
    "df_images  = pd.read_csv(IMAGE_CSV)\n",
    "\n",
    "print(\"df_regions:\", df_regions.shape)\n",
    "print(\"df_images :\", df_images.shape)\n",
    "display(df_regions.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:14.471742Z",
     "start_time": "2025-12-28T09:26:14.391295800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def safe_cols(df: pd.DataFrame, cols):\n",
    "    return [c for c in cols if c in df.columns]\n",
    "\n",
    "def zscore_cols(X, eps=1e-9):\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    mu = np.nanmean(X, axis=0)\n",
    "    sd = np.nanstd(X, axis=0)\n",
    "    return (X - mu) / (sd + eps)\n",
    "\n",
    "def cosine_similarity_matrix(X):\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True) + 1e-9\n",
    "    U = X / norms\n",
    "    return U @ U.T\n",
    "\n",
    "def ensure_dir(p):\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def sanitize_path_component(x: str) -> str:\n",
    "    \"\"\"\n",
    "    Windows-safe folder name, because image_id has slashes/backslashes/colon etc.\n",
    "    \"\"\"\n",
    "    x = str(x)\n",
    "    bad = ['\\\\', '/', ':', '*', '?', '\"', '<', '>', '|']\n",
    "    for b in bad:\n",
    "        x = x.replace(b, \"_\")\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:14.491237700Z",
     "start_time": "2025-12-28T09:26:14.487498500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Form-0 graph builder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "DEFAULT_FEATS = [\n",
    "    \"area_ratio\", \"skel_mass_px\",\n",
    "    \"pca_eig_ratio\", \"symmetry_pca\", \"saliency\",\n",
    "    \"n_endpoints\", \"n_junctions\", \"n_edges\",\n",
    "    \"centeredness\", \"smoothness\",\n",
    "    \"stability_mask_mean\", \"stability_mask_min\", \"stability_mask_max\", \"stability_mask_range\"\n",
    "]\n",
    "\n",
    "ROLE_COLS = [\"is_primary\", \"is_secondary\", \"is_whole\"]\n",
    "\n",
    "def build_form_graph_for_image_csv_only(\n",
    "    split, image_id, df_img: pd.DataFrame,\n",
    "    feature_cols=None,\n",
    "    repetition_threshold=0.85,\n",
    "    max_rep_edges_per_node=3,\n",
    "    add_role_links=True\n",
    "):\n",
    "    \"\"\"\n",
    "    CSV-only Form-0 graph.\n",
    "\n",
    "    Nodes: region_index with all CSV attributes.\n",
    "    Edges:\n",
    "      - repetition edges from cosine similarity on selected feature columns\n",
    "      - optional role-link edges if role columns exist (is_primary/is_secondary/is_whole)\n",
    "    \"\"\"\n",
    "    feature_cols = feature_cols or DEFAULT_FEATS\n",
    "    feat_cols = safe_cols(df_img, feature_cols)\n",
    "    if len(feat_cols) == 0:\n",
    "        raise ValueError(\"No usable feature columns found to build repetition edges.\")\n",
    "\n",
    "    # ---- init graph\n",
    "    G = nx.Graph(split=str(split), image_id=str(image_id), form0_mode=\"csv_only\")\n",
    "\n",
    "    df_img = df_img.copy().reset_index(drop=True)\n",
    "\n",
    "    # ---- add nodes\n",
    "    if \"region_index\" not in df_img.columns:\n",
    "        raise KeyError(\"df_img must contain 'region_index' column.\")\n",
    "    for _, row in df_img.iterrows():\n",
    "        rid = int(row[\"region_index\"])\n",
    "        attrs = row.to_dict()\n",
    "        attrs[\"node_type\"] = \"region\"\n",
    "        G.add_node(rid, **attrs)\n",
    "\n",
    "    # ---- repetition edges\n",
    "    # clean numeric matrix, fill NaNs with column medians (stable for cosine)\n",
    "    X = df_img[feat_cols].apply(pd.to_numeric, errors=\"coerce\").to_numpy(dtype=float)\n",
    "    # median fill\n",
    "    col_meds = np.nanmedian(X, axis=0)\n",
    "    inds = np.where(~np.isfinite(X))\n",
    "    if len(inds[0]) > 0:\n",
    "        X[inds] = np.take(col_meds, inds[1])\n",
    "\n",
    "    Xn = zscore_cols(X)\n",
    "    S = cosine_similarity_matrix(Xn)\n",
    "\n",
    "    ids = df_img[\"region_index\"].astype(int).tolist()\n",
    "    id_to_pos = {rid: i for i, rid in enumerate(ids)}\n",
    "\n",
    "    for rid in ids:\n",
    "        i = id_to_pos[rid]\n",
    "        sims = [(ids[j], float(S[i, j])) for j in range(len(ids)) if j != i]\n",
    "        sims.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        added = 0\n",
    "        for other, sim in sims:\n",
    "            if sim < repetition_threshold:\n",
    "                break\n",
    "            if added >= max_rep_edges_per_node:\n",
    "                break\n",
    "\n",
    "            if not G.has_edge(rid, other):\n",
    "                G.add_edge(rid, other, rel_repetition=1, repetition_sim=float(sim))\n",
    "            else:\n",
    "                G.edges[rid, other][\"rel_repetition\"] = 1\n",
    "                prev = G.edges[rid, other].get(\"repetition_sim\", -1)\n",
    "                G.edges[rid, other][\"repetition_sim\"] = float(max(sim, prev))\n",
    "            added += 1\n",
    "\n",
    "    # ---- optional role-link edges\n",
    "    if add_role_links:\n",
    "        role_cols_present = safe_cols(df_img, ROLE_COLS)\n",
    "        for role in role_cols_present:\n",
    "            # connect all regions with role==1\n",
    "            members = df_img.loc[pd.to_numeric(df_img[role], errors=\"coerce\").fillna(0).astype(int) == 1, \"region_index\"]\n",
    "            members = members.astype(int).tolist()\n",
    "            for a_i in range(len(members)):\n",
    "                for b_i in range(a_i + 1, len(members)):\n",
    "                    a, b = members[a_i], members[b_i]\n",
    "                    if not G.has_edge(a, b):\n",
    "                        G.add_edge(a, b, rel_rolelink=1, role=str(role))\n",
    "                    else:\n",
    "                        G.edges[a, b][\"rel_rolelink\"] = 1\n",
    "                        G.edges[a, b][\"role\"] = str(role)\n",
    "\n",
    "    # ---- export tables\n",
    "    nodes_out = pd.DataFrame([{\"node\": n, **G.nodes[n]} for n in G.nodes])\n",
    "    edge_rows = []\n",
    "    for u, v, a in G.edges(data=True):\n",
    "        row = {\"u\": u, \"v\": v}\n",
    "        row.update(a)\n",
    "        edge_rows.append(row)\n",
    "    edges_out = pd.DataFrame(edge_rows)\n",
    "\n",
    "    return G, nodes_out, edges_out, feat_cols"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:14.642325300Z",
     "start_time": "2025-12-28T09:26:14.505672100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Single-Image Runner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def build_and_save_one_form_graph(\n",
    "    df_regions: pd.DataFrame,\n",
    "    split: str,\n",
    "    image_id: str,\n",
    "    out_root: str = OUT_FORM_DIR,\n",
    "    repetition_threshold: float = 0.85,\n",
    "    max_rep_edges_per_node: int = 3,\n",
    "    add_role_links: bool = True,\n",
    "):\n",
    "    gdf = df_regions[(df_regions[\"split\"] == split) & (df_regions[\"image_id\"] == image_id)].copy()\n",
    "    if len(gdf) == 0:\n",
    "        raise ValueError(f\"No rows found for split={split}, image_id={image_id}\")\n",
    "\n",
    "    G, nodes_df, edges_df, used_feat_cols = build_form_graph_for_image_csv_only(\n",
    "        split, image_id, gdf,\n",
    "        repetition_threshold=repetition_threshold,\n",
    "        max_rep_edges_per_node=max_rep_edges_per_node,\n",
    "        add_role_links=add_role_links\n",
    "    )\n",
    "\n",
    "    # safer folder names\n",
    "    od = os.path.join(out_root, sanitize_path_component(split), sanitize_path_component(image_id))\n",
    "    ensure_dir(od)\n",
    "\n",
    "    with open(os.path.join(od, \"form_graph.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(G, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    nodes_df.to_csv(os.path.join(od, \"nodes.csv\"), index=False)\n",
    "    edges_df.to_csv(os.path.join(od, \"edges.csv\"), index=False)\n",
    "\n",
    "    meta = {\n",
    "        \"split\": split,\n",
    "        \"image_id\": image_id,\n",
    "        \"n_nodes\": int(G.number_of_nodes()),\n",
    "        \"n_edges\": int(G.number_of_edges()),\n",
    "        \"feature_cols_used\": \",\".join(used_feat_cols),\n",
    "        \"repetition_threshold\": float(repetition_threshold),\n",
    "        \"max_rep_edges_per_node\": int(max_rep_edges_per_node),\n",
    "        \"out_dir\": od\n",
    "    }\n",
    "    return G, nodes_df, edges_df, meta"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:14.705348700Z",
     "start_time": "2025-12-28T09:26:14.534766Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run for all batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\1496182630.py:49: RuntimeWarning: All-NaN slice encountered\n",
      "  col_meds = np.nanmedian(X, axis=0)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\380558264.py:6: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graphs_built: 128\n",
      "nodes_all: (366, 28)\n",
      "edges_all: (417, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  split                                           image_id  n_nodes  n_edges  \\\n0  real     real\\images\\10pm_feeding_around_the_clock.webp       19      108   \n1  real                              real\\images\\11pm.webp        1        0   \n2  real                         real\\images\\12_4_7_10.webp        1        0   \n3  real                      real\\images\\Belly_breast.webp        7        9   \n4  real  real\\images\\Belly_breast_face_brain_placenta.webp        1        0   \n\n                                   feature_cols_used  repetition_threshold  \\\n0  area_ratio,skel_mass_px,pca_eig_ratio,symmetry...                  0.85   \n1  area_ratio,skel_mass_px,pca_eig_ratio,symmetry...                  0.85   \n2  area_ratio,skel_mass_px,pca_eig_ratio,symmetry...                  0.85   \n3  area_ratio,skel_mass_px,pca_eig_ratio,symmetry...                  0.85   \n4  area_ratio,skel_mass_px,pca_eig_ratio,symmetry...                  0.85   \n\n   max_rep_edges_per_node  \n0                       3  \n1                       3  \n2                       3  \n3                       3  \n4                       3  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>split</th>\n      <th>image_id</th>\n      <th>n_nodes</th>\n      <th>n_edges</th>\n      <th>feature_cols_used</th>\n      <th>repetition_threshold</th>\n      <th>max_rep_edges_per_node</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>real</td>\n      <td>real\\images\\10pm_feeding_around_the_clock.webp</td>\n      <td>19</td>\n      <td>108</td>\n      <td>area_ratio,skel_mass_px,pca_eig_ratio,symmetry...</td>\n      <td>0.85</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>real</td>\n      <td>real\\images\\11pm.webp</td>\n      <td>1</td>\n      <td>0</td>\n      <td>area_ratio,skel_mass_px,pca_eig_ratio,symmetry...</td>\n      <td>0.85</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>real</td>\n      <td>real\\images\\12_4_7_10.webp</td>\n      <td>1</td>\n      <td>0</td>\n      <td>area_ratio,skel_mass_px,pca_eig_ratio,symmetry...</td>\n      <td>0.85</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>real</td>\n      <td>real\\images\\Belly_breast.webp</td>\n      <td>7</td>\n      <td>9</td>\n      <td>area_ratio,skel_mass_px,pca_eig_ratio,symmetry...</td>\n      <td>0.85</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>real</td>\n      <td>real\\images\\Belly_breast_face_brain_placenta.webp</td>\n      <td>1</td>\n      <td>0</td>\n      <td>area_ratio,skel_mass_px,pca_eig_ratio,symmetry...</td>\n      <td>0.85</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_nodes = []\n",
    "all_edges = []\n",
    "meta_rows = []\n",
    "graphs_built = 0\n",
    "\n",
    "for (split, image_id), gdf in df_regions.groupby([\"split\", \"image_id\"], sort=False):\n",
    "\n",
    "    G, nodes_df, edges_df, used_feat_cols = build_form_graph_for_image_csv_only(\n",
    "        split, image_id, gdf,\n",
    "        repetition_threshold=0.85,\n",
    "        max_rep_edges_per_node=3,\n",
    "        add_role_links=True\n",
    "    )\n",
    "\n",
    "    od = os.path.join(OUT_FORM_DIR, sanitize_path_component(split), sanitize_path_component(image_id))\n",
    "    ensure_dir(od)\n",
    "\n",
    "    with open(os.path.join(od, \"form_graph.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(G, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    nodes_df.to_csv(os.path.join(od, \"nodes.csv\"), index=False)\n",
    "    edges_df.to_csv(os.path.join(od, \"edges.csv\"), index=False)\n",
    "\n",
    "    # collect\n",
    "    nodes_df2 = nodes_df.copy()\n",
    "    edges_df2 = edges_df.copy()\n",
    "    nodes_df2[\"split\"] = split\n",
    "    nodes_df2[\"image_id\"] = image_id\n",
    "    edges_df2[\"split\"] = split\n",
    "    edges_df2[\"image_id\"] = image_id\n",
    "\n",
    "    all_nodes.append(nodes_df2)\n",
    "    all_edges.append(edges_df2)\n",
    "\n",
    "    meta_rows.append({\n",
    "        \"split\": split,\n",
    "        \"image_id\": image_id,\n",
    "        \"n_nodes\": int(G.number_of_nodes()),\n",
    "        \"n_edges\": int(G.number_of_edges()),\n",
    "        \"feature_cols_used\": \",\".join(used_feat_cols),\n",
    "        \"repetition_threshold\": 0.85,\n",
    "        \"max_rep_edges_per_node\": 3\n",
    "    })\n",
    "\n",
    "    graphs_built += 1\n",
    "\n",
    "df_form_nodes = pd.concat(all_nodes, ignore_index=True) if all_nodes else pd.DataFrame()\n",
    "df_form_edges = pd.concat(all_edges, ignore_index=True) if all_edges else pd.DataFrame()\n",
    "df_form_meta  = pd.DataFrame(meta_rows)\n",
    "\n",
    "df_form_nodes.to_csv(os.path.join(OUT_FORM_DIR, \"form_nodes_all.csv\"), index=False)\n",
    "df_form_edges.to_csv(os.path.join(OUT_FORM_DIR, \"form_edges_all.csv\"), index=False)\n",
    "df_form_meta.to_csv(os.path.join(OUT_FORM_DIR, \"form_graph_meta.csv\"), index=False)\n",
    "\n",
    "print(\"graphs_built:\", graphs_built)\n",
    "print(\"nodes_all:\", df_form_nodes.shape)\n",
    "print(\"edges_all:\", df_form_edges.shape)\n",
    "display(df_form_meta.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:18.891325800Z",
     "start_time": "2025-12-28T09:26:14.585497400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Orientation & frames of reference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "OUT_FORM1_DIR = r\"outputs\\form\\form1_orientation\"\n",
    "os.makedirs(OUT_FORM1_DIR, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:18.903694500Z",
     "start_time": "2025-12-28T09:26:18.898339400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helpers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def _as_float_series(s):\n",
    "    \"\"\"For pandas Series / array-like columns.\"\"\"\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(float)\n",
    "\n",
    "def _as_float_scalar(x, default=np.nan):\n",
    "    \"\"\"For single values.\"\"\"\n",
    "    try:\n",
    "        v = pd.to_numeric(x, errors=\"coerce\")\n",
    "        if v is None or (isinstance(v, float) and np.isnan(v)):\n",
    "            return default\n",
    "        return float(v)\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def _strength_score(row):\n",
    "    \"\"\"\n",
    "    Axis strength proxy in [0,1].\n",
    "    row is a pandas Series from iterrows()\n",
    "    \"\"\"\n",
    "    eig = _as_float_scalar(row.get(\"pca_eig_ratio\", np.nan))\n",
    "    v = np.log1p(max(eig, 0.0))\n",
    "    return float(np.clip(v / 4.0, 0.0, 1.0))\n",
    "\n",
    "def _wrap180(angle_deg):\n",
    "    \"\"\"Map degrees to [0, 180).\"\"\"\n",
    "    a = np.asarray(angle_deg, dtype=float)\n",
    "    return np.mod(a, 180.0)\n",
    "\n",
    "def _axis_angle_from_uv(dx, dy):\n",
    "    \"\"\"\n",
    "    Convert axis unit vector (dx,dy) to directionless axis angle in degrees [0,180).\n",
    "    dx,dy in image x,y coords.\n",
    "    \"\"\"\n",
    "    ang = np.degrees(np.arctan2(dy, dx))\n",
    "    return _wrap180(ang)\n",
    "\n",
    "def _dist_to_axis(angle_deg, axis_deg):\n",
    "    \"\"\"\n",
    "    Smallest absolute angular distance between two directionless axes (0..90).\n",
    "    Both in [0,180).\n",
    "    \"\"\"\n",
    "    a = np.asarray(angle_deg, dtype=float)\n",
    "    b = np.asarray(axis_deg, dtype=float)\n",
    "    d = np.abs(a - b)\n",
    "    d = np.minimum(d, 180.0 - d)\n",
    "    # directionless axis => treat 0 and 180 same already; this yields 0..90\n",
    "    return d\n",
    "\n",
    "def _min_dist_to_hv(angle_deg):\n",
    "    \"\"\"Distance to nearest horizontal(0) or vertical(90) in degrees (0..45).\"\"\"\n",
    "    a = np.asarray(angle_deg, dtype=float)\n",
    "    d0 = _dist_to_axis(a, 0.0)\n",
    "    d90 = _dist_to_axis(a, 90.0)\n",
    "    return np.minimum(d0, d90)\n",
    "\n",
    "def _global_align_score(angle_deg):\n",
    "    \"\"\"\n",
    "    1.0 = perfectly horizontal/vertical\n",
    "    0.0 = maximally diagonal (45 deg away)\n",
    "    \"\"\"\n",
    "    d = _min_dist_to_hv(angle_deg)  # 0..45\n",
    "    return 1.0 - (d / 45.0)\n",
    "\n",
    "def _pick_parent(df_img):\n",
    "    \"\"\"\n",
    "    Choose a 'parent' / dominant frame region.\n",
    "    Preference: is_whole==1, else highest saliency, else largest area_ratio.\n",
    "    Returns region_index or None.\n",
    "    \"\"\"\n",
    "    if \"is_whole\" in df_img.columns and (df_img[\"is_whole\"].astype(int) == 1).any():\n",
    "        return int(df_img.loc[df_img[\"is_whole\"].astype(int) == 1, \"region_index\"].iloc[0])\n",
    "\n",
    "    if \"saliency\" in df_img.columns and np.isfinite(_as_float_series(df_img[\"saliency\"])).any():\n",
    "        j = int(_as_float_series(df_img[\"saliency\"]).fillna(-1).idxmax())\n",
    "        return int(df_img.loc[j, \"region_index\"])\n",
    "\n",
    "    if \"area_ratio\" in df_img.columns and np.isfinite(_as_float_series(df_img[\"area_ratio\"])).any():\n",
    "        j = int(_as_float_series(df_img[\"area_ratio\"]).fillna(-1).idxmax())\n",
    "        return int(df_img.loc[j, \"region_index\"])\n",
    "\n",
    "    return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:19.058805100Z",
     "start_time": "2025-12-28T09:26:18.929333300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "if \"pca_angle_deg\" not in df_regions.columns:\n",
    "    raise KeyError(\n",
    "        \"df_regions is missing 'pca_angle_deg'. \"\n",
    "        \"Add it during Shape (Step4 PCA) export, then rerun Form-1.\"\n",
    "    )\n",
    "\n",
    "# Ensure numeric\n",
    "df_regions = df_regions.copy()\n",
    "df_regions[\"pca_angle_deg\"] = _as_float_series(df_regions[\"pca_angle_deg\"])\n",
    "if \"pca_eig_ratio\" in df_regions.columns:\n",
    "    df_regions[\"pca_eig_ratio\"] = _as_float_series(df_regions[\"pca_eig_ratio\"])\n",
    "if \"saliency\" in df_regions.columns: df_regions[\"saliency\"] = _as_float_series(df_regions[\"saliency\"])\n",
    "if \"area_ratio\" in df_regions.columns: df_regions[\"area_ratio\"] = _as_float_series(df_regions[\"area_ratio\"])\n",
    "if \"pca_eig_ratio\" in df_regions.columns: df_regions[\"pca_eig_ratio\"] = _as_float_series(df_regions[\"pca_eig_ratio\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:19.129057400Z",
     "start_time": "2025-12-28T09:26:18.954663500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute Per Image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "rows_region = []\n",
    "rows_image  = []\n",
    "\n",
    "for (split, image_id), g in df_regions.groupby([\"split\", \"image_id\"], sort=False):\n",
    "    df_img = g.copy().reset_index(drop=True)\n",
    "\n",
    "    # (1) Global frame alignment per region\n",
    "    ang = df_img[\"pca_angle_deg\"].to_numpy(dtype=float)\n",
    "    global_align = _global_align_score(ang)  # [0,1]\n",
    "    dist_hv_deg  = _min_dist_to_hv(ang)      # [0,45]\n",
    "\n",
    "    # choose parent frame\n",
    "    parent_rid = _pick_parent(df_img)\n",
    "    if parent_rid is not None and (df_img[\"region_index\"].astype(int) == parent_rid).any():\n",
    "        parent_angle = float(df_img.loc[df_img[\"region_index\"].astype(int) == parent_rid, \"pca_angle_deg\"].iloc[0])\n",
    "    else:\n",
    "        parent_angle = np.nan\n",
    "\n",
    "    # (2) Local frame influence: child alignment to parent vs global H/V\n",
    "    # child-parent distance (0..90), child-global distance (0..45)\n",
    "    child_parent_dist = _dist_to_axis(ang, parent_angle) if np.isfinite(parent_angle) else np.full(len(df_img), np.nan)\n",
    "    child_global_dist = dist_hv_deg\n",
    "\n",
    "    # influence score:\n",
    "    # positive if child is closer to parent frame than to global H/V,\n",
    "    # normalized to [-1, +1]\n",
    "    #   +1: much closer to parent than to global\n",
    "    #    0: equal\n",
    "    #   -1: closer to global than parent\n",
    "    denom = np.maximum(child_parent_dist + child_global_dist, 1e-9)\n",
    "    local_influence = (child_global_dist - child_parent_dist) / denom\n",
    "    local_influence = np.clip(local_influence, -1.0, 1.0)\n",
    "\n",
    "    # (3) Orientation conflict index (\"crossfire\"):\n",
    "    # count strong axes that disagree with the dominant frame and with each other\n",
    "    # We'll define strong by axis strength score >= 0.35 (tunable)\n",
    "    strength = np.array([_strength_score(r) for _, r in df_img.iterrows()], dtype=float)\n",
    "    strong_mask = strength >= 0.35\n",
    "\n",
    "    strong_angles = ang[strong_mask]\n",
    "    # pairwise disagreement: count pairs with angular distance >= 25 deg\n",
    "    conflict_pairs = 0\n",
    "    total_pairs = 0\n",
    "    if len(strong_angles) >= 2:\n",
    "        for i in range(len(strong_angles)):\n",
    "            for j in range(i+1, len(strong_angles)):\n",
    "                d = _dist_to_axis(strong_angles[i], strong_angles[j])  # 0..90\n",
    "                total_pairs += 1\n",
    "                if d >= 25.0:\n",
    "                    conflict_pairs += 1\n",
    "    conflict_index = (conflict_pairs / total_pairs) if total_pairs > 0 else 0.0\n",
    "\n",
    "    # also \"dominant frame disagreement\": fraction of strong regions far from parent (>25deg)\n",
    "    if np.isfinite(parent_angle) and len(strong_angles) > 0:\n",
    "        d_parent = _dist_to_axis(strong_angles, parent_angle)\n",
    "        frac_disagree_parent = float(np.mean(d_parent >= 25.0))\n",
    "    else:\n",
    "        frac_disagree_parent = np.nan\n",
    "\n",
    "    # ---- save per-region\n",
    "    for i, r in df_img.iterrows():\n",
    "        rid = int(r[\"region_index\"])\n",
    "        rows_region.append({\n",
    "            \"split\": split,\n",
    "            \"image_id\": image_id,\n",
    "            \"region_index\": rid,\n",
    "\n",
    "            \"pca_angle_deg\": float(r[\"pca_angle_deg\"]),\n",
    "            \"dist_to_hv_deg\": float(dist_hv_deg[i]),\n",
    "            \"global_frame_align_01\": float(global_align[i]),\n",
    "\n",
    "            \"parent_region_index\": parent_rid,\n",
    "            \"parent_angle_deg\": (float(parent_angle) if np.isfinite(parent_angle) else np.nan),\n",
    "            \"child_parent_dist_deg\": (float(child_parent_dist[i]) if np.isfinite(child_parent_dist[i]) else np.nan),\n",
    "            \"child_global_dist_deg\": float(child_global_dist[i]),\n",
    "            \"local_frame_influence_m11\": (float(local_influence[i]) if np.isfinite(local_influence[i]) else np.nan),\n",
    "\n",
    "            \"axis_strength_01\": float(strength[i]),\n",
    "        })\n",
    "\n",
    "    # ---- per-image summary (weighted by saliency if available, else area_ratio)\n",
    "    if \"saliency\" in df_img.columns and np.isfinite(df_img[\"saliency\"].to_numpy(dtype=float)).any():\n",
    "        w = df_img[\"saliency\"].to_numpy(dtype=float)\n",
    "    else:\n",
    "        w = df_img[\"area_ratio\"].to_numpy(dtype=float) if \"area_ratio\" in df_img.columns else np.ones(len(df_img), dtype=float)\n",
    "    w = np.where(np.isfinite(w) & (w > 0), w, 0.0)\n",
    "    wsum = float(w.sum() + 1e-12)\n",
    "\n",
    "    # weighted global alignment\n",
    "    img_global_align = float(np.nansum(global_align * w) / wsum)\n",
    "\n",
    "    # weighted magnitude of local influence (how strong local frame effects are)\n",
    "    if np.isfinite(local_influence).any():\n",
    "        img_local_influence_abs = float(np.nansum(np.abs(local_influence) * w) / wsum)\n",
    "        img_local_influence_signed = float(np.nansum(local_influence * w) / wsum)\n",
    "    else:\n",
    "        img_local_influence_abs = np.nan\n",
    "        img_local_influence_signed = np.nan\n",
    "\n",
    "    rows_image.append({\n",
    "        \"split\": split,\n",
    "        \"image_id\": image_id,\n",
    "        \"parent_region_index\": parent_rid,\n",
    "        \"parent_angle_deg\": (float(parent_angle) if np.isfinite(parent_angle) else np.nan),\n",
    "\n",
    "        \"form1_global_frame_alignment_01\": img_global_align,\n",
    "        \"form1_local_frame_influence_abs_01\": img_local_influence_abs,     # 0..1\n",
    "        \"form1_local_frame_influence_signed\": img_local_influence_signed,  # -1..+1\n",
    "\n",
    "        \"form1_orientation_conflict_index_01\": float(conflict_index),      # 0..1\n",
    "        \"form1_frac_strong_disagree_parent_01\": frac_disagree_parent,\n",
    "\n",
    "        \"n_regions\": int(len(df_img)),\n",
    "        \"n_strong_axes\": int(np.sum(strong_mask)),\n",
    "        \"conflict_pairs\": int(conflict_pairs),\n",
    "        \"total_pairs\": int(total_pairs),\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:20.055617800Z",
     "start_time": "2025-12-28T09:26:18.969104400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - outputs\\form\\form1_orientation\\form1_region_orientation.csv (366, 12)\n",
      " - outputs\\form\\form1_orientation\\form1_image_orientation.csv (128, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  split                                           image_id  \\\n0  real     real\\images\\10pm_feeding_around_the_clock.webp   \n1  real                              real\\images\\11pm.webp   \n2  real                         real\\images\\12_4_7_10.webp   \n3  real                      real\\images\\Belly_breast.webp   \n4  real  real\\images\\Belly_breast_face_brain_placenta.webp   \n\n   parent_region_index  parent_angle_deg  form1_global_frame_alignment_01  \\\n0                   18         57.090095                         0.771307   \n1                    0         99.685522                         0.784766   \n2                    0         85.450598                         0.898902   \n3                    6         96.212515                         0.662090   \n4                    0          0.372193                         0.991729   \n\n   form1_local_frame_influence_abs_01  form1_local_frame_influence_signed  \\\n0                            0.762570                           -0.616509   \n1                            1.000000                            1.000000   \n2                            1.000000                            1.000000   \n3                            0.439827                            0.009007   \n4                            1.000000                            1.000000   \n\n   form1_orientation_conflict_index_01  form1_frac_strong_disagree_parent_01  \\\n0                             0.043956                              1.000000   \n1                             0.000000                                   NaN   \n2                             0.000000                                   NaN   \n3                             0.600000                              0.333333   \n4                             0.000000                                   NaN   \n\n   n_regions  n_strong_axes  conflict_pairs  total_pairs  \n0         19             14               4           91  \n1          1              0               0            0  \n2          1              0               0            0  \n3          7              6               9           15  \n4          1              0               0            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>split</th>\n      <th>image_id</th>\n      <th>parent_region_index</th>\n      <th>parent_angle_deg</th>\n      <th>form1_global_frame_alignment_01</th>\n      <th>form1_local_frame_influence_abs_01</th>\n      <th>form1_local_frame_influence_signed</th>\n      <th>form1_orientation_conflict_index_01</th>\n      <th>form1_frac_strong_disagree_parent_01</th>\n      <th>n_regions</th>\n      <th>n_strong_axes</th>\n      <th>conflict_pairs</th>\n      <th>total_pairs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>real</td>\n      <td>real\\images\\10pm_feeding_around_the_clock.webp</td>\n      <td>18</td>\n      <td>57.090095</td>\n      <td>0.771307</td>\n      <td>0.762570</td>\n      <td>-0.616509</td>\n      <td>0.043956</td>\n      <td>1.000000</td>\n      <td>19</td>\n      <td>14</td>\n      <td>4</td>\n      <td>91</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>real</td>\n      <td>real\\images\\11pm.webp</td>\n      <td>0</td>\n      <td>99.685522</td>\n      <td>0.784766</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>real</td>\n      <td>real\\images\\12_4_7_10.webp</td>\n      <td>0</td>\n      <td>85.450598</td>\n      <td>0.898902</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>real</td>\n      <td>real\\images\\Belly_breast.webp</td>\n      <td>6</td>\n      <td>96.212515</td>\n      <td>0.662090</td>\n      <td>0.439827</td>\n      <td>0.009007</td>\n      <td>0.600000</td>\n      <td>0.333333</td>\n      <td>7</td>\n      <td>6</td>\n      <td>9</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>real</td>\n      <td>real\\images\\Belly_breast_face_brain_placenta.webp</td>\n      <td>0</td>\n      <td>0.372193</td>\n      <td>0.991729</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_form1_regions = pd.DataFrame(rows_region)\n",
    "df_form1_images  = pd.DataFrame(rows_image)\n",
    "\n",
    "df_form1_regions.to_csv(os.path.join(OUT_FORM1_DIR, \"form1_region_orientation.csv\"), index=False)\n",
    "df_form1_images.to_csv(os.path.join(OUT_FORM1_DIR, \"form1_image_orientation.csv\"), index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", os.path.join(OUT_FORM1_DIR, \"form1_region_orientation.csv\"), df_form1_regions.shape)\n",
    "print(\" -\", os.path.join(OUT_FORM1_DIR, \"form1_image_orientation.csv\"),  df_form1_images.shape)\n",
    "\n",
    "display(df_form1_images.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:20.153224100Z",
     "start_time": "2025-12-28T09:26:20.065521700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Projection / foreshortening / â€œdeviation from the simpleâ€"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def _as_float_series(s):\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(float)\n",
    "\n",
    "def _wrap180(a):\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    return np.mod(a, 180.0)\n",
    "\n",
    "def _dist_to_axis(a_deg, b_deg):\n",
    "    a = np.asarray(a_deg, dtype=float)\n",
    "    b = np.asarray(b_deg, dtype=float)\n",
    "    d = np.abs(a - b)\n",
    "    d = np.minimum(d, 180.0 - d)\n",
    "    return d  # 0..90\n",
    "\n",
    "def _min_dist_to_hv(a_deg):\n",
    "    a = np.asarray(a_deg, dtype=float)\n",
    "    d0  = _dist_to_axis(a, 0.0)\n",
    "    d90 = _dist_to_axis(a, 90.0)\n",
    "    return np.minimum(d0, d90)  # 0..45\n",
    "\n",
    "def _strength_01_from_eigratio(eig_ratio):\n",
    "    # log1p saturation to [0,1]\n",
    "    eig = np.asarray(eig_ratio, dtype=float)\n",
    "    v = np.log1p(np.maximum(eig, 0.0))\n",
    "    return np.clip(v / 4.0, 0.0, 1.0)\n",
    "\n",
    "def _weighted_mean(x, w):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    w = np.asarray(w, dtype=float)\n",
    "    m = np.isfinite(x) & np.isfinite(w) & (w > 0)\n",
    "    if m.sum() == 0:\n",
    "        return np.nan\n",
    "    return float(np.sum(x[m] * w[m]) / (np.sum(w[m]) + 1e-12))\n",
    "\n",
    "def _norm01_minmax(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    m = np.isfinite(x)\n",
    "    if m.sum() == 0:\n",
    "        return x * np.nan\n",
    "    mn, mx = np.nanmin(x[m]), np.nanmax(x[m])\n",
    "    if not np.isfinite(mn) or not np.isfinite(mx) or (mx - mn) < 1e-12:\n",
    "        return np.zeros_like(x, dtype=float)\n",
    "    return (x - mn) / (mx - mn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:20.185492Z",
     "start_time": "2025-12-28T09:26:20.171563Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Affine Distortion Score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def form2_affine_distortion_region(df_img):\n",
    "    eig = _as_float_series(df_img.get(\"pca_eig_ratio\", np.nan))\n",
    "    sym = _as_float_series(df_img.get(\"symmetry_pca\", np.nan))\n",
    "\n",
    "    # anisotropy: 0 if eig_ratio==1, grows as eig_ratio increases\n",
    "    # log compress then map to [0,1] with soft saturation\n",
    "    aniso = np.log1p(np.maximum(eig, 1e-9))     # >=0\n",
    "    aniso01 = np.clip(aniso / 4.0, 0.0, 1.0)\n",
    "\n",
    "    # symmetry loss: 0 if sym==1, 1 if sym==0\n",
    "    sym_loss = np.clip(1.0 - sym, 0.0, 1.0)\n",
    "\n",
    "    # combine (tunable weights)\n",
    "    # higher = more \"projection-like distortion\"\n",
    "    distortion = 0.6 * aniso01 + 0.4 * sym_loss\n",
    "    return distortion.to_numpy(dtype=float)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:20.305546800Z",
     "start_time": "2025-12-28T09:26:20.193599Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Symmetry-axis Degradation under tilt / weak-stimulus sweep (per-region)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def form2_symmetry_degradation_region(df_img,\n",
    "                                      sym_strong_thr=0.65,\n",
    "                                      use_tilt=True,\n",
    "                                      use_weak_stim=True):\n",
    "    sym = _as_float_series(df_img.get(\"symmetry_pca\", np.nan)).to_numpy(dtype=float)\n",
    "\n",
    "    # Only measure degradation if symmetry is strong enough; else set NaN (not applicable)\n",
    "    applicable = np.isfinite(sym) & (sym >= float(sym_strong_thr))\n",
    "\n",
    "    deg_terms = []\n",
    "\n",
    "    if use_tilt and (\"pca_angle_deg\" in df_img.columns):\n",
    "        ang = _as_float_series(df_img[\"pca_angle_deg\"]).to_numpy(dtype=float)\n",
    "        tilt01 = np.clip(_min_dist_to_hv(ang) / 45.0, 0.0, 1.0)  # 0..1\n",
    "        deg_terms.append(tilt01)\n",
    "\n",
    "    if use_weak_stim and (\"stability_mask_range\" in df_img.columns):\n",
    "        rngv = _as_float_series(df_img[\"stability_mask_range\"]).to_numpy(dtype=float)\n",
    "        # normalize per-image to keep scale stable\n",
    "        rng01 = _norm01_minmax(rngv)\n",
    "        deg_terms.append(np.clip(rng01, 0.0, 1.0))\n",
    "\n",
    "    if use_weak_stim and (\"stability_mask_mean\" in df_img.columns):\n",
    "        meanv = _as_float_series(df_img[\"stability_mask_mean\"]).to_numpy(dtype=float)\n",
    "        instab01 = np.clip(1.0 - meanv, 0.0, 1.0)  # lower stability => higher degradation\n",
    "        deg_terms.append(instab01)\n",
    "\n",
    "    if len(deg_terms) == 0:\n",
    "        out = np.full(len(df_img), np.nan, dtype=float)\n",
    "        return out\n",
    "\n",
    "    # average the available degradation terms\n",
    "    deg = np.nanmean(np.stack(deg_terms, axis=0), axis=0)\n",
    "\n",
    "    # gate by applicability: non-strong symmetry => NaN\n",
    "    out = np.full(len(df_img), np.nan, dtype=float)\n",
    "    out[applicable] = np.clip(deg[applicable], 0.0, 1.0)\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:20.341557400Z",
     "start_time": "2025-12-28T09:26:20.215573900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Viewpoint ambiguity proxy (per-image)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def form2_viewpoint_ambiguity_image(df_img,\n",
    "                                   strong_thr=0.35,\n",
    "                                   use_angles=True):\n",
    "    eig = _as_float_series(df_img.get(\"pca_eig_ratio\", np.nan)).to_numpy(dtype=float)\n",
    "    strength = _strength_01_from_eigratio(eig)  # 0..1\n",
    "    strong = np.isfinite(strength) & (strength >= float(strong_thr))\n",
    "\n",
    "    s = strength[strong]\n",
    "    if len(s) < 2:\n",
    "        return 0.0, int(np.sum(strong)), np.nan  # ambiguity, n_strong, angle_spread\n",
    "\n",
    "    # similar-strength competition: if top1 ~= top2 => high ambiguity\n",
    "    s_sorted = np.sort(s)[::-1]\n",
    "    top1, top2 = float(s_sorted[0]), float(s_sorted[1])\n",
    "    similar01 = np.clip(1.0 - ((top1 - top2) / (top1 + 1e-9)), 0.0, 1.0)\n",
    "\n",
    "    angle_spread01 = np.nan\n",
    "    if use_angles and (\"pca_angle_deg\" in df_img.columns):\n",
    "        ang = _as_float_series(df_img[\"pca_angle_deg\"]).to_numpy(dtype=float)[strong]\n",
    "        # mean pairwise distance normalized by 90\n",
    "        if len(ang) >= 2:\n",
    "            dsum = 0.0\n",
    "            cnt = 0\n",
    "            for i in range(len(ang)):\n",
    "                for j in range(i+1, len(ang)):\n",
    "                    dsum += float(_dist_to_axis(ang[i], ang[j]))\n",
    "                    cnt += 1\n",
    "            mean_d = (dsum / cnt) if cnt > 0 else 0.0\n",
    "            angle_spread01 = np.clip(mean_d / 90.0, 0.0, 1.0)\n",
    "\n",
    "    # ambiguity combines \"similar strengths\" + (optional) angular diversity\n",
    "    if np.isfinite(angle_spread01):\n",
    "        amb = float(0.6 * similar01 + 0.4 * angle_spread01)\n",
    "    else:\n",
    "        amb = float(similar01)\n",
    "\n",
    "    return amb, int(np.sum(strong)), angle_spread01"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:20.403336100Z",
     "start_time": "2025-12-28T09:26:20.243798100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Form-2 region table: (366, 7)\n",
      "Form-2 image table : (128, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  split                                           image_id  \\\n0  real     real\\images\\10pm_feeding_around_the_clock.webp   \n1  real                              real\\images\\11pm.webp   \n2  real                         real\\images\\12_4_7_10.webp   \n3  real                      real\\images\\Belly_breast.webp   \n4  real  real\\images\\Belly_breast_face_brain_placenta.webp   \n5  real          real\\images\\Bellyscape_and_plumb_bob.webp   \n6  real  real\\images\\Birth_perspective_from_above_and_b...   \n7  real              real\\images\\Blue_0_with_red_halo.webp   \n8  real                          real\\images\\Blue_Nip.webp   \n9  real                          real\\images\\Blue_eye.webp   \n\n   form2_affine_distortion_index_01  form2_symmetry_degradation_index_01  \\\n0                          0.529536                             0.177887   \n1                          0.458337                                  NaN   \n2                          0.132365                             0.035642   \n3                          0.664815                                  NaN   \n4                          0.120302                             0.008271   \n5                          0.149785                             0.004707   \n6                          0.166507                             0.258381   \n7                          0.153609                             0.002657   \n8                          0.578118                                  NaN   \n9                          0.445482                                  NaN   \n\n   form2_viewpoint_ambiguity_index_01  n_regions  n_strong_axes  \\\n0                            0.601091         19             14   \n1                            0.000000          1              0   \n2                            0.000000          1              0   \n3                            0.707920          7              6   \n4                            0.000000          1              0   \n5                            0.000000          1              0   \n6                            0.000000          1              0   \n7                            0.000000          1              0   \n8                            0.000000          2              1   \n9                            0.000000          1              0   \n\n   form2_angle_spread_01  \n0               0.119052  \n1                    NaN  \n2                    NaN  \n3               0.422198  \n4                    NaN  \n5                    NaN  \n6                    NaN  \n7                    NaN  \n8                    NaN  \n9                    NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>split</th>\n      <th>image_id</th>\n      <th>form2_affine_distortion_index_01</th>\n      <th>form2_symmetry_degradation_index_01</th>\n      <th>form2_viewpoint_ambiguity_index_01</th>\n      <th>n_regions</th>\n      <th>n_strong_axes</th>\n      <th>form2_angle_spread_01</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>real</td>\n      <td>real\\images\\10pm_feeding_around_the_clock.webp</td>\n      <td>0.529536</td>\n      <td>0.177887</td>\n      <td>0.601091</td>\n      <td>19</td>\n      <td>14</td>\n      <td>0.119052</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>real</td>\n      <td>real\\images\\11pm.webp</td>\n      <td>0.458337</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>real</td>\n      <td>real\\images\\12_4_7_10.webp</td>\n      <td>0.132365</td>\n      <td>0.035642</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>real</td>\n      <td>real\\images\\Belly_breast.webp</td>\n      <td>0.664815</td>\n      <td>NaN</td>\n      <td>0.707920</td>\n      <td>7</td>\n      <td>6</td>\n      <td>0.422198</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>real</td>\n      <td>real\\images\\Belly_breast_face_brain_placenta.webp</td>\n      <td>0.120302</td>\n      <td>0.008271</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>real</td>\n      <td>real\\images\\Bellyscape_and_plumb_bob.webp</td>\n      <td>0.149785</td>\n      <td>0.004707</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>real</td>\n      <td>real\\images\\Birth_perspective_from_above_and_b...</td>\n      <td>0.166507</td>\n      <td>0.258381</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>real</td>\n      <td>real\\images\\Blue_0_with_red_halo.webp</td>\n      <td>0.153609</td>\n      <td>0.002657</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>real</td>\n      <td>real\\images\\Blue_Nip.webp</td>\n      <td>0.578118</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>real</td>\n      <td>real\\images\\Blue_eye.webp</td>\n      <td>0.445482</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_region = []\n",
    "rows_image  = []\n",
    "\n",
    "for (split, image_id), g in df_regions.groupby([\"split\", \"image_id\"], sort=False):\n",
    "    df_img = g.copy().reset_index(drop=True)\n",
    "\n",
    "    # weights for aggregations\n",
    "    if \"saliency\" in df_img.columns and np.isfinite(_as_float_series(df_img[\"saliency\"]).to_numpy()).any():\n",
    "        w = _as_float_series(df_img[\"saliency\"]).to_numpy(dtype=float)\n",
    "    elif \"area_ratio\" in df_img.columns and np.isfinite(_as_float_series(df_img[\"area_ratio\"]).to_numpy()).any():\n",
    "        w = _as_float_series(df_img[\"area_ratio\"]).to_numpy(dtype=float)\n",
    "    else:\n",
    "        w = np.ones(len(df_img), dtype=float)\n",
    "    w = np.where(np.isfinite(w) & (w > 0), w, 0.0)\n",
    "\n",
    "    # (1) Affine distortion (per-region + per-image index)\n",
    "    aff_dist = form2_affine_distortion_region(df_img)              # 0..1\n",
    "    img_aff_dist = _weighted_mean(aff_dist, w)                     # 0..1\n",
    "\n",
    "    # (2) Symmetry degradation (per-region + per-image index)\n",
    "    sym_deg = form2_symmetry_degradation_region(df_img)            # 0..1 for applicable regions, else NaN\n",
    "    # aggregate: weighted mean over applicable\n",
    "    img_sym_deg = _weighted_mean(sym_deg, w)                       # 0..1 or NaN if none applicable\n",
    "\n",
    "    # (3) Viewpoint ambiguity (per-image index)\n",
    "    img_amb, n_strong, angle_spread01 = form2_viewpoint_ambiguity_image(df_img)\n",
    "\n",
    "    # save per-region rows\n",
    "    for i, r in df_img.iterrows():\n",
    "        rows_region.append({\n",
    "            \"split\": split,\n",
    "            \"image_id\": image_id,\n",
    "            \"region_index\": int(r[\"region_index\"]),\n",
    "\n",
    "            # helpful carry-through\n",
    "            \"pca_eig_ratio\": float(pd.to_numeric(r.get(\"pca_eig_ratio\", np.nan), errors=\"coerce\")),\n",
    "            \"symmetry_pca\": float(pd.to_numeric(r.get(\"symmetry_pca\", np.nan), errors=\"coerce\")),\n",
    "\n",
    "            # FORM-2 region measures\n",
    "            \"form2_affine_distortion_01\": float(aff_dist[i]) if np.isfinite(aff_dist[i]) else np.nan,\n",
    "            \"form2_symmetry_degradation_01\": float(sym_deg[i]) if np.isfinite(sym_deg[i]) else np.nan,\n",
    "        })\n",
    "\n",
    "    # save per-image indices\n",
    "    rows_image.append({\n",
    "        \"split\": split,\n",
    "        \"image_id\": image_id,\n",
    "\n",
    "        # FORM-2 indices (report these)\n",
    "        \"form2_affine_distortion_index_01\": float(img_aff_dist) if np.isfinite(img_aff_dist) else np.nan,\n",
    "        \"form2_symmetry_degradation_index_01\": float(img_sym_deg) if np.isfinite(img_sym_deg) else np.nan,\n",
    "        \"form2_viewpoint_ambiguity_index_01\": float(img_amb),\n",
    "\n",
    "        # diagnostics\n",
    "        \"n_regions\": int(len(df_img)),\n",
    "        \"n_strong_axes\": int(n_strong),\n",
    "        \"form2_angle_spread_01\": float(angle_spread01) if np.isfinite(angle_spread01) else np.nan,\n",
    "    })\n",
    "\n",
    "df_form2_region = pd.DataFrame(rows_region)\n",
    "df_form2_image  = pd.DataFrame(rows_image)\n",
    "\n",
    "# Example save paths (edit as needed)\n",
    "df_form2_region.to_csv(r\"outputs/form2_region.csv\", index=False)\n",
    "df_form2_image.to_csv(r\"outputs/form2_image.csv\", index=False)\n",
    "\n",
    "print(\"Form-2 region table:\", df_form2_region.shape)\n",
    "print(\"Form-2 image table :\", df_form2_image.shape)\n",
    "df_form2_image.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:21.424041100Z",
     "start_time": "2025-12-28T09:26:20.269408900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Overlapping & depth-order cues"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "REGION_CSV = r\"F:\\New Dissertation - Image Generation\\POC\\outputs\\shape_region_features.csv\"\n",
    "MASK_ROOT  = Path(r\"F:\\New Dissertation - Image Generation\\POC\\outputs\\form3_masks\")  # must match export path\n",
    "OUT_DIR    = Path(r\"outputs\\form\\form3\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# tuning\n",
    "MIN_OVERLAP_IOU = 0.002       # very small overlap is enough to flag\n",
    "DILATE_OVERLAP  = 1           # pixels: allow near-overlap\n",
    "TJ_WIN          = 7           # local window for polarity\n",
    "TJ_MIN_SUPPORT  = 3           # min pixels supporting bar direction\n",
    "MAX_TJ_PER_PAIR = 200         # cap to avoid blowups on noisy images"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:21.424041100Z",
     "start_time": "2025-12-28T09:26:21.424041100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helpers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def sanitize_path(s: str) -> str:\n",
    "    s = s.replace(\"\\\\\", \"/\")\n",
    "    return s.replace(\":\", \"\").replace(\"/\", \"__\")\n",
    "\n",
    "def load_masks(split, image_id):\n",
    "    p = MASK_ROOT / split / sanitize_path(image_id) / \"regions.npz\"\n",
    "    if not p.exists():\n",
    "        return None\n",
    "    z = np.load(str(p), allow_pickle=True)\n",
    "    masks = z[\"masks\"].astype(np.uint8)  # (n,H,W)\n",
    "    return masks\n",
    "\n",
    "def boundary_from_mask(m01):\n",
    "    m = (m01 > 0).astype(np.uint8) * 255\n",
    "    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "    er = cv2.erode(m, k, iterations=1)\n",
    "    b = ((m > 0) & (er == 0)).astype(np.uint8)\n",
    "    return b\n",
    "\n",
    "def edge_junctions_from_edges(Eb01):\n",
    "    \"\"\"\n",
    "    Approximate edge-junction pixels from binary edge map using 8-neighbor degree.\n",
    "    T-junction-like points tend to have degree>=3.\n",
    "    \"\"\"\n",
    "    e = (Eb01 > 0).astype(np.uint8)\n",
    "    # count neighbors via convolution\n",
    "    kernel = np.array([[1,1,1],[1,0,1],[1,1,1]], dtype=np.uint8)\n",
    "    deg = cv2.filter2D(e, -1, kernel, borderType=cv2.BORDER_CONSTANT)\n",
    "    # junction candidates: edge pixel with >=3 neighbors\n",
    "    j = ((e > 0) & (deg >= 3)).astype(np.uint8)\n",
    "    return j\n",
    "\n",
    "def overlap_iou(a, b):\n",
    "    a = (a > 0); b = (b > 0)\n",
    "    inter = np.logical_and(a,b).sum()\n",
    "    union = np.logical_or(a,b).sum()\n",
    "    return float(inter) / float(union + 1e-12)\n",
    "\n",
    "def dilate01(m01, k=1):\n",
    "    if k <= 0:\n",
    "        return (m01 > 0).astype(np.uint8)\n",
    "    ker = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*k+1, 2*k+1))\n",
    "    return (cv2.dilate((m01>0).astype(np.uint8), ker, iterations=1) > 0).astype(np.uint8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:21.599383300Z",
     "start_time": "2025-12-28T09:26:21.424041100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def local_polarity_vote(j_pt_rc, bA, bB, Eb, win=7):\n",
    "    \"\"\"\n",
    "    Decide occluder at a junction point using a simple polarity heuristic:\n",
    "    - Look in a window around the junction\n",
    "    - Count edge continuity on each region boundary\n",
    "    - The region whose boundary is more continuous through the junction is treated as 'occluder' (bar),\n",
    "      the one that terminates is treated as 'occluded' (stem).\n",
    "    Returns:\n",
    "      occluder (0/1) where 0->A occludes B, 1->B occludes A, or None if ambiguous.\n",
    "    \"\"\"\n",
    "    r, c = j_pt_rc\n",
    "    H, W = Eb.shape\n",
    "    half = win//2\n",
    "    r0 = max(0, r-half); r1 = min(H, r+half+1)\n",
    "    c0 = max(0, c-half); c1 = min(W, c+half+1)\n",
    "\n",
    "    # local edge support on boundaries\n",
    "    Eb_loc = Eb[r0:r1, c0:c1] > 0\n",
    "    a_loc  = (bA[r0:r1, c0:c1] > 0) & Eb_loc\n",
    "    b_loc  = (bB[r0:r1, c0:c1] > 0) & Eb_loc\n",
    "\n",
    "    sa = int(a_loc.sum())\n",
    "    sb = int(b_loc.sum())\n",
    "\n",
    "    # if both tiny -> can't decide\n",
    "    if sa < TJ_MIN_SUPPORT and sb < TJ_MIN_SUPPORT:\n",
    "        return None\n",
    "\n",
    "    # if one much larger -> that one likely continues (bar)\n",
    "    if sa >= sb + 2:\n",
    "        return 0  # A occludes B\n",
    "    if sb >= sa + 2:\n",
    "        return 1  # B occludes A\n",
    "\n",
    "    return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:21.631304100Z",
     "start_time": "2025-12-28T09:26:21.511424400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def build_depth_graph_for_image(split, image_id, gdf, masks):\n",
    "    \"\"\"\n",
    "    Produces:\n",
    "      per_region rows (dominance stats)\n",
    "      per_pair edges (occlusion edges + overlap edges)\n",
    "      per_image summary row\n",
    "    \"\"\"\n",
    "    n = masks.shape[0]\n",
    "    H, W = masks.shape[1], masks.shape[2]\n",
    "\n",
    "    # optional: if you still have Eb saved somewhere, great.\n",
    "    # If not, we approximate an edge map from region boundaries (works OK for occlusion evidence).\n",
    "    boundaries = [boundary_from_mask(masks[i]) for i in range(n)]\n",
    "    Eb = np.zeros((H,W), np.uint8)\n",
    "    for b in boundaries:\n",
    "        Eb = np.maximum(Eb, b)\n",
    "    junctions = edge_junctions_from_edges(Eb)\n",
    "\n",
    "    # overlap candidates\n",
    "    rows_pair = []\n",
    "    occl_counts = np.zeros(n, dtype=int)\n",
    "    occd_counts = np.zeros(n, dtype=int)\n",
    "\n",
    "    # region strength weights (for dominance weighting if needed)\n",
    "    if \"saliency\" in gdf.columns and np.isfinite(pd.to_numeric(gdf[\"saliency\"], errors=\"coerce\")).any():\n",
    "        w = pd.to_numeric(gdf[\"saliency\"], errors=\"coerce\").to_numpy(dtype=float)\n",
    "    else:\n",
    "        w = pd.to_numeric(gdf.get(\"area_ratio\", pd.Series(np.ones(n))), errors=\"coerce\").to_numpy(dtype=float)\n",
    "    w = np.where(np.isfinite(w) & (w>0), w, 0.0)\n",
    "\n",
    "    # Pairwise overlap + occlusion\n",
    "    for i in range(n):\n",
    "        Ai = masks[i]\n",
    "        bA = boundaries[i]\n",
    "        for j in range(i+1, n):\n",
    "            Bj = masks[j]\n",
    "            bB = boundaries[j]\n",
    "\n",
    "            # ---- (1) overlap detection ----\n",
    "            Ai2 = dilate01(Ai, DILATE_OVERLAP)\n",
    "            Bj2 = dilate01(Bj, DILATE_OVERLAP)\n",
    "            iou = overlap_iou(Ai2, Bj2)\n",
    "\n",
    "            is_overlap = (iou >= MIN_OVERLAP_IOU)\n",
    "\n",
    "            # ---- (2) occlusion evidence: T-junctions near both boundaries ----\n",
    "            # candidate junction pixels close to both boundaries\n",
    "            near = (junctions > 0) & ((cv2.dilate(bA, np.ones((3,3),np.uint8))>0) & (cv2.dilate(bB, np.ones((3,3),np.uint8))>0))\n",
    "            pts = np.argwhere(near)\n",
    "\n",
    "            # polarity voting\n",
    "            votes_A_over_B = 0\n",
    "            votes_B_over_A = 0\n",
    "            used = 0\n",
    "\n",
    "            if len(pts) > 0:\n",
    "                # cap for safety\n",
    "                if len(pts) > MAX_TJ_PER_PAIR:\n",
    "                    pts = pts[np.random.choice(len(pts), MAX_TJ_PER_PAIR, replace=False)]\n",
    "                for (r,c) in pts:\n",
    "                    v = local_polarity_vote((int(r),int(c)), bA, bB, Eb, win=TJ_WIN)\n",
    "                    if v == 0: votes_A_over_B += 1\n",
    "                    elif v == 1: votes_B_over_A += 1\n",
    "                    used += 1\n",
    "\n",
    "            # infer direction if enough imbalance\n",
    "            occl_dir = None\n",
    "            if (votes_A_over_B + votes_B_over_A) >= 3:\n",
    "                if votes_A_over_B >= votes_B_over_A + 2:\n",
    "                    occl_dir = (i, j)  # i occludes j\n",
    "                elif votes_B_over_A >= votes_A_over_B + 2:\n",
    "                    occl_dir = (j, i)  # j occludes i\n",
    "\n",
    "            if occl_dir is not None:\n",
    "                occl_counts[occl_dir[0]] += 1\n",
    "                occd_counts[occl_dir[1]] += 1\n",
    "\n",
    "            rows_pair.append({\n",
    "                \"split\": split,\n",
    "                \"image_id\": image_id,\n",
    "                \"i\": i, \"j\": j,\n",
    "                \"overlap_iou\": float(iou),\n",
    "                \"is_overlap\": int(is_overlap),\n",
    "\n",
    "                \"tj_points\": int(len(pts)),\n",
    "                \"votes_i_over_j\": int(votes_A_over_B),\n",
    "                \"votes_j_over_i\": int(votes_B_over_A),\n",
    "\n",
    "                \"occluder\": int(occl_dir[0]) if occl_dir else np.nan,\n",
    "                \"occluded\": int(occl_dir[1]) if occl_dir else np.nan,\n",
    "                \"has_occlusion\": int(occl_dir is not None),\n",
    "            })\n",
    "\n",
    "    # ---- (3) depth-order graph ----\n",
    "    G = nx.DiGraph()\n",
    "    for rid in range(n):\n",
    "        G.add_node(rid, weight=float(w[rid]) if rid < len(w) else 1.0)\n",
    "\n",
    "    for row in rows_pair:\n",
    "        if row[\"has_occlusion\"] == 1:\n",
    "            a = int(row[\"occluder\"]); b = int(row[\"occluded\"])\n",
    "            if G.has_edge(a,b):\n",
    "                G[a][b][\"support\"] += 1\n",
    "            else:\n",
    "                G.add_edge(a,b, support=1)\n",
    "\n",
    "    # ---- (4) dominance / subservience per region ----\n",
    "    rows_region = []\n",
    "    for rid in range(n):\n",
    "        oc = int(occl_counts[rid])\n",
    "        od = int(occd_counts[rid])\n",
    "        denom = oc + od\n",
    "        dom = float(oc / denom) if denom > 0 else np.nan  # undefined if no evidence\n",
    "        rows_region.append({\n",
    "            \"split\": split,\n",
    "            \"image_id\": image_id,\n",
    "            \"region_index\": int(rid),\n",
    "            \"occludes_count\": oc,\n",
    "            \"occluded_count\": od,\n",
    "            \"dominance_index_01\": dom,  # 0..1\n",
    "        })\n",
    "\n",
    "    # image summary\n",
    "    total_occl = int(np.sum(occl_counts))\n",
    "    denom_all = int(np.sum(occl_counts + occd_counts))\n",
    "    img_dom = float(np.sum(occl_counts) / denom_all) if denom_all > 0 else np.nan\n",
    "\n",
    "    rows_image = [{\n",
    "        \"split\": split,\n",
    "        \"image_id\": image_id,\n",
    "        \"n_regions\": int(n),\n",
    "        \"overlap_pairs\": int(sum(1 for r in rows_pair if r[\"is_overlap\"]==1)),\n",
    "        \"occlusion_edges\": int(G.number_of_edges()),\n",
    "        \"total_occlusion_votes\": int(total_occl),\n",
    "        \"form3_dominance_subservience_index_01\": img_dom,\n",
    "    }]\n",
    "\n",
    "    return rows_region, rows_pair, rows_image, G\n",
    "\n",
    "# ----------------------------\n",
    "# RUN ALL IMAGES\n",
    "# ----------------------------\n",
    "df_regions = pd.read_csv(REGION_CSV)\n",
    "\n",
    "all_region = []\n",
    "all_pair   = []\n",
    "all_image  = []\n",
    "\n",
    "graphs = {}  # optional: keep in memory\n",
    "\n",
    "for (split, image_id), gdf in df_regions.groupby([\"split\",\"image_id\"], sort=False):\n",
    "    masks = load_masks(split, image_id)\n",
    "    if masks is None:\n",
    "        print(\"Missing masks for:\", split, image_id)\n",
    "        continue\n",
    "\n",
    "    r_rows, p_rows, i_rows, G = build_depth_graph_for_image(split, image_id, gdf, masks)\n",
    "\n",
    "    all_region.extend(r_rows)\n",
    "    all_pair.extend(p_rows)\n",
    "    all_image.extend(i_rows)\n",
    "    graphs[(split, image_id)] = G"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:29.331357600Z",
     "start_time": "2025-12-28T09:26:21.551625Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "  outputs\\form\\form3\\form3_region.csv (366, 6)\n",
      "  outputs\\form\\form3\\form3_pairs.csv (769, 12)\n",
      "  outputs\\form\\form3\\form3_image.csv (128, 7)\n"
     ]
    }
   ],
   "source": [
    "df_form3_region = pd.DataFrame(all_region)\n",
    "df_form3_pair   = pd.DataFrame(all_pair)\n",
    "df_form3_image  = pd.DataFrame(all_image)\n",
    "\n",
    "df_form3_region.to_csv(OUT_DIR / \"form3_region.csv\", index=False)\n",
    "df_form3_pair.to_csv(OUT_DIR / \"form3_pairs.csv\", index=False)\n",
    "df_form3_image.to_csv(OUT_DIR / \"form3_image.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" \", OUT_DIR / \"form3_region.csv\", df_form3_region.shape)\n",
    "print(\" \", OUT_DIR / \"form3_pairs.csv\", df_form3_pair.shape)\n",
    "print(\" \", OUT_DIR / \"form3_image.csv\", df_form3_image.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:29.353228100Z",
     "start_time": "2025-12-28T09:26:29.331357600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Completion & Continuity under Disruption"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"data\")  # expects data/real and data/generated\n",
    "OUT_DIR = Path(\"outputs/form4\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SIGMAS = (1, 2, 4)\n",
    "EDGE_PERCENTILE = 85.0\n",
    "MIN_AREA_RATIO = 0.00005\n",
    "CLOSE_K_RATIO = 0.004\n",
    "CLOSE_ITERS = 1\n",
    "\n",
    "# Linking hyperparams (tunable)\n",
    "MAX_LINK_DIST_FRAC = 0.08   # max endpoint distance as fraction of image diagonal\n",
    "NBR_WIN = 9                 # local neighborhood for tangent estimate\n",
    "COLLIN_W = 0.55\n",
    "DIST_W   = 0.25\n",
    "EDGE_W   = 0.20\n",
    "\n",
    "# For plausibility\n",
    "TOP_LINKS_PER_IMAGE = 12    # evaluate strongest K candidate links\n",
    "PLAUS_ENDPT_GAIN_W  = 0.7\n",
    "PLAUS_TURN_W        = 0.3\n",
    "\n",
    "# For amputation risk\n",
    "CURV_WIN = 11               # curvature window on contour\n",
    "CURV_THRESH = 0.35          # higher => more â€œcorner/concavityâ€\n",
    "STUMP_CLOSE_EDGE_FRAC = 0.03"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:29.421781600Z",
     "start_time": "2025-12-28T09:26:29.351643600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Basic Image + Edge Pipe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def read_image_bgr(path: str) -> np.ndarray:\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(path)\n",
    "    if img.ndim == 2:\n",
    "        return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    if img.shape[2] == 4:\n",
    "        bgr = img[:, :, :3].astype(np.float32)\n",
    "        alpha = img[:, :, 3:4].astype(np.float32) / 255.0\n",
    "        white = np.full_like(bgr, 255.0, dtype=np.float32)\n",
    "        comp = bgr * alpha + white * (1.0 - alpha)\n",
    "        return np.clip(comp, 0, 255).astype(np.uint8)\n",
    "    return img[:, :, :3]\n",
    "\n",
    "def preprocess_gray01(path: str) -> np.ndarray:\n",
    "    bgr = read_image_bgr(path)\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0\n",
    "    # mild denoise (same spirit as your pipeline)\n",
    "    gray = cv2.GaussianBlur(gray, (0,0), 1.2)\n",
    "    return gray\n",
    "\n",
    "def gaussian_blur(gray_f: np.ndarray, sigma: float) -> np.ndarray:\n",
    "    return cv2.GaussianBlur(gray_f, (0, 0), sigmaX=sigma, sigmaY=sigma)\n",
    "\n",
    "def sobel_magnitude(gray_f: np.ndarray) -> np.ndarray:\n",
    "    gx = cv2.Sobel(gray_f, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(gray_f, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    return cv2.magnitude(gx, gy)\n",
    "\n",
    "def normalize_01(x: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "    x = x.astype(np.float32)\n",
    "    mn, mx = float(np.min(x)), float(np.max(x))\n",
    "    return (x - mn) / (mx - mn + eps)\n",
    "\n",
    "def multiscale_edge_strength(gray_f: np.ndarray, sigmas=(1,2,4)):\n",
    "    mags = []\n",
    "    for s in sigmas:\n",
    "        sm = gaussian_blur(gray_f, float(s))\n",
    "        mag = sobel_magnitude(sm)\n",
    "        mags.append(normalize_01(mag))\n",
    "    E = np.max(np.stack(mags, axis=0), axis=0)\n",
    "    return E\n",
    "\n",
    "def remove_small_components(binary01: np.ndarray, min_area_px: int) -> np.ndarray:\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(binary01.astype(np.uint8), connectivity=8)\n",
    "    out = np.zeros_like(binary01, dtype=np.uint8)\n",
    "    for i in range(1, num):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_area_px:\n",
    "            out[labels == i] = 1\n",
    "    return out\n",
    "\n",
    "def morph_close(binary01: np.ndarray, k: int, iters: int) -> np.ndarray:\n",
    "    if k % 2 == 0: k += 1\n",
    "    k = max(3, int(k))\n",
    "    ker = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k,k))\n",
    "    closed = cv2.morphologyEx((binary01*255).astype(np.uint8), cv2.MORPH_CLOSE, ker, iterations=int(iters))\n",
    "    return (closed > 0).astype(np.uint8)\n",
    "\n",
    "def make_edge_maps(gray01: np.ndarray):\n",
    "    H, W = gray01.shape\n",
    "    E = multiscale_edge_strength(gray01, sigmas=SIGMAS)\n",
    "    thr = np.percentile(E, EDGE_PERCENTILE)\n",
    "    Eb = (E >= thr).astype(np.uint8)\n",
    "\n",
    "    min_area_px = int(max(10, round(MIN_AREA_RATIO * H * W)))\n",
    "    Eb = remove_small_components(Eb, min_area_px=min_area_px)\n",
    "\n",
    "    k = int(max(3, round(CLOSE_K_RATIO * min(H, W))))\n",
    "    Eb = morph_close(Eb, k=k, iters=CLOSE_ITERS)\n",
    "\n",
    "    return E, Eb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:29.421781600Z",
     "start_time": "2025-12-28T09:26:29.383482600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Edge Skeleton + Endpoints"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def zhang_suen_thinning(bin01: np.ndarray) -> np.ndarray:\n",
    "    img = bin01.copy().astype(np.uint8)\n",
    "    img[img > 0] = 1\n",
    "    H, W = img.shape\n",
    "\n",
    "    def neighbors(x, y):\n",
    "        return [img[x-1,y], img[x-1,y+1], img[x,y+1], img[x+1,y+1],\n",
    "                img[x+1,y], img[x+1,y-1], img[x,y-1], img[x-1,y-1]]\n",
    "\n",
    "    def transitions(nb):\n",
    "        n = nb + [nb[0]]\n",
    "        return sum((n[i] == 0 and n[i+1] == 1) for i in range(8))\n",
    "\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        to_del = []\n",
    "        for x in range(1, H-1):\n",
    "            for y in range(1, W-1):\n",
    "                if img[x,y] != 1:\n",
    "                    continue\n",
    "                nb = neighbors(x,y)\n",
    "                B = sum(nb)\n",
    "                A = transitions(nb)\n",
    "                if 2 <= B <= 6 and A == 1 and (nb[0]*nb[2]*nb[4] == 0) and (nb[2]*nb[4]*nb[6] == 0):\n",
    "                    to_del.append((x,y))\n",
    "        if to_del:\n",
    "            for x,y in to_del: img[x,y] = 0\n",
    "            changed = True\n",
    "\n",
    "        to_del = []\n",
    "        for x in range(1, H-1):\n",
    "            for y in range(1, W-1):\n",
    "                if img[x,y] != 1:\n",
    "                    continue\n",
    "                nb = neighbors(x,y)\n",
    "                B = sum(nb)\n",
    "                A = transitions(nb)\n",
    "                if 2 <= B <= 6 and A == 1 and (nb[0]*nb[2]*nb[6] == 0) and (nb[0]*nb[4]*nb[6] == 0):\n",
    "                    to_del.append((x,y))\n",
    "        if to_del:\n",
    "            for x,y in to_del: img[x,y] = 0\n",
    "            changed = True\n",
    "    return img\n",
    "\n",
    "def skeleton_degrees(skel01: np.ndarray) -> np.ndarray:\n",
    "    sk = (skel01 > 0).astype(np.uint8)\n",
    "    H, W = sk.shape\n",
    "    deg = np.zeros((H,W), np.uint8)\n",
    "    pts = np.argwhere(sk > 0)\n",
    "    for r,c in pts:\n",
    "        n = 0\n",
    "        for dr in (-1,0,1):\n",
    "            for dc in (-1,0,1):\n",
    "                if dr==0 and dc==0:\n",
    "                    continue\n",
    "                rr, cc = r+dr, c+dc\n",
    "                if 0 <= rr < H and 0 <= cc < W and sk[rr,cc] > 0:\n",
    "                    n += 1\n",
    "        deg[r,c] = n\n",
    "    return deg\n",
    "\n",
    "def edge_endpoints(Eb01: np.ndarray):\n",
    "    sk = zhang_suen_thinning(Eb01.astype(np.uint8))\n",
    "    deg = skeleton_degrees(sk)\n",
    "    eps = np.argwhere((sk > 0) & (deg == 1))  # (r,c)\n",
    "    return sk, eps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:29.431493Z",
     "start_time": "2025-12-28T09:26:29.401379700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Good Continuation Link Score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def _unit(v, eps=1e-9):\n",
    "    v = np.asarray(v, dtype=float)\n",
    "    n = np.linalg.norm(v)\n",
    "    return v / (n + eps)\n",
    "\n",
    "def estimate_tangent(skel01: np.ndarray, pt_rc, win=NBR_WIN):\n",
    "    \"\"\"Local PCA on skeleton pixels in a window â†’ tangent direction (dx,dy) in x,y coords.\"\"\"\n",
    "    r,c = int(pt_rc[0]), int(pt_rc[1])\n",
    "    H,W = skel01.shape\n",
    "    h = win//2\n",
    "    r0,r1 = max(0,r-h), min(H,r+h+1)\n",
    "    c0,c1 = max(0,c-h), min(W,c+h+1)\n",
    "    ys,xs = np.where(skel01[r0:r1, c0:c1] > 0)\n",
    "    if len(xs) < 5:\n",
    "        return np.array([1.0, 0.0], dtype=float)\n",
    "    xs = xs + c0\n",
    "    ys = ys + r0\n",
    "    pts = np.stack([xs.astype(float), ys.astype(float)], axis=1) # (x,y)\n",
    "    ctr = pts.mean(axis=0)\n",
    "    X = pts - ctr\n",
    "    C = (X.T @ X) / max(1, len(X)-1)\n",
    "    eigvals, eigvecs = np.linalg.eigh(C)\n",
    "    v = eigvecs[:, np.argmax(eigvals)]  # principal axis\n",
    "    return _unit(v)\n",
    "\n",
    "def sample_edge_strength_along_segment(E01: np.ndarray, a_rc, b_rc, n=30):\n",
    "    \"\"\"Mean E along straight segment between endpoints.\"\"\"\n",
    "    ar,ac = float(a_rc[0]), float(a_rc[1])\n",
    "    br,bc = float(b_rc[0]), float(b_rc[1])\n",
    "    H,W = E01.shape\n",
    "    rs = np.linspace(ar, br, n)\n",
    "    cs = np.linspace(ac, bc, n)\n",
    "    vals = []\n",
    "    for r,c in zip(rs,cs):\n",
    "        rr = int(np.clip(round(r), 0, H-1))\n",
    "        cc = int(np.clip(round(c), 0, W-1))\n",
    "        vals.append(float(E01[rr,cc]))\n",
    "    return float(np.mean(vals)) if vals else 0.0\n",
    "\n",
    "def link_score(E01, skel01, a_rc, b_rc, diag):\n",
    "    \"\"\"\n",
    "    Good-continuation score in [0,1]:\n",
    "    - collinearity: tangent at endpoints aligns with connecting vector\n",
    "    - distance penalty: closer is better\n",
    "    - edge support: if segment crosses high E, more plausible\n",
    "    \"\"\"\n",
    "    a = np.array([float(a_rc[1]), float(a_rc[0])])  # (x,y)\n",
    "    b = np.array([float(b_rc[1]), float(b_rc[0])])\n",
    "    v = b - a\n",
    "    d = float(np.linalg.norm(v))\n",
    "    if d < 1e-6:\n",
    "        return 0.0, d, 0.0, 0.0\n",
    "\n",
    "    vhat = _unit(v)\n",
    "\n",
    "    ta = estimate_tangent(skel01, a_rc)\n",
    "    tb = estimate_tangent(skel01, b_rc)\n",
    "\n",
    "    # endpoint tangents should point *toward* the connection (directionless)\n",
    "    col_a = abs(float(np.dot(ta, vhat)))\n",
    "    col_b = abs(float(np.dot(tb, -vhat)))\n",
    "    col = 0.5*(col_a + col_b)  # 0..1\n",
    "\n",
    "    # distance term (0..1), soft decay\n",
    "    d01 = np.clip(d / (MAX_LINK_DIST_FRAC*diag + 1e-9), 0.0, 1.0)\n",
    "    dist_term = 1.0 - d01\n",
    "\n",
    "    # edge support (0..1)\n",
    "    edge_term = sample_edge_strength_along_segment(E01, a_rc, b_rc, n=30)\n",
    "\n",
    "    score = COLLIN_W*col + DIST_W*dist_term + EDGE_W*edge_term\n",
    "    return float(np.clip(score, 0.0, 1.0)), d, col, edge_term\n",
    "\n",
    "def build_links_for_image(E01, Eb01):\n",
    "    H,W = Eb01.shape\n",
    "    diag = float(np.hypot(H,W))\n",
    "    skel01, eps = edge_endpoints(Eb01)\n",
    "\n",
    "    # candidate pairs within max distance\n",
    "    max_d = MAX_LINK_DIST_FRAC * diag\n",
    "    links = []\n",
    "    for i in range(len(eps)):\n",
    "        for j in range(i+1, len(eps)):\n",
    "            d = np.linalg.norm(eps[j].astype(float) - eps[i].astype(float))\n",
    "            if d <= max_d:\n",
    "                s, dist_px, col, edge_term = link_score(E01, skel01, eps[i], eps[j], diag)\n",
    "                links.append((i, j, s, dist_px, col, edge_term))\n",
    "\n",
    "    # sort by score desc\n",
    "    links.sort(key=lambda x: x[2], reverse=True)\n",
    "    return skel01, eps, links"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:29.437585700Z",
     "start_time": "2025-12-28T09:26:29.421781600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Completion Plausibility"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def mean_turning_at_endpoint(skel01, pt_rc, win=11):\n",
    "    \"\"\"\n",
    "    Quick local â€œsimplicityâ€ proxy:\n",
    "    - take skeleton pixels in window, compute PCA eccentricity\n",
    "    - higher eccentricity => more line-like continuation => simpler\n",
    "    \"\"\"\n",
    "    r,c = int(pt_rc[0]), int(pt_rc[1])\n",
    "    H,W = skel01.shape\n",
    "    h = win//2\n",
    "    r0,r1 = max(0,r-h), min(H,r+h+1)\n",
    "    c0,c1 = max(0,c-h), min(W,c+h+1)\n",
    "    ys,xs = np.where(skel01[r0:r1, c0:c1] > 0)\n",
    "    if len(xs) < 10:\n",
    "        return 0.0\n",
    "    xs = xs + c0\n",
    "    ys = ys + r0\n",
    "    pts = np.stack([xs.astype(float), ys.astype(float)], axis=1)\n",
    "    ctr = pts.mean(axis=0)\n",
    "    X = pts - ctr\n",
    "    C = (X.T @ X) / max(1, len(X)-1)\n",
    "    eigvals, _ = np.linalg.eigh(C)\n",
    "    eigvals = np.sort(eigvals)[::-1]\n",
    "    e1, e2 = float(eigvals[0]), float(eigvals[1] + 1e-9)\n",
    "    ecc = e1 / e2\n",
    "    # map to 0..1 (soft saturate)\n",
    "    return float(np.clip(np.log1p(max(ecc,0.0))/4.0, 0.0, 1.0))\n",
    "\n",
    "def plausibility_from_top_links(skel01, eps, links):\n",
    "    \"\"\"\n",
    "    If we connect good pairs, endpoints should reduce and local continuation should become more line-like.\n",
    "    We simulate by â€œvirtuallyâ€ reducing endpoints count based on accepted links, and compute average tangent simplicity.\n",
    "    \"\"\"\n",
    "    if len(eps) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    used = set()\n",
    "    accepted = []\n",
    "    for (i,j,s,dist_px,col,edge_term) in links[:TOP_LINKS_PER_IMAGE]:\n",
    "        if i in used or j in used:\n",
    "            continue\n",
    "        if s < 0.55:  # accept only strong continuations\n",
    "            continue\n",
    "        used.add(i); used.add(j)\n",
    "        accepted.append((i,j,s))\n",
    "\n",
    "    # endpoints reduction proxy: each accepted link â€œresolvesâ€ 2 endpoints\n",
    "    resolved = 2 * len(accepted)\n",
    "    gain = resolved / max(1, len(eps))  # 0..1\n",
    "\n",
    "    # local simplicity near endpoints involved\n",
    "    sims = []\n",
    "    for (i,j,s) in accepted:\n",
    "        sims.append(mean_turning_at_endpoint(skel01, eps[i]))\n",
    "        sims.append(mean_turning_at_endpoint(skel01, eps[j]))\n",
    "    sim = float(np.mean(sims)) if sims else 0.0\n",
    "\n",
    "    plaus = PLAUS_ENDPT_GAIN_W*gain + PLAUS_TURN_W*sim\n",
    "    return float(np.clip(plaus, 0.0, 1.0)), len(accepted), gain, sim"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:29.450253100Z",
     "start_time": "2025-12-28T09:26:29.445325400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Amputation Risk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def contour_curvature_points(Eb01, win=CURV_WIN):\n",
    "    \"\"\"\n",
    "    Extract contour points from Eb, estimate curvature magnitude at each point.\n",
    "    Returns list of (r,c,curv01).\n",
    "    \"\"\"\n",
    "    e = (Eb01*255).astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(e, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    out = []\n",
    "    if not contours:\n",
    "        return out\n",
    "\n",
    "    w = max(5, int(win) | 1)\n",
    "    h = w//2\n",
    "\n",
    "    for cnt in contours:\n",
    "        pts = cnt[:,0,:]  # (x,y)\n",
    "        if len(pts) < w + 2:\n",
    "            continue\n",
    "        # make cyclic to avoid edges\n",
    "        P = np.vstack([pts[-h:], pts, pts[:h]])\n",
    "        for i in range(h, len(P)-h):\n",
    "            p0 = P[i-h].astype(float)\n",
    "            p1 = P[i].astype(float)\n",
    "            p2 = P[i+h].astype(float)\n",
    "            v1 = p0 - p1\n",
    "            v2 = p2 - p1\n",
    "            n1 = np.linalg.norm(v1) + 1e-9\n",
    "            n2 = np.linalg.norm(v2) + 1e-9\n",
    "            c = abs(float(np.dot(v1, v2) / (n1*n2)))   # collinearity\n",
    "            curv = 1.0 - c                             # curvature-ish\n",
    "            x,y = int(p1[0]), int(p1[1])\n",
    "            out.append((y, x, float(np.clip(curv, 0.0, 1.0))))  # store as (r,c)\n",
    "    return out\n",
    "\n",
    "def amputation_risk(Eb01, skel01, eps):\n",
    "    \"\"\"\n",
    "    â€œHigh risk stumpâ€ proxy:\n",
    "    - endpoint sits near a high-curvature contour zone (disruption near concavity/joint)\n",
    "    - and the endpoint neighborhood is locally edge-dense (looks complete)\n",
    "    \"\"\"\n",
    "    H,W = Eb01.shape\n",
    "    diag = float(np.hypot(H,W))\n",
    "    close_r = STUMP_CLOSE_EDGE_FRAC * diag\n",
    "\n",
    "    curv_pts = contour_curvature_points(Eb01, win=CURV_WIN)\n",
    "    if len(curv_pts) == 0 or len(eps) == 0:\n",
    "        return np.nan, 0, 0\n",
    "\n",
    "    # build quick list for nearest-curvature search (brutal but OK for your sizes)\n",
    "    curv_rc = np.array([(p[0], p[1]) for p in curv_pts], dtype=float)\n",
    "    curv_v  = np.array([p[2] for p in curv_pts], dtype=float)\n",
    "\n",
    "    risky = 0\n",
    "    checked = 0\n",
    "\n",
    "    for ep in eps:\n",
    "        checked += 1\n",
    "        d = np.linalg.norm(curv_rc - ep.astype(float), axis=1)\n",
    "        j = int(np.argmin(d))\n",
    "        if float(d[j]) > close_r:\n",
    "            continue\n",
    "\n",
    "        curv = float(curv_v[j])\n",
    "        if curv < CURV_THRESH:\n",
    "            continue\n",
    "\n",
    "        # local edge density around endpoint (stump â€œlooks completeâ€ if dense)\n",
    "        r,c = int(ep[0]), int(ep[1])\n",
    "        win = 11\n",
    "        h = win//2\n",
    "        r0,r1 = max(0,r-h), min(H,r+h+1)\n",
    "        c0,c1 = max(0,c-h), min(W,c+h+1)\n",
    "        dens = float(np.mean(Eb01[r0:r1, c0:c1]))\n",
    "\n",
    "        if dens >= 0.15:\n",
    "            risky += 1\n",
    "\n",
    "    risk01 = risky / max(1, checked)\n",
    "    return float(np.clip(risk01, 0.0, 1.0)), risky, checked"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:29.576937600Z",
     "start_time": "2025-12-28T09:26:29.462013900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run Batch for All Images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# ---- Safety knobs (useful if it hangs)\n",
    "MAX_IMAGES = None          # e.g. 50 for testing; None = all\n",
    "MAX_ENDPOINTS = 250        # cap endpoints to avoid O(N^2) blowups\n",
    "DENSITY_THINNING_SKIP = 0.18  # if Eb is too dense, skip thinning/linking\n",
    "\n",
    "def iter_images(data_root: Path):\n",
    "    exts = {\".png\", \".jpg\", \".jpeg\", \".webp\", \".tif\", \".tiff\", \".bmp\"}\n",
    "    for split in [\"real\", \"generated\"]:\n",
    "        base = data_root / split\n",
    "        if not base.exists():\n",
    "            continue\n",
    "        for p in base.rglob(\"*\"):\n",
    "            if p.suffix.lower() in exts:\n",
    "                rel = str(p.relative_to(data_root))\n",
    "                yield split, rel, str(p)\n",
    "\n",
    "def edge_endpoints_safe(Eb01: np.ndarray):\n",
    "    \"\"\"Endpoints with density guard (prevents thinning hangs on very dense edge maps).\"\"\"\n",
    "    dens = float(Eb01.mean())\n",
    "    if dens > DENSITY_THINNING_SKIP:\n",
    "        # Too dense => thinning expensive + endpoints not meaningful anyway\n",
    "        sk = np.zeros_like(Eb01, dtype=np.uint8)\n",
    "        eps = np.zeros((0, 2), dtype=int)\n",
    "        return sk, eps, dens, True\n",
    "    sk = zhang_suen_thinning(Eb01.astype(np.uint8))\n",
    "    deg = skeleton_degrees(sk)\n",
    "    eps = np.argwhere((sk > 0) & (deg == 1))\n",
    "    return sk, eps, dens, False\n",
    "\n",
    "def build_links_for_image_safe(E01, Eb01):\n",
    "    H, W = Eb01.shape\n",
    "    diag = float(np.hypot(H, W))\n",
    "\n",
    "    skel01, eps, dens, skipped = edge_endpoints_safe(Eb01)\n",
    "\n",
    "    # cap endpoints to avoid O(N^2)\n",
    "    if len(eps) > MAX_ENDPOINTS:\n",
    "        eps = eps[:MAX_ENDPOINTS]\n",
    "\n",
    "    max_d = MAX_LINK_DIST_FRAC * diag\n",
    "    links = []\n",
    "\n",
    "    if len(eps) >= 2 and not skipped:\n",
    "        for i in range(len(eps)):\n",
    "            ei = eps[i].astype(float)\n",
    "            for j in range(i + 1, len(eps)):\n",
    "                d = float(np.linalg.norm(eps[j].astype(float) - ei))\n",
    "                if d <= max_d:\n",
    "                    s, dist_px, col, edge_term = link_score(E01, skel01, eps[i], eps[j], diag)\n",
    "                    links.append((i, j, s, dist_px, col, edge_term))\n",
    "\n",
    "        links.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    return skel01, eps, links, dens, skipped"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T09:26:29.578952500Z",
     "start_time": "2025-12-28T09:26:29.481194400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] OK  real | real\\images\\10pm_feeding_around_the_clock.webp | dens=0.150 skip=0 eps=88 links=197 topK=12 t=9.53s\n",
      "[2] OK  real | real\\images\\11pm.webp | dens=0.150 skip=0 eps=13 links=43 topK=12 t=6.99s\n",
      "[3] OK  real | real\\images\\12_4_7_10.webp | dens=0.151 skip=0 eps=173 links=1556 topK=12 t=10.65s\n",
      "[4] OK  real | real\\images\\around_the_clock.webp | dens=0.150 skip=0 eps=43 links=81 topK=12 t=10.81s\n",
      "[5] OK  real | real\\images\\around_the_clock_alizarin.webp | dens=0.151 skip=0 eps=8 links=9 topK=9 t=20.84s\n",
      "[6] OK  real | real\\images\\Bellyscape_and_plumb_bob.webp | dens=0.152 skip=0 eps=21 links=24 topK=12 t=15.58s\n",
      "[7] OK  real | real\\images\\Belly_breast.webp | dens=0.147 skip=0 eps=250 links=3123 topK=12 t=14.49s\n",
      "[8] OK  real | real\\images\\Belly_breast_face_brain_placenta.webp | dens=0.148 skip=0 eps=190 links=1228 topK=12 t=7.89s\n",
      "[9] OK  real | real\\images\\Birth_perspective_from_above_and_below.webp | dens=0.149 skip=0 eps=157 links=977 topK=12 t=14.35s\n",
      "[10] OK  real | real\\images\\Blue_0_with_red_halo.webp | dens=0.152 skip=0 eps=0 links=0 topK=0 t=11.26s\n",
      "[11] OK  real | real\\images\\Blue_eye.webp | dens=0.152 skip=0 eps=6 links=1 topK=1 t=13.71s\n",
      "[12] OK  real | real\\images\\Blue_Nip.webp | dens=0.150 skip=0 eps=16 links=30 topK=12 t=11.61s\n",
      "[13] OK  real | real\\images\\Boob_Wheel.webp | dens=0.151 skip=0 eps=93 links=421 topK=12 t=18.67s\n",
      "[14] OK  real | real\\images\\Book_of_Birth_1.webp | dens=0.149 skip=0 eps=54 links=111 topK=12 t=16.79s\n",
      "[15] OK  real | real\\images\\Book_of_Birth_2.webp | dens=0.150 skip=0 eps=45 links=86 topK=12 t=15.67s\n",
      "[16] OK  real | real\\images\\cascade.webp | dens=0.152 skip=0 eps=62 links=137 topK=12 t=19.49s\n",
      "[17] OK  real | real\\images\\Colostrum_well.webp | dens=0.149 skip=0 eps=95 links=496 topK=12 t=22.70s\n",
      "[18] OK  real | real\\images\\Deep_Breath.webp | dens=0.151 skip=0 eps=26 links=26 topK=12 t=9.90s\n",
      "[19] OK  real | real\\images\\Deep_Tear.webp | dens=0.151 skip=0 eps=60 links=149 topK=12 t=10.82s\n",
      "[20] OK  real | real\\images\\Descent_into_chaos.webp | dens=0.150 skip=0 eps=69 links=187 topK=12 t=11.52s\n",
      "[21] OK  real | real\\images\\Eclipse.webp | dens=0.152 skip=0 eps=95 links=653 topK=12 t=54.57s\n",
      "[22] OK  real | real\\images\\Eight_Centimeters_Dilated.webp | dens=0.150 skip=0 eps=38 links=51 topK=12 t=19.29s\n",
      "[23] OK  real | real\\images\\Empty_Belly.webp | dens=0.153 skip=0 eps=71 links=167 topK=12 t=9.26s\n",
      "[24] OK  real | real\\images\\Engorged.webp | dens=0.150 skip=0 eps=27 links=40 topK=12 t=11.29s\n",
      "[25] OK  real | real\\images\\Expanding_Figure.webp | dens=0.151 skip=0 eps=71 links=174 topK=12 t=8.24s\n",
      "[26] OK  real | real\\images\\Feeding_around_the_clock.webp | dens=0.153 skip=0 eps=82 links=245 topK=12 t=42.65s\n",
      "[27] OK  real | real\\images\\Finding_Time.webp | dens=0.151 skip=0 eps=133 links=558 topK=12 t=22.27s\n",
      "[28] OK  real | real\\images\\Fourteen_Saints.webp | dens=0.149 skip=0 eps=222 links=2001 topK=12 t=12.07s\n",
      "[29] OK  real | real\\images\\Four_breasts_pink_purple_red_yellow.webp | dens=0.151 skip=0 eps=80 links=224 topK=12 t=23.11s\n",
      "[30] OK  real | real\\images\\Fuchsia_Brain.webp | dens=0.152 skip=0 eps=26 links=42 topK=12 t=13.57s\n",
      "[31] OK  real | real\\images\\Fully_Dilated.webp | dens=0.152 skip=0 eps=48 links=127 topK=12 t=52.02s\n",
      "[32] OK  real | real\\images\\Full_Bodied.webp | dens=0.158 skip=0 eps=184 links=1970 topK=12 t=892.50s\n",
      "[33] OK  real | real\\images\\Green_Brain.webp | dens=0.152 skip=0 eps=40 links=84 topK=12 t=17.14s\n",
      "[34] OK  real | real\\images\\Heavy_Burden.webp | dens=0.151 skip=0 eps=20 links=22 topK=12 t=10.05s\n",
      "[35] OK  real | real\\images\\Horizon_on_my_pit_of_Hell.webp | dens=0.150 skip=0 eps=14 links=5 topK=5 t=9.86s\n",
      "[36] OK  real | real\\images\\Juggling_Act.webp | dens=0.151 skip=0 eps=59 links=149 topK=12 t=10.05s\n",
      "[37] OK  real | real\\images\\Let_down.webp | dens=0.151 skip=0 eps=44 links=86 topK=12 t=17.13s\n",
      "[38] OK  real | real\\images\\Lingam_Twist_Blue_Orange.webp | dens=0.151 skip=0 eps=46 links=115 topK=12 t=138.60s\n",
      "[39] OK  real | real\\images\\Linked_Lingams_Yellow_Purple.webp | dens=0.152 skip=0 eps=38 links=23 topK=12 t=16.98s\n",
      "[40] OK  real | real\\images\\Linked_Lingam_Orange.webp | dens=0.146 skip=0 eps=94 links=394 topK=12 t=74.68s\n",
      "[41] OK  real | real\\images\\Mechanics_of_a_Breast_Pump.webp | dens=0.154 skip=0 eps=175 links=1725 topK=12 t=8.54s\n",
      "[42] OK  real | real\\images\\Meeting_in_the_middle.webp | dens=0.149 skip=0 eps=97 links=346 topK=12 t=9.37s\n",
      "[43] OK  real | real\\images\\Meeting_Place.webp | dens=0.150 skip=0 eps=9 links=3 topK=3 t=5.54s\n",
      "[44] OK  real | real\\images\\middle.webp | dens=0.152 skip=0 eps=51 links=48 topK=12 t=5.27s\n",
      "[45] OK  real | real\\images\\Milk_Fountain.webp | dens=0.151 skip=0 eps=33 links=93 topK=12 t=9.42s\n",
      "[46] OK  real | real\\images\\Milk_Fountain_II.webp | dens=0.152 skip=0 eps=26 links=42 topK=12 t=9.19s\n",
      "[47] OK  real | real\\images\\Milk_Spine.webp | dens=0.151 skip=0 eps=44 links=97 topK=12 t=4.28s\n",
      "[48] OK  real | real\\images\\Milk_Spout.webp | dens=0.151 skip=0 eps=19 links=17 topK=12 t=3.71s\n",
      "[49] OK  real | real\\images\\Mothers_milk.webp | dens=0.152 skip=0 eps=14 links=17 topK=12 t=5.51s\n",
      "[50] OK  real | real\\images\\Nipple_Talk.webp | dens=0.150 skip=0 eps=105 links=315 topK=12 t=7.27s\n",
      "[51] OK  real | real\\images\\One_opening_leads_to_another.webp | dens=0.151 skip=0 eps=40 links=50 topK=12 t=4.79s\n",
      "[52] OK  real | real\\images\\Orange_Brain.webp | dens=0.152 skip=0 eps=8 links=0 topK=0 t=6.81s\n",
      "[53] OK  real | real\\images\\Overview_Effect.webp | dens=0.150 skip=0 eps=33 links=40 topK=12 t=48.87s\n",
      "[54] OK  real | real\\images\\Overview_Effect_blue_red_mandala.webp | dens=0.150 skip=0 eps=46 links=105 topK=12 t=5.15s\n",
      "[55] OK  real | real\\images\\Overview_Effect_red_yellow.webp | dens=0.151 skip=0 eps=51 links=89 topK=12 t=34.80s\n",
      "[56] OK  real | real\\images\\Perspective_From_Above_and_Below.webp | dens=0.149 skip=0 eps=60 links=162 topK=12 t=8.84s\n",
      "[57] OK  real | real\\images\\Pink_Rainbow_over_Blue_Mounds.webp | dens=0.151 skip=0 eps=32 links=33 topK=12 t=5.34s\n",
      "[58] OK  real | real\\images\\Postpartum_belly_void.webp | dens=0.151 skip=0 eps=112 links=494 topK=12 t=4.78s\n",
      "[59] OK  real | real\\images\\Postpartum_Plumb_Line.webp | dens=0.150 skip=0 eps=19 links=11 topK=11 t=4.01s\n",
      "[60] OK  real | real\\images\\Post_pregnant_belly_and_boobs.webp | dens=0.150 skip=0 eps=104 links=515 topK=12 t=3.49s\n",
      "[61] OK  real | real\\images\\Pregnancy_in_three_acts.webp | dens=0.151 skip=0 eps=34 links=61 topK=12 t=5.09s\n",
      "[62] OK  real | real\\images\\Pregnant_Red.webp | dens=0.152 skip=0 eps=22 links=29 topK=12 t=3.99s\n",
      "[63] OK  real | real\\images\\Prenatal_Plumb_Line.webp | dens=0.150 skip=0 eps=37 links=43 topK=12 t=3.79s\n",
      "[64] OK  real | real\\images\\Pressure_blue_purple.webp | dens=0.129 skip=0 eps=250 links=5104 topK=12 t=463.11s\n",
      "[65] OK  real | real\\images\\Push_Out.webp | dens=0.150 skip=0 eps=18 links=7 topK=7 t=6.16s\n",
      "[66] OK  generated | generated\\ComfyUI_00082_.png | dens=0.155 skip=0 eps=46 links=69 topK=12 t=7.82s\n",
      "[67] OK  generated | generated\\ComfyUI_00083_.png | dens=0.153 skip=0 eps=16 links=9 topK=9 t=3.98s\n",
      "[68] OK  generated | generated\\ComfyUI_00084_.png | dens=0.151 skip=0 eps=12 links=5 topK=5 t=2.57s\n",
      "[69] OK  generated | generated\\ComfyUI_00085_.png | dens=0.150 skip=0 eps=41 links=58 topK=12 t=2.87s\n",
      "[70] OK  generated | generated\\ComfyUI_00086_.png | dens=0.150 skip=0 eps=8 links=4 topK=4 t=3.32s\n",
      "[71] OK  generated | generated\\ComfyUI_00087_.png | dens=0.150 skip=0 eps=4 links=0 topK=0 t=1.79s\n",
      "[72] OK  generated | generated\\ComfyUI_00088_.png | dens=0.150 skip=0 eps=16 links=12 topK=12 t=2.07s\n",
      "[73] OK  generated | generated\\ComfyUI_00089_.png | dens=0.151 skip=0 eps=15 links=4 topK=4 t=4.76s\n",
      "[74] OK  generated | generated\\ComfyUI_00090_.png | dens=0.154 skip=0 eps=32 links=33 topK=12 t=5.28s\n",
      "[75] OK  generated | generated\\ComfyUI_00091_.png | dens=0.150 skip=0 eps=14 links=7 topK=7 t=3.12s\n",
      "[76] OK  generated | generated\\ComfyUI_00092_.png | dens=0.150 skip=0 eps=32 links=37 topK=12 t=4.67s\n",
      "[77] OK  generated | generated\\ComfyUI_00093_.png | dens=0.152 skip=0 eps=14 links=6 topK=6 t=4.59s\n",
      "[78] OK  generated | generated\\ComfyUI_00094_.png | dens=0.154 skip=0 eps=14 links=7 topK=7 t=3.98s\n",
      "[79] OK  generated | generated\\ComfyUI_00095_.png | dens=0.154 skip=0 eps=14 links=4 topK=4 t=6.48s\n",
      "[80] OK  generated | generated\\ComfyUI_00096_.png | dens=0.150 skip=0 eps=9 links=2 topK=2 t=5.61s\n",
      "[81] OK  generated | generated\\ComfyUI_00097_.png | dens=0.156 skip=0 eps=18 links=12 topK=12 t=2.97s\n",
      "[82] OK  generated | generated\\ComfyUI_00098_.png | dens=0.151 skip=0 eps=23 links=26 topK=12 t=5.43s\n",
      "[83] OK  generated | generated\\ComfyUI_00099_.png | dens=0.151 skip=0 eps=22 links=19 topK=12 t=3.79s\n",
      "[84] OK  generated | generated\\ComfyUI_00100_.png | dens=0.150 skip=0 eps=7 links=3 topK=3 t=3.35s\n",
      "[85] OK  generated | generated\\ComfyUI_00101_.png | dens=0.153 skip=0 eps=26 links=37 topK=12 t=7.19s\n",
      "[86] OK  generated | generated\\ComfyUI_00102_.png | dens=0.151 skip=0 eps=19 links=14 topK=12 t=3.13s\n",
      "[87] OK  generated | generated\\ComfyUI_00103_.png | dens=0.150 skip=0 eps=6 links=1 topK=1 t=2.86s\n",
      "[88] OK  generated | generated\\ComfyUI_00104_.png | dens=0.151 skip=0 eps=21 links=22 topK=12 t=4.70s\n",
      "[89] OK  generated | generated\\ComfyUI_00105_.png | dens=0.150 skip=0 eps=9 links=7 topK=7 t=3.05s\n",
      "[90] OK  generated | generated\\ComfyUI_00106_.png | dens=0.156 skip=0 eps=29 links=24 topK=12 t=3.78s\n",
      "[91] OK  generated | generated\\ComfyUI_00108_.png | dens=0.151 skip=0 eps=5 links=1 topK=1 t=2.49s\n",
      "[92] OK  generated | generated\\ComfyUI_00109_.png | dens=0.153 skip=0 eps=48 links=106 topK=12 t=3.34s\n",
      "[93] OK  generated | generated\\ComfyUI_00110_.png | dens=0.150 skip=0 eps=38 links=43 topK=12 t=6.18s\n",
      "[94] OK  generated | generated\\ComfyUI_00115_.png | dens=0.152 skip=0 eps=12 links=4 topK=4 t=3.19s\n",
      "[95] OK  generated | generated\\ComfyUI_00118_.png | dens=0.151 skip=0 eps=18 links=15 topK=12 t=4.14s\n",
      "[96] OK  generated | generated\\ComfyUI_00119_.png | dens=0.153 skip=0 eps=34 links=50 topK=12 t=4.30s\n",
      "[97] OK  generated | generated\\ComfyUI_00120_.png | dens=0.154 skip=0 eps=11 links=2 topK=2 t=3.28s\n",
      "[98] OK  generated | generated\\ComfyUI_00121_.png | dens=0.155 skip=0 eps=29 links=42 topK=12 t=3.89s\n",
      "[99] OK  generated | generated\\ComfyUI_00122_.png | dens=0.151 skip=0 eps=17 links=7 topK=7 t=4.45s\n",
      "[100] OK  generated | generated\\ComfyUI_00123_.png | dens=0.150 skip=0 eps=22 links=27 topK=12 t=2.92s\n",
      "[101] OK  generated | generated\\ComfyUI_00126_.png | dens=0.150 skip=0 eps=28 links=40 topK=12 t=7.31s\n",
      "[102] OK  generated | generated\\ComfyUI_00127_.png | dens=0.150 skip=0 eps=33 links=48 topK=12 t=3.27s\n",
      "[103] OK  generated | generated\\ComfyUI_00129_.png | dens=0.153 skip=0 eps=34 links=37 topK=12 t=3.84s\n",
      "[104] OK  generated | generated\\ComfyUI_00130_.png | dens=0.152 skip=0 eps=51 links=60 topK=12 t=3.26s\n",
      "[105] OK  generated | generated\\ComfyUI_00131_.png | dens=0.152 skip=0 eps=45 links=44 topK=12 t=2.92s\n",
      "[106] OK  generated | generated\\ComfyUI_00132_.png | dens=0.152 skip=0 eps=38 links=33 topK=12 t=3.37s\n",
      "[107] OK  generated | generated\\ComfyUI_00134_.png | dens=0.150 skip=0 eps=25 links=24 topK=12 t=3.45s\n",
      "[108] OK  generated | generated\\ComfyUI_00136_.png | dens=0.159 skip=0 eps=33 links=22 topK=12 t=11.86s\n",
      "[109] OK  generated | generated\\ComfyUI_00137_.png | dens=0.150 skip=0 eps=53 links=69 topK=12 t=6.19s\n",
      "[110] OK  generated | generated\\ComfyUI_00138_.png | dens=0.151 skip=0 eps=53 links=88 topK=12 t=6.87s\n",
      "[111] OK  generated | generated\\ComfyUI_00139_.png | dens=0.153 skip=0 eps=67 links=131 topK=12 t=5.73s\n",
      "[112] OK  generated | generated\\ComfyUI_00141_.png | dens=0.155 skip=0 eps=70 links=180 topK=12 t=4.53s\n",
      "[113] OK  generated | generated\\ComfyUI_00143_.png | dens=0.154 skip=0 eps=39 links=51 topK=12 t=3.74s\n",
      "[114] OK  generated | generated\\ComfyUI_00144_.png | dens=0.150 skip=0 eps=20 links=17 topK=12 t=3.48s\n",
      "[115] OK  generated | generated\\ComfyUI_00145_.png | dens=0.151 skip=0 eps=56 links=77 topK=12 t=3.84s\n",
      "[116] OK  generated | generated\\ComfyUI_00146_.png | dens=0.150 skip=0 eps=19 links=17 topK=12 t=2.44s\n",
      "[117] OK  generated | generated\\ComfyUI_00147_.png | dens=0.150 skip=0 eps=18 links=11 topK=11 t=3.36s\n",
      "[118] OK  generated | generated\\ComfyUI_00149_.png | dens=0.150 skip=0 eps=21 links=18 topK=12 t=4.18s\n",
      "[119] OK  generated | generated\\ComfyUI_00150_.png | dens=0.154 skip=0 eps=24 links=15 topK=12 t=4.87s\n",
      "[120] OK  generated | generated\\ComfyUI_00151_.png | dens=0.154 skip=0 eps=65 links=171 topK=12 t=10.47s\n",
      "[121] OK  generated | generated\\ComfyUI_00152_.png | dens=0.153 skip=0 eps=37 links=41 topK=12 t=7.54s\n",
      "[122] OK  generated | generated\\ComfyUI_00153_.png | dens=0.150 skip=0 eps=18 links=29 topK=12 t=4.88s\n",
      "[123] OK  generated | generated\\ComfyUI_00154_.png | dens=0.150 skip=0 eps=47 links=57 topK=12 t=6.01s\n",
      "[124] OK  generated | generated\\ComfyUI_00155_.png | dens=0.150 skip=0 eps=23 links=15 topK=12 t=3.59s\n",
      "[125] OK  generated | generated\\ComfyUI_00156_.png | dens=0.154 skip=0 eps=18 links=11 topK=11 t=4.02s\n",
      "[126] OK  generated | generated\\ComfyUI_00158_.png | dens=0.151 skip=0 eps=22 links=11 topK=11 t=2.70s\n",
      "[127] OK  generated | generated\\ComfyUI_00159_.png | dens=0.150 skip=0 eps=19 links=22 topK=12 t=4.16s\n",
      "[128] OK  generated | generated\\ComfyUI_00160_.png | dens=0.151 skip=0 eps=19 links=14 topK=12 t=3.85s\n",
      "[129] OK  generated | generated\\ComfyUI_00161_.png | dens=0.150 skip=0 eps=10 links=0 topK=0 t=4.38s\n",
      "[130] OK  generated | generated\\ComfyUI_00163_.png | dens=0.150 skip=0 eps=4 links=0 topK=0 t=5.24s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "rows_links = []\n",
    "rows_img = []\n",
    "\n",
    "t0 = time.time()\n",
    "ok = 0\n",
    "fail = 0\n",
    "total = 0\n",
    "\n",
    "for k, (split, image_id, path) in enumerate(iter_images(DATA_ROOT), start=1):\n",
    "    if MAX_IMAGES is not None and k > MAX_IMAGES:\n",
    "        break\n",
    "\n",
    "    total += 1\n",
    "    t_img0 = time.time()\n",
    "\n",
    "    try:\n",
    "        gray01 = preprocess_gray01(path)\n",
    "        E01, Eb01 = make_edge_maps(gray01)\n",
    "\n",
    "        H, W = Eb01.shape\n",
    "        skel01, eps, links, dens, skipped = build_links_for_image_safe(E01, Eb01)\n",
    "\n",
    "        # (1) Good-continuation index (top K mean score)\n",
    "        top = links[:TOP_LINKS_PER_IMAGE]\n",
    "        gc01 = float(np.mean([x[2] for x in top])) if len(top) else 0.0\n",
    "\n",
    "        for (i, j, s, dist_px, col, edge_term) in top:\n",
    "            a = eps[i]; b = eps[j]\n",
    "            rows_links.append({\n",
    "                \"split\": split,\n",
    "                \"image_id\": image_id,\n",
    "                \"ep_i\": int(i),\n",
    "                \"ep_j\": int(j),\n",
    "                \"a_r\": int(a[0]), \"a_c\": int(a[1]),\n",
    "                \"b_r\": int(b[0]), \"b_c\": int(b[1]),\n",
    "                \"link_score_01\": float(s),\n",
    "                \"dist_px\": float(dist_px),\n",
    "                \"collinearity_01\": float(col),\n",
    "                \"edge_support_01\": float(edge_term),\n",
    "            })\n",
    "\n",
    "        # (2) Completion plausibility\n",
    "        plaus = plausibility_from_top_links(skel01, eps, links)\n",
    "        if isinstance(plaus, tuple):\n",
    "            plaus01, n_acc, gain01, simp01 = plaus\n",
    "        else:\n",
    "            plaus01, n_acc, gain01, simp01 = np.nan, 0, np.nan, np.nan\n",
    "\n",
    "        # (3) Amputation risk\n",
    "        risk01, risky_n, checked_n = amputation_risk(Eb01, skel01, eps)\n",
    "\n",
    "        rows_img.append({\n",
    "            \"split\": split,\n",
    "            \"image_id\": image_id,\n",
    "\n",
    "            \"form4_good_continuation_01\": float(gc01),\n",
    "            \"form4_completion_plausibility_01\": (float(plaus01) if np.isfinite(plaus01) else np.nan),\n",
    "            \"form4_amputation_risk_01\": (float(risk01) if np.isfinite(risk01) else np.nan),\n",
    "\n",
    "            \"n_endpoints\": int(len(eps)),\n",
    "            \"n_candidate_links\": int(len(links)),\n",
    "            \"n_accepted_links\": int(n_acc),\n",
    "\n",
    "            \"endpoint_gain_01\": (float(gain01) if np.isfinite(gain01) else np.nan),\n",
    "            \"local_simplicity_01\": (float(simp01) if np.isfinite(simp01) else np.nan),\n",
    "\n",
    "            \"risky_endpoints\": int(risky_n),\n",
    "            \"checked_endpoints\": int(checked_n),\n",
    "\n",
    "            \"edge_density_01\": float(dens),\n",
    "            \"thinning_skipped\": int(bool(skipped)),\n",
    "\n",
    "            \"H\": int(H),\n",
    "            \"W\": int(W),\n",
    "        })\n",
    "\n",
    "        ok += 1\n",
    "        dt = time.time() - t_img0\n",
    "        print(f\"[{k}] OK  {split} | {image_id} | dens={dens:.3f} skip={int(skipped)} \"\n",
    "              f\"eps={len(eps)} links={len(links)} topK={len(top)} t={dt:.2f}s\")\n",
    "\n",
    "    except Exception as e:\n",
    "        fail += 1\n",
    "        dt = time.time() - t_img0\n",
    "        print(f\"[{k}] FAIL {split} | {image_id} | {type(e).__name__}: {e} (t={dt:.2f}s)\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.639349400Z",
     "start_time": "2025-12-28T09:26:29.490043100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: outputs\\form4\\form4_links.csv rows= 1342\n",
      "Saved: outputs\\form4\\form4_image_indices.csv rows= 130\n",
      "Done. ok=130 fail=0 total=130 elapsed=2692.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": "  split                                           image_id  \\\n0  real     real\\images\\10pm_feeding_around_the_clock.webp   \n1  real                              real\\images\\11pm.webp   \n2  real                         real\\images\\12_4_7_10.webp   \n3  real                  real\\images\\around_the_clock.webp   \n4  real         real\\images\\around_the_clock_alizarin.webp   \n5  real          real\\images\\Bellyscape_and_plumb_bob.webp   \n6  real                      real\\images\\Belly_breast.webp   \n7  real  real\\images\\Belly_breast_face_brain_placenta.webp   \n8  real  real\\images\\Birth_perspective_from_above_and_b...   \n9  real              real\\images\\Blue_0_with_red_halo.webp   \n\n   form4_good_continuation_01  form4_completion_plausibility_01  \\\n0                    0.771539                          0.202122   \n1                    0.621331                          0.430769   \n2                    0.815214                          0.097110   \n3                    0.663651                          0.335998   \n4                    0.497145                          0.525000   \n5                    0.746824                          0.333333   \n6                    0.838962                          0.067200   \n7                    0.822282                          0.094294   \n8                    0.820921                          0.139384   \n9                    0.000000                               NaN   \n\n   form4_amputation_risk_01  n_endpoints  n_candidate_links  n_accepted_links  \\\n0                  0.352273           88                197                10   \n1                  0.538462           13                 43                 4   \n2                  0.416185          173               1556                12   \n3                  0.372093           43                 81                10   \n4                  0.250000            8                  9                 3   \n5                  0.428571           21                 24                 5   \n6                  0.548000          250               3123                12   \n7                  0.352632          190               1228                11   \n8                  0.426752          157                977                12   \n9                       NaN            0                  0                 0   \n\n   endpoint_gain_01  local_simplicity_01  risky_endpoints  checked_endpoints  \\\n0          0.227273             0.143435               31                 88   \n1          0.615385             0.000000                7                 13   \n2          0.138728             0.000000               72                173   \n3          0.465116             0.034722               16                 43   \n4          0.750000             0.000000                2                  8   \n5          0.476190             0.000000                9                 21   \n6          0.096000             0.000000              137                250   \n7          0.115789             0.044139               67                190   \n8          0.152866             0.107926               67                157   \n9               NaN                  NaN                0                  0   \n\n   edge_density_01  thinning_skipped    H     W  \n0         0.150277                 0  749   750  \n1         0.150075                 0  642   500  \n2         0.151121                 0  749   750  \n3         0.150061                 0  799   750  \n4         0.150786                 0  704  1000  \n5         0.151760                 0  595   750  \n6         0.147070                 0  667  1000  \n7         0.148355                 0  680   750  \n8         0.148619                 0  571   750  \n9         0.152359                 0  640   500  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>split</th>\n      <th>image_id</th>\n      <th>form4_good_continuation_01</th>\n      <th>form4_completion_plausibility_01</th>\n      <th>form4_amputation_risk_01</th>\n      <th>n_endpoints</th>\n      <th>n_candidate_links</th>\n      <th>n_accepted_links</th>\n      <th>endpoint_gain_01</th>\n      <th>local_simplicity_01</th>\n      <th>risky_endpoints</th>\n      <th>checked_endpoints</th>\n      <th>edge_density_01</th>\n      <th>thinning_skipped</th>\n      <th>H</th>\n      <th>W</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>real</td>\n      <td>real\\images\\10pm_feeding_around_the_clock.webp</td>\n      <td>0.771539</td>\n      <td>0.202122</td>\n      <td>0.352273</td>\n      <td>88</td>\n      <td>197</td>\n      <td>10</td>\n      <td>0.227273</td>\n      <td>0.143435</td>\n      <td>31</td>\n      <td>88</td>\n      <td>0.150277</td>\n      <td>0</td>\n      <td>749</td>\n      <td>750</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>real</td>\n      <td>real\\images\\11pm.webp</td>\n      <td>0.621331</td>\n      <td>0.430769</td>\n      <td>0.538462</td>\n      <td>13</td>\n      <td>43</td>\n      <td>4</td>\n      <td>0.615385</td>\n      <td>0.000000</td>\n      <td>7</td>\n      <td>13</td>\n      <td>0.150075</td>\n      <td>0</td>\n      <td>642</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>real</td>\n      <td>real\\images\\12_4_7_10.webp</td>\n      <td>0.815214</td>\n      <td>0.097110</td>\n      <td>0.416185</td>\n      <td>173</td>\n      <td>1556</td>\n      <td>12</td>\n      <td>0.138728</td>\n      <td>0.000000</td>\n      <td>72</td>\n      <td>173</td>\n      <td>0.151121</td>\n      <td>0</td>\n      <td>749</td>\n      <td>750</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>real</td>\n      <td>real\\images\\around_the_clock.webp</td>\n      <td>0.663651</td>\n      <td>0.335998</td>\n      <td>0.372093</td>\n      <td>43</td>\n      <td>81</td>\n      <td>10</td>\n      <td>0.465116</td>\n      <td>0.034722</td>\n      <td>16</td>\n      <td>43</td>\n      <td>0.150061</td>\n      <td>0</td>\n      <td>799</td>\n      <td>750</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>real</td>\n      <td>real\\images\\around_the_clock_alizarin.webp</td>\n      <td>0.497145</td>\n      <td>0.525000</td>\n      <td>0.250000</td>\n      <td>8</td>\n      <td>9</td>\n      <td>3</td>\n      <td>0.750000</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>8</td>\n      <td>0.150786</td>\n      <td>0</td>\n      <td>704</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>real</td>\n      <td>real\\images\\Bellyscape_and_plumb_bob.webp</td>\n      <td>0.746824</td>\n      <td>0.333333</td>\n      <td>0.428571</td>\n      <td>21</td>\n      <td>24</td>\n      <td>5</td>\n      <td>0.476190</td>\n      <td>0.000000</td>\n      <td>9</td>\n      <td>21</td>\n      <td>0.151760</td>\n      <td>0</td>\n      <td>595</td>\n      <td>750</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>real</td>\n      <td>real\\images\\Belly_breast.webp</td>\n      <td>0.838962</td>\n      <td>0.067200</td>\n      <td>0.548000</td>\n      <td>250</td>\n      <td>3123</td>\n      <td>12</td>\n      <td>0.096000</td>\n      <td>0.000000</td>\n      <td>137</td>\n      <td>250</td>\n      <td>0.147070</td>\n      <td>0</td>\n      <td>667</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>real</td>\n      <td>real\\images\\Belly_breast_face_brain_placenta.webp</td>\n      <td>0.822282</td>\n      <td>0.094294</td>\n      <td>0.352632</td>\n      <td>190</td>\n      <td>1228</td>\n      <td>11</td>\n      <td>0.115789</td>\n      <td>0.044139</td>\n      <td>67</td>\n      <td>190</td>\n      <td>0.148355</td>\n      <td>0</td>\n      <td>680</td>\n      <td>750</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>real</td>\n      <td>real\\images\\Birth_perspective_from_above_and_b...</td>\n      <td>0.820921</td>\n      <td>0.139384</td>\n      <td>0.426752</td>\n      <td>157</td>\n      <td>977</td>\n      <td>12</td>\n      <td>0.152866</td>\n      <td>0.107926</td>\n      <td>67</td>\n      <td>157</td>\n      <td>0.148619</td>\n      <td>0</td>\n      <td>571</td>\n      <td>750</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>real</td>\n      <td>real\\images\\Blue_0_with_red_halo.webp</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.152359</td>\n      <td>0</td>\n      <td>640</td>\n      <td>500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_links = pd.DataFrame(rows_links)\n",
    "df_img = pd.DataFrame(rows_img)\n",
    "\n",
    "df_links.to_csv(OUT_DIR / \"form4_links.csv\", index=False)\n",
    "df_img.to_csv(OUT_DIR / \"form4_image_indices.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved:\", OUT_DIR / \"form4_links.csv\", \"rows=\", len(df_links))\n",
    "print(\"Saved:\", OUT_DIR / \"form4_image_indices.csv\", \"rows=\", len(df_img))\n",
    "print(f\"Done. ok={ok} fail={fail} total={total} elapsed={time.time()-t0:.1f}s\")\n",
    "\n",
    "df_img.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.640350100Z",
     "start_time": "2025-12-28T10:11:26.638349800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Symmetry, repetition, ornamentality"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Helpers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def _as_float_series(s):\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(float)\n",
    "\n",
    "def _as_float_scalar(x, default=np.nan):\n",
    "    try:\n",
    "        v = pd.to_numeric(x, errors=\"coerce\")\n",
    "        if v is None:\n",
    "            return default\n",
    "        if isinstance(v, (np.ndarray, list, tuple)):\n",
    "            v = np.array(v).ravel()[0] if len(v) else default\n",
    "        v = float(v)\n",
    "        return v if np.isfinite(v) else default\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "def _wrap180(a):\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    return np.mod(a, 180.0)\n",
    "\n",
    "def _dist_to_axis(a_deg, b_deg):\n",
    "    a = np.asarray(a_deg, dtype=float)\n",
    "    b = np.asarray(b_deg, dtype=float)\n",
    "    d = np.abs(a - b)\n",
    "    d = np.minimum(d, 180.0 - d)  # 0..90\n",
    "    return d\n",
    "\n",
    "def _min_dist_to_hv(a_deg):\n",
    "    a = np.asarray(a_deg, dtype=float)\n",
    "    d0  = _dist_to_axis(a, 0.0)\n",
    "    d90 = _dist_to_axis(a, 90.0)\n",
    "    return np.minimum(d0, d90)     # 0..45\n",
    "\n",
    "def _safe_cols(df, cols):\n",
    "    return [c for c in cols if c in df.columns]\n",
    "\n",
    "def _pick_centroid_cols(df_img):\n",
    "    # common names we might have used earlier\n",
    "    candidates = [\n",
    "        (\"cx\",\"cy\"),\n",
    "        (\"centroid_x\",\"centroid_y\"),\n",
    "        (\"x_centroid\",\"y_centroid\"),\n",
    "        (\"center_x\",\"center_y\"),\n",
    "        (\"cX\",\"cY\"),\n",
    "    ]\n",
    "    for xcol, ycol in candidates:\n",
    "        if xcol in df_img.columns and ycol in df_img.columns:\n",
    "            return xcol, ycol\n",
    "    return None, None\n",
    "\n",
    "def _weights(df_img):\n",
    "    # prefer saliency, else area_ratio, else uniform\n",
    "    if \"saliency\" in df_img.columns and np.isfinite(_as_float_series(df_img[\"saliency\"])).any():\n",
    "        w = _as_float_series(df_img[\"saliency\"]).to_numpy()\n",
    "    elif \"area_ratio\" in df_img.columns and np.isfinite(_as_float_series(df_img[\"area_ratio\"])).any():\n",
    "        w = _as_float_series(df_img[\"area_ratio\"]).to_numpy()\n",
    "    else:\n",
    "        w = np.ones(len(df_img), dtype=float)\n",
    "    w = np.where(np.isfinite(w) & (w > 0), w, 0.0)\n",
    "    return w\n",
    "\n",
    "def _normalize01(x, lo=None, hi=None):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if lo is None: lo = np.nanmin(x)\n",
    "    if hi is None: hi = np.nanmax(x)\n",
    "    return np.clip((x - lo) / (hi - lo + 1e-9), 0.0, 1.0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.641349300Z",
     "start_time": "2025-12-28T10:11:26.639349400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def reflection_symmetry_region(row):\n",
    "    \"\"\"\n",
    "    CSV-only proxy:\n",
    "    - if symmetry_pca exists (0..1-ish), use it\n",
    "    - else fallback from pca_eig_ratio (more elongated + stable axis -> easier reflection)\n",
    "    \"\"\"\n",
    "    if \"symmetry_pca\" in row.index:\n",
    "        v = _as_float_scalar(row.get(\"symmetry_pca\", np.nan), default=np.nan)\n",
    "        if np.isfinite(v):\n",
    "            return float(np.clip(v, 0.0, 1.0))\n",
    "\n",
    "    eig = _as_float_scalar(row.get(\"pca_eig_ratio\", np.nan), default=np.nan)\n",
    "    if np.isfinite(eig):\n",
    "        # log-saturate -> 0..1\n",
    "        return float(np.clip(np.log1p(max(eig, 0.0)) / 4.0, 0.0, 1.0))\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "def reflection_symmetry_whole(df_img):\n",
    "    v = np.array([reflection_symmetry_region(r) for _, r in df_img.iterrows()], dtype=float)\n",
    "    w = _weights(df_img)\n",
    "    wsum = float(np.sum(w) + 1e-12)\n",
    "    return float(np.nansum(v * w) / wsum) if np.isfinite(v).any() else np.nan"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.642349700Z",
     "start_time": "2025-12-28T10:11:26.641349300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rotational symmetry score (structural proxy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def rotational_symmetry_proxy(df_img):\n",
    "    \"\"\"\n",
    "    CSV-only proxy:\n",
    "    - need centroids + angles\n",
    "    - estimate center (weighted centroid)\n",
    "    - take polar angles of regions around center\n",
    "    - measure how well angles align to a K-fold pattern (K=2..6), choose best\n",
    "    Output: 0..1\n",
    "    \"\"\"\n",
    "    xcol, ycol = _pick_centroid_cols(df_img)\n",
    "    if xcol is None:\n",
    "        return np.nan\n",
    "\n",
    "    if \"pca_angle_deg\" not in df_img.columns:\n",
    "        return np.nan\n",
    "\n",
    "    x = _as_float_series(df_img[xcol]).to_numpy()\n",
    "    y = _as_float_series(df_img[ycol]).to_numpy()\n",
    "    ang = _wrap180(_as_float_series(df_img[\"pca_angle_deg\"]).to_numpy())\n",
    "\n",
    "    ok = np.isfinite(x) & np.isfinite(y) & np.isfinite(ang)\n",
    "    if np.sum(ok) < 4:\n",
    "        return np.nan\n",
    "\n",
    "    w = _weights(df_img)[ok]\n",
    "    wsum = float(np.sum(w) + 1e-12)\n",
    "\n",
    "    cx = float(np.sum(x[ok] * w) / wsum)\n",
    "    cy = float(np.sum(y[ok] * w) / wsum)\n",
    "\n",
    "    # polar angles around center (0..2pi)\n",
    "    dx = x[ok] - cx\n",
    "    dy = y[ok] - cy\n",
    "    phi = np.arctan2(dy, dx)  # -pi..pi\n",
    "\n",
    "    # test K-fold regularity: we want phis to fall near multiples of 2pi/K\n",
    "    best = 0.0\n",
    "    for K in range(2, 7):\n",
    "        # map each phi to nearest lattice point\n",
    "        step = 2*np.pi / K\n",
    "        # distance to nearest multiple, normalized\n",
    "        d = np.abs(((phi + np.pi) % step) - step/2)  # 0..step/2-ish (cheap)\n",
    "        # turn into score: smaller d => higher score\n",
    "        d01 = np.clip(d / (step/2 + 1e-9), 0.0, 1.0)\n",
    "        score = float(1.0 - (np.sum(d01 * w) / wsum))\n",
    "        best = max(best, score)\n",
    "\n",
    "    return float(np.clip(best, 0.0, 1.0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.642349700Z",
     "start_time": "2025-12-28T10:11:26.642349700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Repetition / frieze-like regularity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def _descriptor_matrix(df_img):\n",
    "    # choose a stable descriptor set (only existing columns)\n",
    "    base = [\n",
    "        \"area_ratio\", \"pca_eig_ratio\", \"symmetry_pca\",\n",
    "        \"smoothness\", \"centeredness\", \"saliency\"\n",
    "    ]\n",
    "    cols = _safe_cols(df_img, base)\n",
    "\n",
    "    if not cols:\n",
    "        return None, []\n",
    "\n",
    "    X = df_img[cols].copy()\n",
    "    for c in cols:\n",
    "        X[c] = _as_float_series(X[c])\n",
    "    X = X.to_numpy(dtype=float)\n",
    "\n",
    "    # z-score (per image) to compare patterns inside same image\n",
    "    mu = np.nanmean(X, axis=0)\n",
    "    sd = np.nanstd(X, axis=0) + 1e-9\n",
    "    Xz = (X - mu) / sd\n",
    "    Xz = np.where(np.isfinite(Xz), Xz, 0.0)\n",
    "    return Xz, cols\n",
    "\n",
    "def _cos_sim(X):\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True) + 1e-9\n",
    "    U = X / norms\n",
    "    return U @ U.T\n",
    "\n",
    "def repetition_index(df_img, sim_threshold=0.88):\n",
    "    \"\"\"\n",
    "    Repetition density:\n",
    "    - build descriptor similarity matrix\n",
    "    - count how many near-duplicates (above threshold)\n",
    "    - normalize by N*(N-1)\n",
    "    Output: 0..1\n",
    "    \"\"\"\n",
    "    Xz, cols = _descriptor_matrix(df_img)\n",
    "    if Xz is None or len(df_img) < 2:\n",
    "        return np.nan, np.nan, cols\n",
    "\n",
    "    S = _cos_sim(Xz)\n",
    "    N = S.shape[0]\n",
    "    # ignore diagonal\n",
    "    mask = np.ones_like(S, dtype=bool)\n",
    "    np.fill_diagonal(mask, False)\n",
    "    sims = S[mask]\n",
    "\n",
    "    rep = float(np.mean(sims >= sim_threshold))  # 0..1\n",
    "\n",
    "    # spacing regularity (frieze-like): along dominant global axis if centroids exist\n",
    "    xcol, ycol = _pick_centroid_cols(df_img)\n",
    "    spacing01 = np.nan\n",
    "    if xcol is not None:\n",
    "        x = _as_float_series(df_img[xcol]).to_numpy()\n",
    "        y = _as_float_series(df_img[ycol]).to_numpy()\n",
    "        ok = np.isfinite(x) & np.isfinite(y)\n",
    "        if np.sum(ok) >= 4:\n",
    "            # dominant axis via PCA on centroids\n",
    "            pts = np.stack([x[ok], y[ok]], axis=1)\n",
    "            ctr = pts.mean(axis=0)\n",
    "            X = pts - ctr\n",
    "            C = (X.T @ X) / max(1, len(X)-1)\n",
    "            eigvals, eigvecs = np.linalg.eigh(C)\n",
    "            v = eigvecs[:, np.argmax(eigvals)]  # dominant direction\n",
    "            proj = X @ v                         # 1D projection\n",
    "            proj = np.sort(proj)\n",
    "            gaps = np.diff(proj)\n",
    "            gaps = gaps[gaps > 1e-9]\n",
    "            if len(gaps) >= 3:\n",
    "                cv = float(np.std(gaps) / (np.mean(gaps) + 1e-9))  # lower is more regular\n",
    "                spacing01 = float(np.clip(1.0 - cv, 0.0, 1.0))\n",
    "\n",
    "    return rep, spacing01, cols"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.671889300Z",
     "start_time": "2025-12-28T10:11:26.642349700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ornamentality index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def structural_surprise(df_img, Xz=None):\n",
    "    \"\"\"\n",
    "    Low â€œstructural surpriseâ€ = low diversity of descriptors.\n",
    "    Proxy: average distance of each region descriptor to the mean (normalized).\n",
    "    Output: 0..1 (higher = more surprise/variety)\n",
    "    \"\"\"\n",
    "    if Xz is None:\n",
    "        Xz, _ = _descriptor_matrix(df_img)\n",
    "    if Xz is None or len(df_img) < 2:\n",
    "        return np.nan\n",
    "\n",
    "    mu = np.mean(Xz, axis=0, keepdims=True)\n",
    "    d = np.linalg.norm(Xz - mu, axis=1)\n",
    "    # normalize by robust scale\n",
    "    d01 = float(np.clip(np.mean(d) / (np.percentile(d, 90) + 1e-9), 0.0, 1.0))\n",
    "    return d01\n",
    "\n",
    "def ornamentality_index(sym_ref_whole, sym_rot, rep, spacing01, surprise01):\n",
    "    \"\"\"\n",
    "    Ornamentality = high symmetry + high repetition + regular spacing + low surprise.\n",
    "    All inputs assumed 0..1.\n",
    "    Output: 0..1\n",
    "    \"\"\"\n",
    "    parts = [\n",
    "        sym_ref_whole,\n",
    "        (sym_rot if np.isfinite(sym_rot) else 0.0),\n",
    "        (rep if np.isfinite(rep) else 0.0),\n",
    "        (spacing01 if np.isfinite(spacing01) else 0.0),\n",
    "        (1.0 - surprise01 if np.isfinite(surprise01) else 0.0),\n",
    "    ]\n",
    "    # weights: symmetry+repetition dominate\n",
    "    w = np.array([0.28, 0.12, 0.28, 0.12, 0.20], dtype=float)\n",
    "    v = np.array([p if np.isfinite(p) else 0.0 for p in parts], dtype=float)\n",
    "    return float(np.clip(np.sum(w*v), 0.0, 1.0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.678404600Z",
     "start_time": "2025-12-28T10:11:26.643349400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Batch Computing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\3638786433.py:18: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\3638786433.py:18: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\3638786433.py:18: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\3638786433.py:18: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\3638786433.py:18: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\3638786433.py:18: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Form5] 25/128 done | split=real | image_id=real\\images\\Four_breasts_pink_purple_red_yellow.webp\n",
      "[Form5] 50/128 done | split=real | image_id=real\\images\\Overview_Effect_blue_red_mandala.webp\n",
      "[Form5] 75/128 done | split=generated | image_id=generated\\ComfyUI_00091_.png\n",
      "[Form5] 100/128 done | split=generated | image_id=generated\\ComfyUI_00126_.png\n",
      "[Form5] 125/128 done | split=generated | image_id=generated\\ComfyUI_00159_.png\n",
      "[Form5] 128/128 done | split=generated | image_id=generated\\ComfyUI_00163_.png\n",
      "Saved: outputs\\form5\\form5_region_indices.csv outputs\\form5\\form5_image_indices.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\3638786433.py:18: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\3638786433.py:18: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\3638786433.py:18: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\3638786433.py:18: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\3638786433.py:18: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\3638786433.py:18: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(X, axis=0)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "data": {
      "text/plain": "  split                                           image_id  \\\n0  real     real\\images\\10pm_feeding_around_the_clock.webp   \n1  real                              real\\images\\11pm.webp   \n2  real                         real\\images\\12_4_7_10.webp   \n3  real                      real\\images\\Belly_breast.webp   \n4  real  real\\images\\Belly_breast_face_brain_placenta.webp   \n5  real          real\\images\\Bellyscape_and_plumb_bob.webp   \n6  real  real\\images\\Birth_perspective_from_above_and_b...   \n7  real              real\\images\\Blue_0_with_red_halo.webp   \n8  real                          real\\images\\Blue_Nip.webp   \n9  real                          real\\images\\Blue_eye.webp   \n\n   form5_reflection_symmetry_whole_01  form5_rotational_symmetry_proxy_01  \\\n0                            0.391989                                 NaN   \n1                            0.182162                                 NaN   \n2                            0.932644                                 NaN   \n3                            0.267258                                 NaN   \n4                            0.988779                                 NaN   \n5                            0.988288                                 NaN   \n6                            0.888450                                 NaN   \n7                            0.997315                                 NaN   \n8                            0.284470                                 NaN   \n9                            0.378793                                 NaN   \n\n   form5_repetition_density_01  form5_spacing_regularity_01  \\\n0                     0.070175                          NaN   \n1                          NaN                          NaN   \n2                          NaN                          NaN   \n3                     0.000000                          NaN   \n4                          NaN                          NaN   \n5                          NaN                          NaN   \n6                          NaN                          NaN   \n7                          NaN                          NaN   \n8                     0.000000                          NaN   \n9                          NaN                          NaN   \n\n   form5_structural_surprise_01  form5_ornamentality_index_01  n_regions  \\\n0                      0.704366                      0.188533         19   \n1                           NaN                      0.051005          1   \n2                           NaN                      0.261140          1   \n3                      0.810257                      0.112781          7   \n4                           NaN                      0.276858          1   \n5                           NaN                      0.276721          1   \n6                           NaN                      0.248766          1   \n7                           NaN                      0.279248          1   \n8                      1.000000                      0.079652          2   \n9                           NaN                      0.106062          1   \n\n                                descriptor_cols_used  rep_sim_threshold  \n0  area_ratio,pca_eig_ratio,symmetry_pca,smoothne...               0.88  \n1  area_ratio,pca_eig_ratio,symmetry_pca,smoothne...               0.88  \n2  area_ratio,pca_eig_ratio,symmetry_pca,smoothne...               0.88  \n3  area_ratio,pca_eig_ratio,symmetry_pca,smoothne...               0.88  \n4  area_ratio,pca_eig_ratio,symmetry_pca,smoothne...               0.88  \n5  area_ratio,pca_eig_ratio,symmetry_pca,smoothne...               0.88  \n6  area_ratio,pca_eig_ratio,symmetry_pca,smoothne...               0.88  \n7  area_ratio,pca_eig_ratio,symmetry_pca,smoothne...               0.88  \n8  area_ratio,pca_eig_ratio,symmetry_pca,smoothne...               0.88  \n9  area_ratio,pca_eig_ratio,symmetry_pca,smoothne...               0.88  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>split</th>\n      <th>image_id</th>\n      <th>form5_reflection_symmetry_whole_01</th>\n      <th>form5_rotational_symmetry_proxy_01</th>\n      <th>form5_repetition_density_01</th>\n      <th>form5_spacing_regularity_01</th>\n      <th>form5_structural_surprise_01</th>\n      <th>form5_ornamentality_index_01</th>\n      <th>n_regions</th>\n      <th>descriptor_cols_used</th>\n      <th>rep_sim_threshold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>real</td>\n      <td>real\\images\\10pm_feeding_around_the_clock.webp</td>\n      <td>0.391989</td>\n      <td>NaN</td>\n      <td>0.070175</td>\n      <td>NaN</td>\n      <td>0.704366</td>\n      <td>0.188533</td>\n      <td>19</td>\n      <td>area_ratio,pca_eig_ratio,symmetry_pca,smoothne...</td>\n      <td>0.88</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>real</td>\n      <td>real\\images\\11pm.webp</td>\n      <td>0.182162</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.051005</td>\n      <td>1</td>\n      <td>area_ratio,pca_eig_ratio,symmetry_pca,smoothne...</td>\n      <td>0.88</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>real</td>\n      <td>real\\images\\12_4_7_10.webp</td>\n      <td>0.932644</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.261140</td>\n      <td>1</td>\n      <td>area_ratio,pca_eig_ratio,symmetry_pca,smoothne...</td>\n      <td>0.88</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>real</td>\n      <td>real\\images\\Belly_breast.webp</td>\n      <td>0.267258</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.810257</td>\n      <td>0.112781</td>\n      <td>7</td>\n      <td>area_ratio,pca_eig_ratio,symmetry_pca,smoothne...</td>\n      <td>0.88</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>real</td>\n      <td>real\\images\\Belly_breast_face_brain_placenta.webp</td>\n      <td>0.988779</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.276858</td>\n      <td>1</td>\n      <td>area_ratio,pca_eig_ratio,symmetry_pca,smoothne...</td>\n      <td>0.88</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>real</td>\n      <td>real\\images\\Bellyscape_and_plumb_bob.webp</td>\n      <td>0.988288</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.276721</td>\n      <td>1</td>\n      <td>area_ratio,pca_eig_ratio,symmetry_pca,smoothne...</td>\n      <td>0.88</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>real</td>\n      <td>real\\images\\Birth_perspective_from_above_and_b...</td>\n      <td>0.888450</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.248766</td>\n      <td>1</td>\n      <td>area_ratio,pca_eig_ratio,symmetry_pca,smoothne...</td>\n      <td>0.88</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>real</td>\n      <td>real\\images\\Blue_0_with_red_halo.webp</td>\n      <td>0.997315</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.279248</td>\n      <td>1</td>\n      <td>area_ratio,pca_eig_ratio,symmetry_pca,smoothne...</td>\n      <td>0.88</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>real</td>\n      <td>real\\images\\Blue_Nip.webp</td>\n      <td>0.284470</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>0.079652</td>\n      <td>2</td>\n      <td>area_ratio,pca_eig_ratio,symmetry_pca,smoothne...</td>\n      <td>0.88</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>real</td>\n      <td>real\\images\\Blue_eye.webp</td>\n      <td>0.378793</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.106062</td>\n      <td>1</td>\n      <td>area_ratio,pca_eig_ratio,symmetry_pca,smoothne...</td>\n      <td>0.88</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_region = []\n",
    "rows_image  = []\n",
    "\n",
    "# tuning knobs\n",
    "REP_SIM_THRESHOLD = 0.88\n",
    "\n",
    "# progress without extra deps\n",
    "groups = list(df_regions.groupby([\"split\",\"image_id\"], sort=False))\n",
    "total = len(groups)\n",
    "\n",
    "for gi, ((split, image_id), g) in enumerate(groups, start=1):\n",
    "    df_img = g.copy().reset_index(drop=True)\n",
    "\n",
    "    # Per-region reflection symmetry\n",
    "    sym_ref_r = np.array([reflection_symmetry_region(r) for _, r in df_img.iterrows()], dtype=float)\n",
    "\n",
    "    # Whole reflection symmetry (weighted)\n",
    "    sym_ref_wh = reflection_symmetry_whole(df_img)\n",
    "\n",
    "    # Rotational symmetry proxy\n",
    "    sym_rot = rotational_symmetry_proxy(df_img)\n",
    "\n",
    "    # Repetition + spacing regularity\n",
    "    rep01, spacing01, desc_cols = repetition_index(df_img, sim_threshold=REP_SIM_THRESHOLD)\n",
    "\n",
    "    # Surprise\n",
    "    Xz, _ = _descriptor_matrix(df_img)\n",
    "    surprise01 = structural_surprise(df_img, Xz=Xz)\n",
    "\n",
    "    # Ornamentality\n",
    "    orn01 = ornamentality_index(sym_ref_wh, sym_rot, rep01, spacing01, surprise01)\n",
    "\n",
    "    # Per-region rows\n",
    "    for i, r in df_img.iterrows():\n",
    "        rows_region.append({\n",
    "            \"split\": split,\n",
    "            \"image_id\": image_id,\n",
    "            \"region_index\": int(r[\"region_index\"]) if \"region_index\" in df_img.columns else int(i),\n",
    "\n",
    "            \"form5_reflection_symmetry_region_01\": float(sym_ref_r[i]) if np.isfinite(sym_ref_r[i]) else np.nan,\n",
    "            \"form5_reflection_symmetry_whole_01\": float(sym_ref_wh) if np.isfinite(sym_ref_wh) else np.nan,\n",
    "\n",
    "            # optional: keep useful context\n",
    "            \"pca_angle_deg\": float(_as_float_scalar(r.get(\"pca_angle_deg\", np.nan))),\n",
    "        })\n",
    "\n",
    "    # Per-image summary row\n",
    "    rows_image.append({\n",
    "        \"split\": split,\n",
    "        \"image_id\": image_id,\n",
    "\n",
    "        \"form5_reflection_symmetry_whole_01\": float(sym_ref_wh) if np.isfinite(sym_ref_wh) else np.nan,\n",
    "        \"form5_rotational_symmetry_proxy_01\": float(sym_rot) if np.isfinite(sym_rot) else np.nan,\n",
    "\n",
    "        \"form5_repetition_density_01\": float(rep01) if np.isfinite(rep01) else np.nan,\n",
    "        \"form5_spacing_regularity_01\": float(spacing01) if np.isfinite(spacing01) else np.nan,\n",
    "\n",
    "        \"form5_structural_surprise_01\": float(surprise01) if np.isfinite(surprise01) else np.nan,\n",
    "        \"form5_ornamentality_index_01\": float(orn01) if np.isfinite(orn01) else np.nan,\n",
    "\n",
    "        \"n_regions\": int(len(df_img)),\n",
    "        \"descriptor_cols_used\": \",\".join(desc_cols),\n",
    "        \"rep_sim_threshold\": float(REP_SIM_THRESHOLD),\n",
    "    })\n",
    "\n",
    "    if gi % 25 == 0 or gi == total:\n",
    "        print(f\"[Form5] {gi}/{total} done | split={split} | image_id={image_id}\")\n",
    "\n",
    "df_form5_region = pd.DataFrame(rows_region)\n",
    "df_form5_image  = pd.DataFrame(rows_image)\n",
    "\n",
    "# Save\n",
    "OUT_FORM5_DIR = r\"outputs\\form5\"\n",
    "import os\n",
    "os.makedirs(OUT_FORM5_DIR, exist_ok=True)\n",
    "\n",
    "df_form5_region.to_csv(os.path.join(OUT_FORM5_DIR, \"form5_region_indices.csv\"), index=False)\n",
    "df_form5_image.to_csv(os.path.join(OUT_FORM5_DIR, \"form5_image_indices.csv\"), index=False)\n",
    "\n",
    "print(\"Saved:\",\n",
    "      os.path.join(OUT_FORM5_DIR, \"form5_region_indices.csv\"),\n",
    "      os.path.join(OUT_FORM5_DIR, \"form5_image_indices.csv\"))\n",
    "df_form5_image.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.679405Z",
     "start_time": "2025-12-28T10:11:26.643349400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Abstraction level & â€œform as inventionâ€ proxies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"data\")  # expects data/real and data/generated\n",
    "OUT_DIR = Path(\"outputs/form6\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.680404700Z",
     "start_time": "2025-12-28T10:11:26.644859800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Edge Pipe (Repeated as Before)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "SIGMAS = (1, 2, 4)\n",
    "EDGE_PERCENTILE = 85.0\n",
    "MIN_AREA_RATIO = 0.00005\n",
    "CLOSE_K_RATIO = 0.004\n",
    "CLOSE_ITERS = 1\n",
    "\n",
    "def read_image_bgr(path: str) -> np.ndarray:\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(path)\n",
    "    if img.ndim == 2:\n",
    "        return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    if img.shape[2] == 4:\n",
    "        bgr = img[:, :, :3].astype(np.float32)\n",
    "        alpha = img[:, :, 3:4].astype(np.float32) / 255.0\n",
    "        white = np.full_like(bgr, 255.0, dtype=np.float32)\n",
    "        comp = bgr * alpha + white * (1.0 - alpha)\n",
    "        return np.clip(comp, 0, 255).astype(np.uint8)\n",
    "    return img[:, :, :3]\n",
    "\n",
    "def preprocess_gray01(path: str) -> np.ndarray:\n",
    "    bgr = read_image_bgr(path)\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0\n",
    "    gray = cv2.GaussianBlur(gray, (0,0), 1.2)\n",
    "    return gray\n",
    "\n",
    "def gaussian_blur(gray_f: np.ndarray, sigma: float) -> np.ndarray:\n",
    "    return cv2.GaussianBlur(gray_f, (0, 0), sigmaX=sigma, sigmaY=sigma)\n",
    "\n",
    "def sobel_magnitude(gray_f: np.ndarray) -> np.ndarray:\n",
    "    gx = cv2.Sobel(gray_f, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(gray_f, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    return cv2.magnitude(gx, gy)\n",
    "\n",
    "def normalize_01(x: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "    x = x.astype(np.float32)\n",
    "    mn, mx = float(np.min(x)), float(np.max(x))\n",
    "    return (x - mn) / (mx - mn + eps)\n",
    "\n",
    "def multiscale_edge_strength(gray_f: np.ndarray, sigmas=(1,2,4)):\n",
    "    mags = []\n",
    "    for s in sigmas:\n",
    "        sm = gaussian_blur(gray_f, float(s))\n",
    "        mag = sobel_magnitude(sm)\n",
    "        mags.append(normalize_01(mag))\n",
    "    return np.max(np.stack(mags, axis=0), axis=0)\n",
    "\n",
    "def remove_small_components(binary01: np.ndarray, min_area_px: int) -> np.ndarray:\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(binary01.astype(np.uint8), connectivity=8)\n",
    "    out = np.zeros_like(binary01, dtype=np.uint8)\n",
    "    for i in range(1, num):\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_area_px:\n",
    "            out[labels == i] = 1\n",
    "    return out\n",
    "\n",
    "def morph_close(binary01: np.ndarray, k: int, iters: int) -> np.ndarray:\n",
    "    if k % 2 == 0: k += 1\n",
    "    k = max(3, int(k))\n",
    "    ker = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k,k))\n",
    "    closed = cv2.morphologyEx((binary01*255).astype(np.uint8), cv2.MORPH_CLOSE, ker, iterations=int(iters))\n",
    "    return (closed > 0).astype(np.uint8)\n",
    "\n",
    "def make_edge_maps(gray01: np.ndarray):\n",
    "    H, W = gray01.shape\n",
    "    E = multiscale_edge_strength(gray01, sigmas=SIGMAS)\n",
    "    thr = np.percentile(E, EDGE_PERCENTILE)\n",
    "    Eb = (E >= thr).astype(np.uint8)\n",
    "\n",
    "    min_area_px = int(max(10, round(MIN_AREA_RATIO * H * W)))\n",
    "    Eb = remove_small_components(Eb, min_area_px=min_area_px)\n",
    "\n",
    "    k = int(max(3, round(CLOSE_K_RATIO * min(H, W))))\n",
    "    Eb = morph_close(Eb, k=k, iters=CLOSE_ITERS)\n",
    "    return E, Eb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.681404800Z",
     "start_time": "2025-12-28T10:11:26.644859800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Iter Images (same as before)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def iter_images(data_root: Path):\n",
    "    for split in [\"real\", \"generated\"]:\n",
    "        base = data_root / split\n",
    "        if not base.exists():\n",
    "            continue\n",
    "        for p in base.rglob(\"*\"):\n",
    "            if p.suffix.lower() in [\".png\",\".jpg\",\".jpeg\",\".webp\",\".tif\",\".tiff\",\".bmp\"]:\n",
    "                rel = str(p.relative_to(data_root)).replace(\"\\\\\", \"/\")\n",
    "                yield split, rel, str(p)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.681404800Z",
     "start_time": "2025-12-28T10:11:26.645863700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Geometricization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### edge pixels explained by straight lines + circles (approx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def geometricization_score(Eb01: np.ndarray):\n",
    "    H, W = Eb01.shape\n",
    "    edge_px = int(Eb01.sum())\n",
    "    if edge_px <= 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    # Use Canny on Eb to get proper 0/255 edges for Hough\n",
    "    edges255 = (Eb01 * 255).astype(np.uint8)\n",
    "\n",
    "    # (a) Lines via Probabilistic Hough\n",
    "    min_line_len = max(20, int(0.03 * min(H, W)))\n",
    "    max_gap = max(3, int(0.01 * min(H, W)))\n",
    "    lines = cv2.HoughLinesP(\n",
    "        edges255, rho=1, theta=np.pi/180,\n",
    "        threshold=80, minLineLength=min_line_len, maxLineGap=max_gap\n",
    "    )\n",
    "\n",
    "    line_cover = np.zeros((H, W), np.uint8)\n",
    "    if lines is not None:\n",
    "        for (x1,y1,x2,y2) in lines[:,0,:]:\n",
    "            cv2.line(line_cover, (x1,y1), (x2,y2), 1, thickness=1)\n",
    "    line_hits = int((line_cover & Eb01).sum())\n",
    "\n",
    "    # (b) Circles via HoughCircles (often returns none; that's ok)\n",
    "    # We run on a blurred grayscale derived from edges to stabilize.\n",
    "    blur = cv2.GaussianBlur(edges255, (0,0), 1.2)\n",
    "    circles = cv2.HoughCircles(\n",
    "        blur, cv2.HOUGH_GRADIENT,\n",
    "        dp=1.2, minDist=max(15, int(0.06 * min(H,W))),\n",
    "        param1=120, param2=18,\n",
    "        minRadius=max(8, int(0.015 * min(H,W))),\n",
    "        maxRadius=int(0.45 * min(H,W))\n",
    "    )\n",
    "\n",
    "    circ_cover = np.zeros((H, W), np.uint8)\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0]).astype(int)\n",
    "        # Draw only a thin perimeter (arc proxy)\n",
    "        for (cx, cy, r) in circles[:12]:  # cap to avoid crazy overdraw\n",
    "            if r <= 0:\n",
    "                continue\n",
    "            cv2.circle(circ_cover, (cx,cy), r, 1, thickness=1)\n",
    "    circ_hits = int((circ_cover & Eb01).sum())\n",
    "\n",
    "    # Combined (avoid double count by OR)\n",
    "    geom_cover = ((line_cover | circ_cover) & Eb01).sum()\n",
    "    geom01 = float(geom_cover / (edge_px + 1e-9))\n",
    "    line01 = float(line_hits / (edge_px + 1e-9))\n",
    "    circ01 = float(circ_hits / (edge_px + 1e-9))\n",
    "\n",
    "    return float(np.clip(geom01, 0.0, 1.0)), float(np.clip(line01, 0.0, 1.0)), float(np.clip(circ01, 0.0, 1.0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.682405600Z",
     "start_time": "2025-12-28T10:11:26.645863700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Structural Economy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\"How many salient parts explain most of the mass?\"\n",
    "Uses df_regions if present; otherwise fallback to edge components count."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def economy_from_regions(df_img_regions: pd.DataFrame, target_mass=0.80):\n",
    "    if df_img_regions is None or len(df_img_regions) == 0:\n",
    "        return np.nan, np.nan, 0\n",
    "\n",
    "    # choose weights: saliency if available, else area_ratio, else area_px\n",
    "    if \"saliency\" in df_img_regions.columns and np.isfinite(df_img_regions[\"saliency\"].to_numpy(dtype=float)).any():\n",
    "        w = pd.to_numeric(df_img_regions[\"saliency\"], errors=\"coerce\").astype(float).fillna(0.0).to_numpy()\n",
    "    elif \"area_ratio\" in df_img_regions.columns and np.isfinite(df_img_regions[\"area_ratio\"].to_numpy(dtype=float)).any():\n",
    "        w = pd.to_numeric(df_img_regions[\"area_ratio\"], errors=\"coerce\").astype(float).fillna(0.0).to_numpy()\n",
    "    elif \"area_px\" in df_img_regions.columns:\n",
    "        w = pd.to_numeric(df_img_regions[\"area_px\"], errors=\"coerce\").astype(float).fillna(0.0).to_numpy()\n",
    "    else:\n",
    "        return np.nan, np.nan, int(len(df_img_regions))\n",
    "\n",
    "    w = np.maximum(w, 0.0)\n",
    "    tot = float(w.sum())\n",
    "    if tot <= 1e-12:\n",
    "        return np.nan, np.nan, int(len(df_img_regions))\n",
    "\n",
    "    idx = np.argsort(-w)\n",
    "    cum = np.cumsum(w[idx]) / (tot + 1e-12)\n",
    "    k = int(np.searchsorted(cum, target_mass) + 1)  # parts needed\n",
    "    k = max(1, min(k, len(w)))\n",
    "\n",
    "    # map to 0..1 where higher=more economical\n",
    "    # economy01 = 1 - (k-1)/(n-1)\n",
    "    n = int(len(w))\n",
    "    economy01 = 1.0 if n <= 1 else 1.0 - ((k - 1) / (n - 1))\n",
    "    return float(np.clip(economy01, 0.0, 1.0)), float(k), n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.682405600Z",
     "start_time": "2025-12-28T10:11:26.645863700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clutter proxies + compression-like proxy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import zlib\n",
    "\n",
    "\n",
    "def compression_proxy(Eb01: np.ndarray):\n",
    "    # A simple, stable proxy:\n",
    "    # compress raw bits with zlib and normalize by pixels\n",
    "    raw = Eb01.astype(np.uint8).tobytes()\n",
    "    comp = zlib.compress(raw, level=6)\n",
    "    return float(len(comp) / (Eb01.size + 1e-9))\n",
    "\n",
    "def connected_edge_components(Eb01: np.ndarray):\n",
    "    num, labels, stats, _ = cv2.connectedComponentsWithStats(Eb01.astype(np.uint8), connectivity=8)\n",
    "    # components excluding background\n",
    "    sizes = stats[1:, cv2.CC_STAT_AREA] if num > 1 else np.array([], dtype=int)\n",
    "    return int(max(0, num-1)), sizes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.682405600Z",
     "start_time": "2025-12-28T10:11:26.645863700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Skeleton complexity from df_regions (you already have skeleton graph features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def skeleton_complexity_from_regions(df_img_regions: pd.DataFrame):\n",
    "    if df_img_regions is None or len(df_img_regions) == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "    def colsum(name):\n",
    "        if name not in df_img_regions.columns:\n",
    "            return np.nan\n",
    "        v = pd.to_numeric(df_img_regions[name], errors=\"coerce\").astype(float).to_numpy()\n",
    "        v = v[np.isfinite(v)]\n",
    "        return float(v.sum()) if len(v) else np.nan\n",
    "\n",
    "    # total branch/junction/edge mass proxies\n",
    "    n_junc = colsum(\"n_junctions\")\n",
    "    n_endp = colsum(\"n_endpoints\")\n",
    "    n_edges = colsum(\"n_edges\")\n",
    "    skel_mass = colsum(\"skel_mass_px\")\n",
    "\n",
    "    # normalized complexity index (soft saturation)\n",
    "    # you can tweak weights anytime; this is stable and monotonic\n",
    "    parts = []\n",
    "    for v, w in [(n_junc, 1.0), (n_edges, 0.6), (n_endp, 0.5), (skel_mass, 0.001)]:\n",
    "        if np.isfinite(v):\n",
    "            parts.append(w * np.log1p(max(v, 0.0)))\n",
    "    if not parts:\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "    raw = float(np.sum(parts))\n",
    "    # map raw -> 0..1 with a soft cap\n",
    "    comp01 = float(np.clip(raw / 10.0, 0.0, 1.0))\n",
    "    return comp01, n_junc, n_edges"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:11:26.682405600Z",
     "start_time": "2025-12-28T10:11:26.646862600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Batch Run"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found images: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Form-6 batch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 130/130 [04:57<00:00,  2.29s/img] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: outputs\\form6\\form6_image_indices.csv rows= 130\n",
      "Saved: outputs\\form6\\form6_region_economy.csv rows= 366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "  split                                           image_id    H     W  \\\n0  real     real/images/10pm_feeding_around_the_clock.webp  749   750   \n1  real                              real/images/11pm.webp  642   500   \n2  real                         real/images/12_4_7_10.webp  749   750   \n3  real                  real/images/around_the_clock.webp  799   750   \n4  real         real/images/around_the_clock_alizarin.webp  704  1000   \n5  real          real/images/Bellyscape_and_plumb_bob.webp  595   750   \n6  real                      real/images/Belly_breast.webp  667  1000   \n7  real  real/images/Belly_breast_face_brain_placenta.webp  680   750   \n8  real  real/images/Birth_perspective_from_above_and_b...  571   750   \n9  real              real/images/Blue_0_with_red_halo.webp  640   500   \n\n   edge_density_01  edge_cc_count  edge_cc_entropy_01  compression_proxy  \\\n0         0.150277             37            0.637317           0.017490   \n1         0.150075              2            0.013210           0.009798   \n2         0.151121             78            0.392085           0.018555   \n3         0.150061             20            0.550538           0.014752   \n4         0.150786              1                 NaN           0.008784   \n5         0.151760              5            0.044018           0.011787   \n6         0.147070            157            0.618057           0.026880   \n7         0.148355             71            0.394676           0.023055   \n8         0.148619             48            0.376538           0.022291   \n9         0.152359              1                 NaN           0.009978   \n\n   form6_geometricization_01  form6_line_explained_01  \\\n0                   0.604516                 0.582163   \n1                   0.792564                 0.779964   \n2                   0.635266                 0.621872   \n3                   0.617221                 0.593746   \n4                   0.792140                 0.783605   \n5                   0.702361                 0.685026   \n6                   0.549706                 0.527463   \n7                   0.626650                 0.601049   \n8                   0.579047                 0.548817   \n9                   0.726346                 0.700564   \n\n   form6_circle_explained_01  form6_structural_economy_01  \\\n0                   0.054976                     0.222222   \n1                   0.046104                     1.000000   \n2                   0.039662                     1.000000   \n3                   0.059339                     1.000000   \n4                   0.040074                     1.000000   \n5                   0.058075                     1.000000   \n6                   0.041847                     0.166667   \n7                   0.052722                     1.000000   \n8                   0.066257                     1.000000   \n9                   0.064465                     1.000000   \n\n   form6_parts_to_explain_80pct  n_regions  form6_skeletal_complexity_01  \\\n0                          15.0         19                      1.000000   \n1                           1.0          1                      0.770513   \n2                           1.0          1                      0.000000   \n3                           1.0          1                      0.096888   \n4                           1.0          1                      0.097085   \n5                           1.0          1                      0.097018   \n6                           6.0          7                      1.000000   \n7                           1.0          1                      1.000000   \n8                           1.0          1                      1.000000   \n9                           1.0          1                      0.097011   \n\n   skel_junctions_sum  skel_edges_sum  form6_clutter_complexity_01  \n0              1359.0          2207.0                     0.449646  \n1                80.0           137.0                     0.228617  \n2                 0.0             0.0                     0.276996  \n3                 0.0             1.0                     0.218470  \n4                 0.0             1.0                     0.089770  \n5                 0.0             1.0                     0.106782  \n6              2276.0          3763.0                     0.551146  \n7               695.0          1381.0                     0.467993  \n8               815.0          1553.0                     0.430769  \n9                 0.0             1.0                     0.090464  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>split</th>\n      <th>image_id</th>\n      <th>H</th>\n      <th>W</th>\n      <th>edge_density_01</th>\n      <th>edge_cc_count</th>\n      <th>edge_cc_entropy_01</th>\n      <th>compression_proxy</th>\n      <th>form6_geometricization_01</th>\n      <th>form6_line_explained_01</th>\n      <th>form6_circle_explained_01</th>\n      <th>form6_structural_economy_01</th>\n      <th>form6_parts_to_explain_80pct</th>\n      <th>n_regions</th>\n      <th>form6_skeletal_complexity_01</th>\n      <th>skel_junctions_sum</th>\n      <th>skel_edges_sum</th>\n      <th>form6_clutter_complexity_01</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>real</td>\n      <td>real/images/10pm_feeding_around_the_clock.webp</td>\n      <td>749</td>\n      <td>750</td>\n      <td>0.150277</td>\n      <td>37</td>\n      <td>0.637317</td>\n      <td>0.017490</td>\n      <td>0.604516</td>\n      <td>0.582163</td>\n      <td>0.054976</td>\n      <td>0.222222</td>\n      <td>15.0</td>\n      <td>19</td>\n      <td>1.000000</td>\n      <td>1359.0</td>\n      <td>2207.0</td>\n      <td>0.449646</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>real</td>\n      <td>real/images/11pm.webp</td>\n      <td>642</td>\n      <td>500</td>\n      <td>0.150075</td>\n      <td>2</td>\n      <td>0.013210</td>\n      <td>0.009798</td>\n      <td>0.792564</td>\n      <td>0.779964</td>\n      <td>0.046104</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.770513</td>\n      <td>80.0</td>\n      <td>137.0</td>\n      <td>0.228617</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>real</td>\n      <td>real/images/12_4_7_10.webp</td>\n      <td>749</td>\n      <td>750</td>\n      <td>0.151121</td>\n      <td>78</td>\n      <td>0.392085</td>\n      <td>0.018555</td>\n      <td>0.635266</td>\n      <td>0.621872</td>\n      <td>0.039662</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.276996</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>real</td>\n      <td>real/images/around_the_clock.webp</td>\n      <td>799</td>\n      <td>750</td>\n      <td>0.150061</td>\n      <td>20</td>\n      <td>0.550538</td>\n      <td>0.014752</td>\n      <td>0.617221</td>\n      <td>0.593746</td>\n      <td>0.059339</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.096888</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.218470</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>real</td>\n      <td>real/images/around_the_clock_alizarin.webp</td>\n      <td>704</td>\n      <td>1000</td>\n      <td>0.150786</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.008784</td>\n      <td>0.792140</td>\n      <td>0.783605</td>\n      <td>0.040074</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.097085</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.089770</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>real</td>\n      <td>real/images/Bellyscape_and_plumb_bob.webp</td>\n      <td>595</td>\n      <td>750</td>\n      <td>0.151760</td>\n      <td>5</td>\n      <td>0.044018</td>\n      <td>0.011787</td>\n      <td>0.702361</td>\n      <td>0.685026</td>\n      <td>0.058075</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.097018</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.106782</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>real</td>\n      <td>real/images/Belly_breast.webp</td>\n      <td>667</td>\n      <td>1000</td>\n      <td>0.147070</td>\n      <td>157</td>\n      <td>0.618057</td>\n      <td>0.026880</td>\n      <td>0.549706</td>\n      <td>0.527463</td>\n      <td>0.041847</td>\n      <td>0.166667</td>\n      <td>6.0</td>\n      <td>7</td>\n      <td>1.000000</td>\n      <td>2276.0</td>\n      <td>3763.0</td>\n      <td>0.551146</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>real</td>\n      <td>real/images/Belly_breast_face_brain_placenta.webp</td>\n      <td>680</td>\n      <td>750</td>\n      <td>0.148355</td>\n      <td>71</td>\n      <td>0.394676</td>\n      <td>0.023055</td>\n      <td>0.626650</td>\n      <td>0.601049</td>\n      <td>0.052722</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1.000000</td>\n      <td>695.0</td>\n      <td>1381.0</td>\n      <td>0.467993</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>real</td>\n      <td>real/images/Birth_perspective_from_above_and_b...</td>\n      <td>571</td>\n      <td>750</td>\n      <td>0.148619</td>\n      <td>48</td>\n      <td>0.376538</td>\n      <td>0.022291</td>\n      <td>0.579047</td>\n      <td>0.548817</td>\n      <td>0.066257</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1.000000</td>\n      <td>815.0</td>\n      <td>1553.0</td>\n      <td>0.430769</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>real</td>\n      <td>real/images/Blue_0_with_red_halo.webp</td>\n      <td>640</td>\n      <td>500</td>\n      <td>0.152359</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0.009978</td>\n      <td>0.726346</td>\n      <td>0.700564</td>\n      <td>0.064465</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0.097011</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.090464</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "rows_img = []\n",
    "rows_reg_econ = []\n",
    "\n",
    "# Build a quick lookup from df_regions (assumes you already loaded it)\n",
    "# df_regions columns include: split, image_id, region_index, area_ratio, saliency, ...\n",
    "df_regions = df_regions.copy()\n",
    "df_regions[\"split\"] = df_regions[\"split\"].astype(str)\n",
    "df_regions[\"image_id\"] = (\n",
    "    df_regions[\"image_id\"]\n",
    "        .astype(str)\n",
    "        .str.replace(\"\\\\\", \"/\", regex=False)   # fix backslashes\n",
    ")\n",
    "\n",
    "regions_lookup = {(s, iid): g.copy()\n",
    "                  for (s, iid), g in df_regions.groupby([\"split\",\"image_id\"], sort=False)}\n",
    "\n",
    "img_list = list(iter_images(DATA_ROOT))\n",
    "print(\"Found images:\", len(img_list))\n",
    "\n",
    "for split, image_id, path in tqdm(img_list, desc=\"Form-6 batch\", unit=\"img\"):\n",
    "    gray01 = preprocess_gray01(path)\n",
    "    E01, Eb01 = make_edge_maps(gray01)\n",
    "\n",
    "    H, W = Eb01.shape\n",
    "    diag = float(np.hypot(H, W))\n",
    "\n",
    "    # (1) Geometricization\n",
    "    geom01, line01, circ01 = geometricization_score(Eb01)\n",
    "\n",
    "    # (2) Economy (region-based)\n",
    "    df_img_regions = regions_lookup.get((split, image_id), None)\n",
    "    econ01, econ_k, n_regions = economy_from_regions(df_img_regions, target_mass=0.80)\n",
    "\n",
    "    # Store region economy detail (optional but useful)\n",
    "    if df_img_regions is not None and len(df_img_regions) > 0:\n",
    "        # ranked contribution curve\n",
    "        if \"saliency\" in df_img_regions.columns and np.isfinite(pd.to_numeric(df_img_regions[\"saliency\"], errors=\"coerce\")).any():\n",
    "            w = pd.to_numeric(df_img_regions[\"saliency\"], errors=\"coerce\").astype(float).fillna(0.0).to_numpy()\n",
    "            w_name = \"saliency\"\n",
    "        elif \"area_ratio\" in df_img_regions.columns:\n",
    "            w = pd.to_numeric(df_img_regions[\"area_ratio\"], errors=\"coerce\").astype(float).fillna(0.0).to_numpy()\n",
    "            w_name = \"area_ratio\"\n",
    "        else:\n",
    "            w = pd.to_numeric(df_img_regions.get(\"area_px\", 0.0), errors=\"coerce\").astype(float).fillna(0.0).to_numpy()\n",
    "            w_name = \"area_px\"\n",
    "        w = np.maximum(w, 0.0)\n",
    "        tot = float(w.sum() + 1e-12)\n",
    "        order = np.argsort(-w)\n",
    "        cum = np.cumsum(w[order]) / tot\n",
    "        for rank, idx in enumerate(order[: min(len(order), 25)], start=1):  # cap\n",
    "            rows_reg_econ.append({\n",
    "                \"split\": split,\n",
    "                \"image_id\": image_id,\n",
    "                \"region_index\": int(df_img_regions.iloc[idx][\"region_index\"]) if \"region_index\" in df_img_regions.columns else int(idx),\n",
    "                \"rank\": int(rank),\n",
    "                \"weight_col\": w_name,\n",
    "                \"weight\": float(w[idx]),\n",
    "                \"cum_mass_01\": float(cum[rank-1]),\n",
    "            })\n",
    "\n",
    "    # (3) Clutter proxies\n",
    "    edge_density_01 = float(Eb01.mean())\n",
    "    n_cc, cc_sizes = connected_edge_components(Eb01)\n",
    "    cc_entropy = np.nan\n",
    "    if len(cc_sizes) >= 2:\n",
    "        p = cc_sizes.astype(float) / (cc_sizes.sum() + 1e-12)\n",
    "        cc_entropy = float(-(p * np.log(p + 1e-12)).sum() / np.log(len(p) + 1e-12))  # normalized 0..1\n",
    "\n",
    "    comp_ratio = compression_proxy(Eb01)\n",
    "\n",
    "    # (4) Skeleton complexity (from df_regions)\n",
    "    sk_comp01, sk_junc_sum, sk_edges_sum = skeleton_complexity_from_regions(df_img_regions)\n",
    "\n",
    "    # A combined â€œclutter/complexityâ€ index (0..1) â€” optional but nice for thesis\n",
    "    # (more edges + more components + higher entropy + higher skeleton complexity)\n",
    "    cc01 = float(np.clip(\n",
    "        0.45*edge_density_01 +\n",
    "        0.20*np.tanh(n_cc / 80.0) +\n",
    "        0.15*(cc_entropy if np.isfinite(cc_entropy) else 0.0) +\n",
    "        0.20*(sk_comp01 if np.isfinite(sk_comp01) else 0.0),\n",
    "        0.0, 1.0\n",
    "    ))\n",
    "\n",
    "    rows_img.append({\n",
    "        \"split\": split,\n",
    "        \"image_id\": image_id,\n",
    "        \"H\": int(H), \"W\": int(W),\n",
    "        \"edge_density_01\": edge_density_01,\n",
    "        \"edge_cc_count\": int(n_cc),\n",
    "        \"edge_cc_entropy_01\": (cc_entropy if np.isfinite(cc_entropy) else np.nan),\n",
    "        \"compression_proxy\": float(comp_ratio),\n",
    "\n",
    "        # Form-6 outputs\n",
    "        \"form6_geometricization_01\": float(geom01),\n",
    "        \"form6_line_explained_01\": float(line01),\n",
    "        \"form6_circle_explained_01\": float(circ01),\n",
    "\n",
    "        \"form6_structural_economy_01\": (float(econ01) if np.isfinite(econ01) else np.nan),\n",
    "        \"form6_parts_to_explain_80pct\": (float(econ_k) if np.isfinite(econ_k) else np.nan),\n",
    "        \"n_regions\": int(n_regions) if np.isfinite(n_regions) else (int(len(df_img_regions)) if df_img_regions is not None else 0),\n",
    "\n",
    "        \"form6_skeletal_complexity_01\": (float(sk_comp01) if np.isfinite(sk_comp01) else np.nan),\n",
    "        \"skel_junctions_sum\": (float(sk_junc_sum) if np.isfinite(sk_junc_sum) else np.nan),\n",
    "        \"skel_edges_sum\": (float(sk_edges_sum) if np.isfinite(sk_edges_sum) else np.nan),\n",
    "\n",
    "        \"form6_clutter_complexity_01\": float(cc01),\n",
    "    })\n",
    "\n",
    "df_img = pd.DataFrame(rows_img)\n",
    "df_reg = pd.DataFrame(rows_reg_econ)\n",
    "\n",
    "df_img.to_csv(OUT_DIR / \"form6_image_indices.csv\", index=False)\n",
    "df_reg.to_csv(OUT_DIR / \"form6_region_economy.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_DIR / \"form6_image_indices.csv\", \"rows=\", len(df_img))\n",
    "print(\"Saved:\", OUT_DIR / \"form6_region_economy.csv\", \"rows=\", len(df_reg))\n",
    "df_img.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:16:22.489313500Z",
     "start_time": "2025-12-28T10:11:26.646862600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Computational Indexing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged form table: (260, 55)\n",
      "Saved: outputs\\form\\form_computational_indices.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_9684\\770586121.py:44: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(x)\n",
      "F:\\New Dissertation - Image Generation\\POC\\venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2019: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "data": {
      "text/plain": "       split                      image_id  form1_orientation_stability_01  \\\n0  generated  generated/ComfyUI_00082_.png                             NaN   \n1  generated  generated/ComfyUI_00083_.png                             NaN   \n2  generated  generated/ComfyUI_00084_.png                             NaN   \n3  generated  generated/ComfyUI_00085_.png                             NaN   \n4  generated  generated/ComfyUI_00086_.png                             NaN   \n5  generated  generated/ComfyUI_00087_.png                             NaN   \n6  generated  generated/ComfyUI_00088_.png                             NaN   \n7  generated  generated/ComfyUI_00089_.png                             NaN   \n8  generated  generated/ComfyUI_00090_.png                             NaN   \n9  generated  generated/ComfyUI_00091_.png                             NaN   \n\n   form2_projection_pressure_01  form3_depth_hierarchy_01  \\\n0                           NaN                       NaN   \n1                           NaN                       NaN   \n2                           NaN                       NaN   \n3                           NaN                       NaN   \n4                           NaN                       NaN   \n5                           NaN                       NaN   \n6                           NaN                       NaN   \n7                           NaN                       NaN   \n8                           NaN                       NaN   \n9                           NaN                       NaN   \n\n   form4_completion_coherence_01  form5_ornamentality_01  \\\n0                            NaN                     NaN   \n1                            NaN                     NaN   \n2                            NaN                     NaN   \n3                            NaN                     NaN   \n4                            NaN                     NaN   \n5                            NaN                     NaN   \n6                            NaN                     NaN   \n7                            NaN                     NaN   \n8                            NaN                     NaN   \n9                            NaN                     NaN   \n\n   form6_abstraction_level_01  form_composite_index_01  \\\n0                    0.541762                 0.541762   \n1                    0.542342                 0.542342   \n2                    0.542344                 0.542344   \n3                    0.518043                 0.518043   \n4                    0.773744                 0.773744   \n5                    0.791118                 0.791118   \n6                    0.780689                 0.780689   \n7                    0.529644                 0.529644   \n8                    0.538636                 0.538636   \n9                    0.690616                 0.690616   \n\n   form1_orientation_stability_z  form2_projection_pressure_z  \\\n0                            NaN                          NaN   \n1                            NaN                          NaN   \n2                            NaN                          NaN   \n3                            NaN                          NaN   \n4                            NaN                          NaN   \n5                            NaN                          NaN   \n6                            NaN                          NaN   \n7                            NaN                          NaN   \n8                            NaN                          NaN   \n9                            NaN                          NaN   \n\n   form3_depth_hierarchy_z  form4_completion_coherence_z  \\\n0                      NaN                           NaN   \n1                      NaN                           NaN   \n2                      NaN                           NaN   \n3                      NaN                           NaN   \n4                      NaN                           NaN   \n5                      NaN                           NaN   \n6                      NaN                           NaN   \n7                      NaN                           NaN   \n8                      NaN                           NaN   \n9                      NaN                           NaN   \n\n   form5_ornamentality_z  form6_abstraction_level_z  form_composite_index_z  \n0                    NaN                  -0.695638                0.108628  \n1                    NaN                  -0.691071                0.112691  \n2                    NaN                  -0.691056                0.112704  \n3                    NaN                  -0.882288               -0.057401  \n4                    NaN                   1.129895                1.732486  \n5                    NaN                   1.266616                1.854102  \n6                    NaN                   1.184548                1.781100  \n7                    NaN                  -0.790997                0.023804  \n8                    NaN                  -0.720238                0.086746  \n9                    NaN                   0.475736                1.150595  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>split</th>\n      <th>image_id</th>\n      <th>form1_orientation_stability_01</th>\n      <th>form2_projection_pressure_01</th>\n      <th>form3_depth_hierarchy_01</th>\n      <th>form4_completion_coherence_01</th>\n      <th>form5_ornamentality_01</th>\n      <th>form6_abstraction_level_01</th>\n      <th>form_composite_index_01</th>\n      <th>form1_orientation_stability_z</th>\n      <th>form2_projection_pressure_z</th>\n      <th>form3_depth_hierarchy_z</th>\n      <th>form4_completion_coherence_z</th>\n      <th>form5_ornamentality_z</th>\n      <th>form6_abstraction_level_z</th>\n      <th>form_composite_index_z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>generated</td>\n      <td>generated/ComfyUI_00082_.png</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.541762</td>\n      <td>0.541762</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.695638</td>\n      <td>0.108628</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>generated</td>\n      <td>generated/ComfyUI_00083_.png</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.542342</td>\n      <td>0.542342</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.691071</td>\n      <td>0.112691</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>generated</td>\n      <td>generated/ComfyUI_00084_.png</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.542344</td>\n      <td>0.542344</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.691056</td>\n      <td>0.112704</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>generated</td>\n      <td>generated/ComfyUI_00085_.png</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.518043</td>\n      <td>0.518043</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.882288</td>\n      <td>-0.057401</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>generated</td>\n      <td>generated/ComfyUI_00086_.png</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.773744</td>\n      <td>0.773744</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.129895</td>\n      <td>1.732486</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>generated</td>\n      <td>generated/ComfyUI_00087_.png</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.791118</td>\n      <td>0.791118</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.266616</td>\n      <td>1.854102</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>generated</td>\n      <td>generated/ComfyUI_00088_.png</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.780689</td>\n      <td>0.780689</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.184548</td>\n      <td>1.781100</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>generated</td>\n      <td>generated/ComfyUI_00089_.png</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.529644</td>\n      <td>0.529644</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.790997</td>\n      <td>0.023804</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>generated</td>\n      <td>generated/ComfyUI_00090_.png</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.538636</td>\n      <td>0.538636</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.720238</td>\n      <td>0.086746</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>generated</td>\n      <td>generated/ComfyUI_00091_.png</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.690616</td>\n      <td>0.690616</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.475736</td>\n      <td>1.150595</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# Output\n",
    "# =========================\n",
    "OUT_DIR = r\"outputs\\form\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# Correct CSVs (from YOUR code)\n",
    "# =========================\n",
    "FILES = {\n",
    "    \"f1\": r\"outputs\\form\\form1_orientation\\form1_image_orientation.csv\",\n",
    "    \"f2\": r\"outputs\\form2_image.csv\",\n",
    "    \"f3\": r\"outputs\\form\\form3\\form3_image.csv\",\n",
    "    \"f4\": r\"outputs\\form4\\form4_image_indices.csv\",\n",
    "    \"f5\": r\"outputs\\form5\\form5_image_indices.csv\",\n",
    "    \"f6\": r\"outputs\\form6\\form6_image_indices.csv\",\n",
    "}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def _safe_read_csv(path):\n",
    "    if path and os.path.exists(path):\n",
    "        return pd.read_csv(path)\n",
    "    print(\"Missing:\", path)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def _as_float(s):\n",
    "    return pd.to_numeric(s, errors=\"coerce\").astype(float)\n",
    "\n",
    "\n",
    "def safe_cols(df, cols):\n",
    "    return [c for c in cols if c in df.columns]\n",
    "\n",
    "\n",
    "def zscore_series(x, eps=1e-9):\n",
    "    x = _as_float(x)\n",
    "    mu = np.nanmean(x)\n",
    "    sd = np.nanstd(x)\n",
    "    return (x - mu) / (sd + eps)\n",
    "\n",
    "\n",
    "def clip01(x):\n",
    "    x = _as_float(x)\n",
    "    return np.clip(x, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def inv01(x):\n",
    "    return 1.0 - clip01(x)\n",
    "\n",
    "\n",
    "def nanmean_row(df, cols):\n",
    "    cols = safe_cols(df, cols)\n",
    "    if not cols:\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    X = df[cols].apply(_as_float)\n",
    "    return X.mean(axis=1, skipna=True)\n",
    "\n",
    "\n",
    "def weighted_nanmean_row(df, cols, wts):\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    if not cols:\n",
    "        return pd.Series(np.nan, index=df.index)\n",
    "    X = df[cols].apply(_as_float)\n",
    "    w = np.array([wts.get(c, 1.0) for c in cols], dtype=float)\n",
    "\n",
    "    num = np.zeros(len(df), dtype=float)\n",
    "    den = np.zeros(len(df), dtype=float)\n",
    "\n",
    "    for j, c in enumerate(cols):\n",
    "        v = X[c].to_numpy(dtype=float)\n",
    "        m = np.isfinite(v)\n",
    "        num[m] += w[j] * v[m]\n",
    "        den[m] += w[j]\n",
    "\n",
    "    out = np.full(len(df), np.nan, dtype=float)\n",
    "    m2 = den > 0\n",
    "    out[m2] = num[m2] / den[m2]\n",
    "    return pd.Series(out, index=df.index)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load + merge (outer)\n",
    "# =========================\n",
    "df1 = _safe_read_csv(FILES[\"f1\"])\n",
    "df2 = _safe_read_csv(FILES[\"f2\"])\n",
    "df3 = _safe_read_csv(FILES[\"f3\"])\n",
    "df4 = _safe_read_csv(FILES[\"f4\"])\n",
    "df5 = _safe_read_csv(FILES[\"f5\"])\n",
    "df6 = _safe_read_csv(FILES[\"f6\"])\n",
    "\n",
    "dfs = [df for df in [df1, df2, df3, df4, df5, df6] if not df.empty]\n",
    "if not dfs:\n",
    "    raise RuntimeError(\"No Form CSVs found. Check FILES paths.\")\n",
    "\n",
    "# validate keys\n",
    "for d in dfs:\n",
    "    if \"split\" not in d.columns or \"image_id\" not in d.columns:\n",
    "        raise ValueError(\"Each CSV must include: split, image_id\")\n",
    "\n",
    "df = dfs[0].copy()\n",
    "for nxt in dfs[1:]:\n",
    "    df = df.merge(nxt, on=[\"split\", \"image_id\"], how=\"outer\", suffixes=(\"\", \"_dup\"))\n",
    "\n",
    "dup_cols = [c for c in df.columns if c.endswith(\"_dup\")]\n",
    "if dup_cols:\n",
    "    df = df.drop(columns=dup_cols)\n",
    "\n",
    "print(\"Merged form table:\", df.shape)\n",
    "df.head(3)\n",
    "\n",
    "# =========================\n",
    "# Subscales (0..1)\n",
    "# =========================\n",
    "\n",
    "# ---- Form-1 (correct columns)\n",
    "df[\"form1_orientation_stability_01\"] = weighted_nanmean_row(\n",
    "    df,\n",
    "    cols=[\n",
    "        \"form1_global_frame_alignment_01\",\n",
    "        \"form1_local_frame_influence_abs_01\",  # \"competing frame\" -> invert\n",
    "        \"form1_orientation_conflict_index_01\",  # conflict -> invert\n",
    "    ],\n",
    "    wts={\n",
    "        \"form1_global_frame_alignment_01\": 0.45,\n",
    "        \"form1_local_frame_influence_abs_01\": 0.25,\n",
    "        \"form1_orientation_conflict_index_01\": 0.30,\n",
    "    }\n",
    ")\n",
    "df[\"_tmp_local_inv\"] = inv01(df.get(\"form1_local_frame_influence_abs_01\", np.nan))\n",
    "df[\"_tmp_conf_inv\"] = inv01(df.get(\"form1_orientation_conflict_index_01\", np.nan))\n",
    "df[\"form1_orientation_stability_01\"] = weighted_nanmean_row(\n",
    "    df,\n",
    "    cols=[\"form1_global_frame_alignment_01\", \"_tmp_local_inv\", \"_tmp_conf_inv\"],\n",
    "    wts={\"form1_global_frame_alignment_01\": 0.45, \"_tmp_local_inv\": 0.25, \"_tmp_conf_inv\": 0.30}\n",
    ")\n",
    "df[\"form1_orientation_stability_01\"] = clip01(df[\"form1_orientation_stability_01\"])\n",
    "\n",
    "# ---- Form-2 (your exact Form-2 outputs)\n",
    "df[\"form2_projection_pressure_01\"] = weighted_nanmean_row(\n",
    "    df,\n",
    "    cols=[\n",
    "        \"form2_affine_distortion_index_01\",\n",
    "        \"form2_symmetry_degradation_index_01\",\n",
    "        \"form2_viewpoint_ambiguity_index_01\",\n",
    "    ],\n",
    "    wts={\n",
    "        \"form2_affine_distortion_index_01\": 0.40,\n",
    "        \"form2_symmetry_degradation_index_01\": 0.30,\n",
    "        \"form2_viewpoint_ambiguity_index_01\": 0.30,\n",
    "    }\n",
    ")\n",
    "df[\"form2_projection_pressure_01\"] = clip01(df[\"form2_projection_pressure_01\"])\n",
    "\n",
    "# ---- Form-3 (your exact Form-3 image column)\n",
    "# only one key index exists in your code:\n",
    "df[\"form3_depth_hierarchy_01\"] = clip01(df.get(\"form3_dominance_subservience_index_01\", np.nan))\n",
    "\n",
    "# ---- Form-4 (your exact Form-4 outputs)\n",
    "df[\"_tmp_amp_inv\"] = inv01(df.get(\"form4_amputation_risk_01\", np.nan))\n",
    "df[\"form4_completion_coherence_01\"] = weighted_nanmean_row(\n",
    "    df,\n",
    "    cols=[\n",
    "        \"form4_good_continuation_01\",\n",
    "        \"form4_completion_plausibility_01\",\n",
    "        \"_tmp_amp_inv\",\n",
    "    ],\n",
    "    wts={\n",
    "        \"form4_good_continuation_01\": 0.45,\n",
    "        \"form4_completion_plausibility_01\": 0.35,\n",
    "        \"_tmp_amp_inv\": 0.20,\n",
    "    }\n",
    ")\n",
    "df[\"form4_completion_coherence_01\"] = clip01(df[\"form4_completion_coherence_01\"])\n",
    "\n",
    "# ---- Form-5 (your exact Form-5 outputs)\n",
    "# Use ornamentality index directly if present\n",
    "if \"form5_ornamentality_index_01\" in df.columns:\n",
    "    df[\"form5_ornamentality_01\"] = clip01(df[\"form5_ornamentality_index_01\"])\n",
    "else:\n",
    "    # fallback build from its parts (still using your column names)\n",
    "    sym = clip01(df.get(\"form5_reflection_symmetry_whole_01\", np.nan))\n",
    "    rep = clip01(df.get(\"form5_repetition_density_01\", np.nan))\n",
    "    spc = clip01(df.get(\"form5_spacing_regularity_01\", np.nan))\n",
    "    surpr = clip01(df.get(\"form5_structural_surprise_01\", np.nan))\n",
    "    df[\"form5_ornamentality_01\"] = nanmean_row(\n",
    "        pd.DataFrame({\"sym\": sym, \"rep\": rep, \"spc\": spc, \"surpr_inv\": inv01(surpr)}),\n",
    "        [\"sym\", \"rep\", \"spc\", \"surpr_inv\"]\n",
    "    )\n",
    "df[\"form5_ornamentality_01\"] = clip01(df[\"form5_ornamentality_01\"])\n",
    "\n",
    "# ---- Form-6 (your exact Form-6 outputs)\n",
    "# Abstraction level = geometricization high + (1 - clutter) + economy (optional)\n",
    "geo = clip01(df.get(\"form6_geometricization_01\", np.nan))\n",
    "clu = clip01(df.get(\"form6_clutter_complexity_01\", np.nan))\n",
    "eco = clip01(df.get(\"form6_structural_economy_01\", np.nan))\n",
    "\n",
    "df[\"form6_abstraction_level_01\"] = weighted_nanmean_row(\n",
    "    pd.DataFrame({\"geo\": geo, \"clu_inv\": inv01(clu), \"eco\": eco}),\n",
    "    cols=[\"geo\", \"clu_inv\", \"eco\"],\n",
    "    wts={\"geo\": 0.45, \"clu_inv\": 0.35, \"eco\": 0.20}\n",
    ")\n",
    "df[\"form6_abstraction_level_01\"] = clip01(df[\"form6_abstraction_level_01\"])\n",
    "\n",
    "# =========================\n",
    "# Composite FORM index\n",
    "# =========================\n",
    "SUBSCALES = [\n",
    "    \"form1_orientation_stability_01\",\n",
    "    \"form2_projection_pressure_01\",\n",
    "    \"form3_depth_hierarchy_01\",\n",
    "    \"form4_completion_coherence_01\",\n",
    "    \"form5_ornamentality_01\",\n",
    "    \"form6_abstraction_level_01\",\n",
    "]\n",
    "df[\"form_composite_index_01\"] = nanmean_row(df, SUBSCALES)\n",
    "df[\"form_composite_index_01\"] = clip01(df[\"form_composite_index_01\"])\n",
    "\n",
    "# =========================\n",
    "# Z-scored versions\n",
    "# =========================\n",
    "for c in SUBSCALES + [\"form_composite_index_01\"]:\n",
    "    df[c.replace(\"_01\", \"_z\")] = zscore_series(df[c])\n",
    "\n",
    "# =========================\n",
    "# Save\n",
    "# =========================\n",
    "keep_cols = [\"split\", \"image_id\"] + SUBSCALES + [\"form_composite_index_01\"] + [c for c in df.columns if\n",
    "                                                                               c.endswith(\"_z\")]\n",
    "out_path = os.path.join(OUT_DIR, \"form_computational_indices.csv\")\n",
    "df[keep_cols].to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "df[keep_cols].head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-28T10:16:22.709144300Z",
     "start_time": "2025-12-28T10:16:22.493891200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
