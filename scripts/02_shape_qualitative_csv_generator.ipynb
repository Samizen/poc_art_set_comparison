{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-26T15:14:52.095256500Z",
     "start_time": "2025-12-26T15:14:51.939382900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: outputs\\shape_likert_simulated.csv\n",
      "Rows: 128\n",
      "       split                      image_id  Q1_shape_emergence  \\\n",
      "0  generated  generated\\ComfyUI_00082_.png                   2   \n",
      "1  generated  generated\\ComfyUI_00083_.png                   3   \n",
      "2  generated  generated\\ComfyUI_00084_.png                   4   \n",
      "3  generated  generated\\ComfyUI_00085_.png                   2   \n",
      "4  generated  generated\\ComfyUI_00086_.png                   2   \n",
      "5  generated  generated\\ComfyUI_00087_.png                   4   \n",
      "6  generated  generated\\ComfyUI_00088_.png                   3   \n",
      "7  generated  generated\\ComfyUI_00089_.png                   2   \n",
      "8  generated  generated\\ComfyUI_00090_.png                   3   \n",
      "9  generated  generated\\ComfyUI_00091_.png                   3   \n",
      "\n",
      "   Q2_boundary_coherence  Q3_felt_structural_axis  Q4_symmetry_quality  \\\n",
      "0                      3                        4                    3   \n",
      "1                      3                        2                    2   \n",
      "2                      5                        2                    2   \n",
      "3                      1                        3                    3   \n",
      "4                      3                        1                    4   \n",
      "5                      5                        2                    4   \n",
      "6                      2                        1                    3   \n",
      "7                      3                        3                    3   \n",
      "8                      4                        3                    3   \n",
      "9                      3                        2                    4   \n",
      "\n",
      "   Q5_hierarchical_org  Q6_part_whole_integration  Q7_perceptual_stability  \\\n",
      "0                    1                          2                        2   \n",
      "1                    3                          3                        4   \n",
      "2                    3                          3                        5   \n",
      "3                    2                          2                        2   \n",
      "4                    5                          3                        3   \n",
      "5                    5                          3                        5   \n",
      "6                    5                          3                        3   \n",
      "7                    2                          2                        2   \n",
      "8                    1                          2                        3   \n",
      "9                    5                          3                        3   \n",
      "\n",
      "   Q8_organic_coherence  structural_coherence_mean  expressive_integrity_mean  \\\n",
      "0                     3                        2.4                   2.666667   \n",
      "1                     3                        3.0                   2.666667   \n",
      "2                     5                        3.8                   3.333333   \n",
      "3                     2                        2.0                   2.333333   \n",
      "4                     3                        2.8                   3.333333   \n",
      "5                     5                        4.2                   4.000000   \n",
      "6                     3                        2.8                   3.000000   \n",
      "7                     4                        2.4                   3.000000   \n",
      "8                     3                        2.8                   2.666667   \n",
      "9                     4                        3.2                   3.666667   \n",
      "\n",
      "   axis_strength_index  symmetry_index  stability_index  \\\n",
      "0             3.459521        0.785653         0.829584   \n",
      "1             0.999565        0.204949              NaN   \n",
      "2             1.976940        0.180049         0.992013   \n",
      "3             3.009513        0.504762         0.793352   \n",
      "4             1.060515        0.938276              NaN   \n",
      "5             0.693290        1.000000         0.999778   \n",
      "6             0.744670        0.963108              NaN   \n",
      "7             2.771166        0.576099         0.797746   \n",
      "8             2.421234        0.538318         0.920009   \n",
      "9             0.849009        0.977425              NaN   \n",
      "\n",
      "   hierarchy_concentration_top1  branching_complexity  \n",
      "0                      0.232892              0.116142  \n",
      "1                      0.515896              0.199165  \n",
      "2                      0.428655              0.346817  \n",
      "3                      0.260589              0.276426  \n",
      "4                      1.000000              0.290718  \n",
      "5                      1.000000              0.007380  \n",
      "6                      1.000000              0.364271  \n",
      "7                      0.261871              0.144952  \n",
      "8                      0.290556              0.266798  \n",
      "9                      1.000000              0.340951  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_22220\\1560203275.py:107: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_extra = df_r.groupby([\"split\", \"image_id\"], as_index=False).apply(agg_group).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# shape_likert_generator.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "INPUT_DIR = Path(\"outputs\")\n",
    "REGION_CSV = r\"F:\\New Dissertation - Image Generation\\POC\\outputs\\shape_region_features.csv\"\n",
    "IMAGE_CSV  = r\"F:\\New Dissertation - Image Generation\\POC\\outputs\\shape_image_indices.csv\"\n",
    "OUT_CSV    = r\"F:\\New Dissertation - Image Generation\\POC\\outputs\\shape_likert_simulated.csv\"\n",
    "\n",
    "SEED = 42\n",
    "NOISE = 0.35          # overall Likert noise (lower = more deterministic)\n",
    "CLIP_MIN, CLIP_MAX = 1, 5\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def robust_norm01(x, lo=5, hi=95):\n",
    "    \"\"\"Robust normalize to [0,1] using percentiles to avoid outliers.\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if np.all(~np.isfinite(x)):\n",
    "        return np.full_like(x, np.nan, dtype=float)\n",
    "    a = np.nanpercentile(x, lo)\n",
    "    b = np.nanpercentile(x, hi)\n",
    "    if not np.isfinite(a) or not np.isfinite(b) or abs(b - a) < 1e-12:\n",
    "        return np.clip(x, 0, 1)\n",
    "    y = (x - a) / (b - a)\n",
    "    return np.clip(y, 0.0, 1.0)\n",
    "\n",
    "def to_likert_1to5(score01, noise=NOISE):\n",
    "    \"\"\"\n",
    "    Map score in [0,1] -> Likert 1..5 with noise.\n",
    "    \"\"\"\n",
    "    s = np.asarray(score01, dtype=float)\n",
    "    s = np.clip(s, 0.0, 1.0)\n",
    "    # map to 1..5\n",
    "    y = 1.0 + 4.0 * s\n",
    "    # add small gaussian noise\n",
    "    y = y + rng.normal(0.0, noise, size=y.shape)\n",
    "    y = np.clip(y, CLIP_MIN, CLIP_MAX)\n",
    "    return np.rint(y).astype(int)\n",
    "\n",
    "def weighted_mean(x, w):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    w = np.asarray(w, dtype=float)\n",
    "    m = np.isfinite(x) & np.isfinite(w) & (w > 0)\n",
    "    if m.sum() == 0:\n",
    "        return np.nan\n",
    "    return float(np.sum(x[m] * w[m]) / (np.sum(w[m]) + 1e-12))\n",
    "\n",
    "def safe_log1p(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    x = np.where(np.isfinite(x) & (x > 0), x, np.nan)\n",
    "    return np.log1p(x)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load CSVs\n",
    "# -----------------------------\n",
    "df_r = pd.read_csv(REGION_CSV)\n",
    "df_i = pd.read_csv(IMAGE_CSV)\n",
    "\n",
    "# -----------------------------\n",
    "# Build extra image-level aggregates from region table\n",
    "# -----------------------------\n",
    "# weights: saliency if present else area_ratio\n",
    "w = df_r[\"saliency\"].astype(float)\n",
    "w = np.where(np.isfinite(w) & (w > 0), w, np.nan)\n",
    "df_r[\"_w\"] = w\n",
    "# fallback when all NaN weights per image will be handled groupwise\n",
    "df_r[\"_w_area\"] = np.where(np.isfinite(df_r[\"area_ratio\"]), df_r[\"area_ratio\"].astype(float), 0.0)\n",
    "\n",
    "df_r[\"_axis_strength\"] = safe_log1p(df_r[\"pca_eig_ratio\"].astype(float))\n",
    "\n",
    "def agg_group(g):\n",
    "    ww = g[\"_w\"].to_numpy(dtype=float)\n",
    "    if not np.isfinite(ww).any():\n",
    "        ww = g[\"_w_area\"].to_numpy(dtype=float)\n",
    "    ww = np.where(np.isfinite(ww) & (ww > 0), ww, 0.0)\n",
    "\n",
    "    return pd.Series({\n",
    "        \"axis_strength_wm\": weighted_mean(g[\"_axis_strength\"].to_numpy(dtype=float), ww),\n",
    "        \"symmetry_wm\": weighted_mean(g[\"symmetry_pca\"].to_numpy(dtype=float), ww),\n",
    "        \"smoothness_wm\": weighted_mean(g[\"smoothness\"].to_numpy(dtype=float), ww),\n",
    "        \"centeredness_wm\": weighted_mean(g[\"centeredness\"].to_numpy(dtype=float), ww),\n",
    "\n",
    "        # stability fields: handle missing columns gracefully\n",
    "        \"stability_mean_wm\": weighted_mean(g.get(\"stability_mask_mean\", g.get(\"stability_iou\")).to_numpy(dtype=float), ww)\n",
    "        if (\"stability_mask_mean\" in g.columns or \"stability_iou\" in g.columns) else np.nan,\n",
    "\n",
    "        \"stability_range_wm\": weighted_mean(g[\"stability_mask_range\"].to_numpy(dtype=float), ww)\n",
    "        if \"stability_mask_range\" in g.columns else np.nan,\n",
    "\n",
    "        \"n_regions\": int(len(g)),\n",
    "        \"saliency_top1_share\": float(\n",
    "            (np.nanmax(np.where(np.isfinite(g[\"saliency\"].to_numpy(dtype=float)), g[\"saliency\"].to_numpy(dtype=float), 0.0)))\n",
    "            / (np.nansum(np.where(np.isfinite(g[\"saliency\"].to_numpy(dtype=float)), g[\"saliency\"].to_numpy(dtype=float), 0.0)) + 1e-12)\n",
    "        ) if np.isfinite(g[\"saliency\"].to_numpy(dtype=float)).any() else np.nan,\n",
    "    })\n",
    "\n",
    "df_extra = df_r.groupby([\"split\", \"image_id\"], as_index=False).apply(agg_group).reset_index(drop=True)\n",
    "\n",
    "# Merge onto image indices\n",
    "df = df_i.merge(df_extra, on=[\"split\", \"image_id\"], how=\"left\")\n",
    "\n",
    "# -----------------------------\n",
    "# Build perceptual scores (0..1) for each Likert question\n",
    "# using realistic proxies from computed metrics.\n",
    "# -----------------------------\n",
    "# Normalized components\n",
    "axis01    = robust_norm01(df[\"axis_strength_index\"].astype(float) if \"axis_strength_index\" in df.columns else df[\"axis_strength_wm\"].astype(float))\n",
    "sym01     = robust_norm01(df[\"symmetry_index\"].astype(float) if \"symmetry_index\" in df.columns else df[\"symmetry_wm\"].astype(float))\n",
    "stab01    = robust_norm01(df[\"stability_index\"].astype(float) if \"stability_index\" in df.columns else df[\"stability_mean_wm\"].astype(float))\n",
    "hier01    = robust_norm01(df[\"hierarchy_concentration_top1\"].astype(float) if \"hierarchy_concentration_top1\" in df.columns else df[\"saliency_top1_share\"].astype(float))\n",
    "branch01  = robust_norm01(df[\"branching_complexity\"].astype(float)) if \"branching_complexity\" in df.columns else np.full(len(df), np.nan)\n",
    "smooth01  = robust_norm01(df[\"smoothness_wm\"].astype(float))\n",
    "cent01    = robust_norm01(df[\"centeredness_wm\"].astype(float))\n",
    "\n",
    "# A simple mechanical-ness penalty (very high symmetry + high branching tends to feel constructed)\n",
    "mech01 = np.nan_to_num(0.6 * sym01 + 0.4 * branch01, nan=0.5)\n",
    "\n",
    "# Q1 Shape Emergence: hierarchy + stability + mild axis support\n",
    "q1_score = np.nan_to_num(0.45 * hier01 + 0.40 * stab01 + 0.15 * axis01, nan=0.5)\n",
    "\n",
    "# Q2 Boundary Coherence: stability + smoothness (closure/continuity proxy)\n",
    "q2_score = np.nan_to_num(0.55 * stab01 + 0.45 * smooth01, nan=0.5)\n",
    "\n",
    "# Q3 Felt Structural Axis: axis strength (dominant) + low branchiness\n",
    "q3_score = np.nan_to_num(0.75 * axis01 + 0.25 * (1.0 - np.nan_to_num(branch01, nan=0.5)), nan=0.5)\n",
    "\n",
    "# Q4 Symmetry Quality: symmetry, but penalize \"mechanical\" feeling\n",
    "q4_score = np.nan_to_num(0.75 * sym01 + 0.25 * (1.0 - mech01), nan=0.5)\n",
    "\n",
    "# Q5 Hierarchical Organization: hierarchy concentration (dominant)\n",
    "q5_score = np.nan_to_num(hier01, nan=0.5)\n",
    "\n",
    "# Q6 Partâ€“Whole Integration: hierarchy + axis + centeredness (coherence proxy)\n",
    "q6_score = np.nan_to_num(0.35 * hier01 + 0.35 * axis01 + 0.30 * cent01, nan=0.5)\n",
    "\n",
    "# Q7 Perceptual Stability: stability + centeredness\n",
    "q7_score = np.nan_to_num(0.70 * stab01 + 0.30 * cent01, nan=0.5)\n",
    "\n",
    "# Q8 Organic Coherence: smoothness + stability, penalize mechanical-ness\n",
    "q8_score = np.nan_to_num(0.50 * smooth01 + 0.35 * stab01 + 0.15 * (1.0 - mech01), nan=0.5)\n",
    "\n",
    "# -----------------------------\n",
    "# Convert to Likert 1..5\n",
    "# -----------------------------\n",
    "df_out = df[[\"split\", \"image_id\"]].copy()\n",
    "\n",
    "df_out[\"Q1_shape_emergence\"]       = to_likert_1to5(q1_score)\n",
    "df_out[\"Q2_boundary_coherence\"]    = to_likert_1to5(q2_score)\n",
    "df_out[\"Q3_felt_structural_axis\"]  = to_likert_1to5(q3_score)\n",
    "df_out[\"Q4_symmetry_quality\"]      = to_likert_1to5(q4_score)\n",
    "df_out[\"Q5_hierarchical_org\"]      = to_likert_1to5(q5_score)\n",
    "df_out[\"Q6_part_whole_integration\"]= to_likert_1to5(q6_score)\n",
    "df_out[\"Q7_perceptual_stability\"]  = to_likert_1to5(q7_score)\n",
    "df_out[\"Q8_organic_coherence\"]     = to_likert_1to5(q8_score)\n",
    "\n",
    "# composites (useful for reporting)\n",
    "df_out[\"structural_coherence_mean\"] = df_out[\n",
    "    [\"Q1_shape_emergence\",\"Q2_boundary_coherence\",\"Q3_felt_structural_axis\",\"Q5_hierarchical_org\",\"Q7_perceptual_stability\"]\n",
    "].mean(axis=1)\n",
    "\n",
    "df_out[\"expressive_integrity_mean\"] = df_out[\n",
    "    [\"Q4_symmetry_quality\",\"Q6_part_whole_integration\",\"Q8_organic_coherence\"]\n",
    "].mean(axis=1)\n",
    "\n",
    "# include computed indices (optional but helpful for analysis joins)\n",
    "keep_cols = [c for c in [\"axis_strength_index\",\"symmetry_index\",\"stability_index\",\"hierarchy_concentration_top1\",\"branching_complexity\"] if c in df.columns]\n",
    "for c in keep_cols:\n",
    "    df_out[c] = df[c].values\n",
    "\n",
    "# write\n",
    "OUT_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_out.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(\"Wrote:\", OUT_CSV)\n",
    "print(\"Rows:\", len(df_out))\n",
    "print(df_out.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
